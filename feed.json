{
    "version": "https://jsonfeed.org/version/1",
    "title": "幽化猫の博客",
    "subtitle": "生活朗朗，万物可爱",
    "icon": "https://love.youhuamao.xyz/images/favicon.ico",
    "description": "这是一个人的博客",
    "home_page_url": "https://love.youhuamao.xyz",
    "items": [
        {
            "id": "https://love.youhuamao.xyz/2022/11/12/ai/Andrew%20Ng%20Lesson/%E9%99%8D%E7%BB%B4/",
            "url": "https://love.youhuamao.xyz/2022/11/12/ai/Andrew%20Ng%20Lesson/%E9%99%8D%E7%BB%B4/",
            "title": "Dimensionality Reduction 降维",
            "date_published": "2022-11-11T16:00:00.000Z",
            "content_html": "<h1 id=\"降维的动机一数据压缩-data-compression\"><a class=\"anchor\" href=\"#降维的动机一数据压缩-data-compression\">#</a> 降维的动机一：数据压缩 Data Compression</h1>\n<p>现在讨论第二种无监督学习问题：降维。 降维的一个作用是数据压缩，允许我们使用较少的内存或磁盘空间，也加快算法速度。</p>\n<p>举例：<br />\n假设用两个特征描述同一个物品的长度，x1 单位是厘米 cm，x2 单位是英寸 inches。这将导致高度冗余，所以需要减到一维。<br />\n<img data-src=\"/pic/wuenda/jiangwei-01.png\" alt=\"img.png\" /></p>\n<p>将数据从三维降至二维：将三维向量投射到一个二维的平面上，强迫使得所有的数据都在同一个平面上，降至二维的特征向量。<br />\n<img data-src=\"/pic/wuenda/jiangwei-02.png\" alt=\"img.png\" /></p>\n<p>这个过程可以用于把任何维度的数据降到任何想要的维度。事实工作中，不同的团队可能会给你几百或成千上万的特征，其中很容易出现冗余特征。</p>\n<h1 id=\"降维的动机二数据可视化-visualization\"><a class=\"anchor\" href=\"#降维的动机二数据可视化-visualization\">#</a> 降维的动机二：数据可视化 Visualization</h1>\n<p>降维可以帮助我们将高维数据可视化。<br />\n假使有关于许多不同国家的数据，每一个特征向量都有 50 个特征 (如 GDP，人均 GDP，平均寿命等)。如果要将这个 50 维的数据可视化是不可能的。将其降至 2 维，便可将其可视化了。<br />\n<img data-src=\"/pic/wuenda/jiangwei-03.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/jiangwei-04.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/jiangwei-05.png\" alt=\"img.png\" /><br />\n 这样做的问题在于，降维算法只负责减少维数，新产生的特征的意义就必须由我们自己去发现了。</p>\n<h1 id=\"pca问题的公式描述-principal-component-analysis-problem-formulation\"><a class=\"anchor\" href=\"#pca问题的公式描述-principal-component-analysis-problem-formulation\">#</a> PCA 问题的公式描述 Principal Component Analysis Problem Formulation</h1>\n<p>主成分分析 (PCA) 是最常见的降维算法。PCA 要做的是找到一个方向向量 (Vector direction)，当把所有的数据都投射到该向量上时，投射平均均方误差尽可能小。方向向量是一个经过原点的向量，投射误差是从特征向量向该方向向量所作垂线的长度。如下图：<br />\n<img data-src=\"/pic/wuenda/jiangwei-06.png\" alt=\"img.png\" /></p>\n<p>主成分分析问题，要将 n 维数据降至 k 维，目标是找到向量 u (1) ，u (2) ，...，u (k) 使得总的投射误差 Projected Error 最小:<br />\n<img data-src=\"/pic/wuenda/jiangwei-07.png\" alt=\"img.png\" /></p>\n<p>主成分分析与线性回归的比较:<br />\n<img data-src=\"/pic/wuenda/jiangwei-08.png\" alt=\"img.png\" /></p>\n<p>主成分分析最小化的是投射误差，不作任何预测。</p>\n<p>线性回归最小化的是预测误差，目的是预测结果。<br />\n上图中，左边的是线性回归的误差 (垂直于横轴投影)，右边则是主要成分分析的误差 (垂直于斜线投影)。</p>\n<p>PCA 将 n 个特征降维到 k 个，可以用来进行数据压缩，如果 100 维的向量最后可以用 10 维来表示，那么压缩率为 90%。同样图像处理领域的 KL 变换使用 PCA 做图像压缩。但 PCA 要保证降维后数据的特性损失最小。</p>\n<p>PCA 的一大好处是对数据进行降维处理。我们可以对新求出的 “主元” 向量的重要性进行排序，根据需要取前面最重要的部分，将后面的维数省去，可以达到降维从而简化模型或是对数据进行压缩的效果。同时最大程度保持原有数据的信息。</p>\n<p>PCA 的一个很大的优点是，它是完全无参数限制的。在 PCA 的计算过程中完全不需要人为的设定参数或是根据任何经验模型对计算进行干预，最后的结果只与数据相关，与用户是独立的。 但这同时也是缺点，如果用户对观测对象有一定的先验知识，掌握了数据的一些特征，却无法通过参数化等方法对处理过程进行干预，可能会得不到预期的效果，效率也不高。</p>\n<h1 id=\"pca算法-principal-component-analysis-algorithm\"><a class=\"anchor\" href=\"#pca算法-principal-component-analysis-algorithm\">#</a> PCA 算法 Principal Component Analysis Algorithm</h1>\n<p>使用 PCA 从 n 维减少到 k 维:<br />\n1 均值归一化。计算出所有特征的均值，然后令 xj = xj − μj 。如果特征是在不同的数量级上，还需要将其除以标准差 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">σ^{2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span> 。<br />\n<img data-src=\"/pic/wuenda/jiangwei-09.png\" alt=\"img.png\" /></p>\n<p>2 计算协方差矩阵 (covariance matrix) sigma Σ<br />\n<img data-src=\"/pic/wuenda/jiangwei-10.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/jiangwei-11.png\" alt=\"img.png\" /></p>\n<p>3）计算协方差矩阵 Σ 的特征向量 (eigenvectors):<br />\n 在 Matlab 里我们可以利用奇异值分解 (singular value decomposition) 来得到特则向量矩阵 U，调用方式为 [U， S，V] = svd (sigma) 。（注：函数返回的矩阵 S 也有用，后续会讲到）<br />\n<img data-src=\"/pic/wuenda/jiangwei-12.png\" alt=\"img.png\" /></p>\n<p>对于一个 n × n 维度的矩阵，U 是一个由 “与数据之间最小投射误差的方向向量” 构成的矩阵。 如果希望将数据从 n 维降至 k 维，只需要从 U 中选取前 k 个向量，获得一个 n × k 维度的矩阵，用 Ureduce 表示，然后通过如下计算获得要求的新特征向量 z (i):<br />\n<img data-src=\"/pic/wuenda/jiangwei-13.png\" alt=\"img.png\" /></p>\n<p>其中 Ureduce 为 n x k 维，x 为 n × 1 维，因此结果 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">z^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 为 k × 1 维。 注：我们不对方差特征进行处理。<br />\n<img data-src=\"/pic/wuenda/jiangwei-14.png\" alt=\"img.png\" /></p>\n<h1 id=\"重建原始特征-reconstruction-from-compressed-representation\"><a class=\"anchor\" href=\"#重建原始特征-reconstruction-from-compressed-representation\">#</a> 重建原始特征 Reconstruction from Compressed Representation</h1>\n<p>给定压缩后的低维数据 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">z^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 怎么反向得到高维的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 数据？ 即：如何根据压缩后的数据去重建原始数据？</p>\n<p>当 x 为 2 维，z 为 1 维，z = UreduceT * x， 则相反的方程为: xappox = Ureduce ⋅ z，  这时有 xappox ≈ x。<br />\n<img data-src=\"/pic/wuenda/jiangwei-15.png\" alt=\"img.png\" /></p>\n<h1 id=\"选择主成分的数量k-choosing-the-number-of-principal-components\"><a class=\"anchor\" href=\"#选择主成分的数量k-choosing-the-number-of-principal-components\">#</a> 选择主成分的数量 k Choosing The Number Of Principal Components</h1>\n<p>主要成分分析最小化投射的平均均方误差，怎么选择适当降维目标 k 值（即主成分的数量）呢？</p>\n<p>我们的目标是：在『平均均方误差与训练集方差的比例尽可能小』的情况下，选择尽可能小的 k 值。</p>\n<p>如果希望比例小于 1%， 就意味着原本数据的偏差有 99% 都保留下来了。 另外，还可以使用 5%（对应 95% 的偏差）， 10%（对应 90% 的偏差） 这些比例。</p>\n<p>通常 95% 到 99% 是最常用的取值范围。（注：对于许多数据集，通常可以在保留大部分差异性的同时大幅降低数据的维度。这是因为大部分现实数据的许多特征变量都是高度相关的。）<br />\n<img data-src=\"/pic/wuenda/jiangwei-16.png\" alt=\"img.png\" /></p>\n<p>具体做法：<br />\n<img data-src=\"/pic/wuenda/jiangwei-17.png\" alt=\"img.png\" /></p>\n<p>a) 先令 k = 1，然后进行主要成分分析，获得 Ureduce 和 z，然后计算比例是否小于 1%。<br />\nb) 如果不是的话，再令 k = 2，如此类推，直到找到可以使得比例小于 1% 的最小 k 值。</p>\n<p>事实上还有一些更好的方式，在 Matlab 中有一个 “svd” 函数。 其中，SVD 代表为奇异值分解（singular value decomposition），函数调用 [U, S, V] = svd (sigma) 返回一个与 Σ（即 ppt 中的 Sigma） 同大小的对角矩阵 S（由 Σ 的特征值组成），两个酉矩阵 U 和 V ，且满足 Σ = U * S * V'。若 A 为 m×n 矩阵，则 U 为 m×m 矩阵，V 为 n×n 矩阵。奇异值在 S 的对角线上，非负且按降序排列，对角线之外的其它元素都是 0。</p>\n<p>对于方阵 Σ，有<br />\n<img data-src=\"/pic/wuenda/jiangwei-18.png\" alt=\"img.png\" /></p>\n<p>因为我们的目的是从 n 维降到 k 维，也就是选出这 n 个特征中最重要的 k 个，也就是选出特征值最大的 k 个。所以得到矩阵 S 后，我们可以直接用它来计算平均均方误差与训练集方差的比例，而不用一遍遍重复计算误差和方差:<br />\n<img data-src=\"/pic/wuenda/jiangwei-19.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/jiangwei-20.png\" alt=\"img.png\" /></p>\n<h1 id=\"pca的应用建议-advice-for-applying-pca\"><a class=\"anchor\" href=\"#pca的应用建议-advice-for-applying-pca\">#</a> PCA 的应用建议 Advice for Applying PCA</h1>\n<p>假使我们正在针对一张 100×100 像素的图片进行某个计算机视觉的机器学习，即总共有 10000 个特征。使用 PCA 算法的步骤如下：</p>\n<ol>\n<li>运用 PCA 将数据压缩至 1000 个特征</li>\n<li>对训练集运行学习算法</li>\n<li>在预测时，采用之前学习得到的 Ureduce 将输入的特征 x 转换成特征向量 z ，然后再进行预测<br />\n<img data-src=\"/pic/wuenda/jiangwei-21.png\" alt=\"img.png\" /><br />\n 注：如果有交叉验证数据集，也采用对训练集学习而来的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>U</mi><mrow><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">U_{reduce}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">u</span><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 。</li>\n</ol>\n<ul>\n<li>\n<p>正确用法，压缩和可视化：<br />\n<img data-src=\"/pic/wuenda/jiangwei-22.png\" alt=\"img.png\" /></p>\n</li>\n<li>\n<p>错误的用法:</p>\n</li>\n</ul>\n<ol>\n<li>将其用于减少过拟合 (通过减少特征的数量)<br />\n<img data-src=\"/pic/wuenda/jiangwei-23.png\" alt=\"img.png\" /></li>\n</ol>\n<p>这样做非常不好，不如使用正则化处理。原因在于 PCA 只是近似地丢弃掉一些特征，它并不考虑任何与结果变量有关的信息，因此可能会丢失非常重要的特征。而当进行正则化处理时，会考虑到结果变量，不会丢掉重要的数据。</p>\n<ol start=\"2\">\n<li>在项目开始时便将 PCA 考虑进去</li>\n<li><img data-src=\"/pic/wuenda/jiangwei-24.png\" alt=\"img.png\" /></li>\n</ol>\n",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/11/ai/Andrew%20Ng%20Lesson/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/",
            "url": "https://love.youhuamao.xyz/2022/11/11/ai/Andrew%20Ng%20Lesson/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/",
            "title": "支持向量机 Support Vector Machines",
            "date_published": "2022-11-10T16:00:00.000Z",
            "content_html": "<h1 id=\"优化目标-optimization-objective\"><a class=\"anchor\" href=\"#优化目标-optimization-objective\">#</a> 优化目标 Optimization Objective</h1>\n<p>支持向量机 (Support Vector Machine) 是一个更加强大的算法，广泛应用于工业界和学术界。与逻辑回归和神经网络相比， SVM 在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。我们通过回顾逻辑回归，一步步将其修改为 SVM。<br />\n首先回顾一下逻辑回归:<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-01.png\" alt=\"img.png\" /></p>\n<p>其 cost function 公式如下（这里稍微有点变化，将负号移到了括号内）：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-02.png\" alt=\"img.png\" /></p>\n<p>现在只考虑一个训练数据 x ，把 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mi mathvariant=\"normal\">/</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><msup><mi>θ</mi><mi>T</mi></msup><mi>x</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_{θ}(x)=1/(1+e^{-θ^{T}x})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord\">/</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.256365em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.006365em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9190928571428572em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal mtight\">x</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 带入公式，得到下面的式子：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-03.png\" alt=\"img.png\" /></p>\n<p>下一步， 使用 z 标示其中的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>θ</mi><mi>T</mi></msup><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">θ^{T}x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\">x</span></span></span></span> ， 则之前的目标变为：<br />\nIf y = 1， we want <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_{θ}(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span> ≈ 1， z&gt;&gt;0；<br />\nIf y = 0， we want <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_{θ}(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span> ≈ 0， z&lt;&lt;0；</p>\n<p>当 y = 1 或 y = 0 时， 上面逻辑回归的 cost function 分别只剩下一项， 对应下面两张图中的灰色曲线：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-04.png\" alt=\"img.png\" /></p>\n<p>当 y=1 时，随着 z 增大，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mi mathvariant=\"normal\">/</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h(x)=1/(1+e^{-z})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord\">/</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.021331em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.771331em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 逼近 1，cost 逐渐减小。　    当 y=0 时，随着 z 减小，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mi mathvariant=\"normal\">/</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h(x)=1/(1+e^{-z})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord\">/</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.021331em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.771331em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 逼近 0，cost 逐渐减小。<br />\n现在我们用新的 cost function 来代替逻辑回归中的 cost function，即上图中玫瑰色的曲线，它分为直线和斜线两部分。左边的函数称为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><msub><mi>t</mi><mn>1</mn></msub><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">cost_{1}(z)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mord\"><span class=\"mord mathnormal\">t</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span></span></span></span>，右边函数称为  <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><msub><mi>t</mi><mn>0</mn></msub><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">cost_{0}(z)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mord\"><span class=\"mord mathnormal\">t</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span></span></span></span>。<br />\n在之后的优化问题中，这种形式的 cost function 会为 SVM 带来计算上的优势。</p>\n<p>现在开始构建 SVM<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-05.png\" alt=\"img.png\" /></p>\n<p>逻辑回归的 cost function 分为 A、B 两个部分。 我们做下面的操作：<br />\n（a） 使用之前定义的 cost1 () 和 cost0 () 替换公式中对应的项。<br />\n（b） 根据 SVM 的习惯，除去 1/m 这个系数<br />\n因为 1/m 仅是个常量，去掉它也会得出同样的 θ 最优值。<br />\n（c）同样根据 SVM 的习惯，做一点变动<br />\n对于逻辑回归， cost function 为 A + λ × B ，通过设置不同的 λ 达到优化目的。 对于 SVM， 我们删掉 λ，引入常数 C， 将 cost function 改为 C × A + B， 通过设置不同的 C 达到优化目的。 （在优化过程中，其意义和逻辑回归是一样的。可以理解为 C = 1 / λ）</p>\n<p>最终得到 SVM 的代价函数：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-06.png\" alt=\"img.png\" /></p>\n<p>另外，逻辑回归中假设的输出是一个概率值。 而 SVM 直接预测 y = 1，还是 y = 0。<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-07.png\" alt=\"img.png\" /><br />\n 当 θTx ≥ 0 时，SVM 会预测结果为 1，其他情况下，预测结果为 0。</p>\n<h1 id=\"大间距分类的直观理解-large-margin-intuition\"><a class=\"anchor\" href=\"#大间距分类的直观理解-large-margin-intuition\">#</a> 大间距分类的直观理解 Large Margin Intuition</h1>\n<p>SVM 经常被看作是一个 &quot;大间距分类器&quot;，也就是找到一条与正类、负类的距离最大的分隔线。 例如下图中的黑线：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-08.png\" alt=\"img.png\" /></p>\n<p>在这一节，我们将得出结论： 为了增加鲁棒性，得到更好的结果 (避免欠拟合、过拟合，应对线性不可分的情况)，SVM 做的不仅仅是将间距最大化，而是做了一些优化：<br />\n（1）之前的定义中，θTx ≥ 0 被分为正类，θTx &lt; 0 被分为负类。</p>\n<p>事实上，SVM 的要求更严格： θTx ≥ 1 被分为正类；θTx ≤ -1 被分为负类<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-09.png\" alt=\"img.png\" /></p>\n<p>这就相当于在支持向量机中嵌入了一个额外的安全因子，或者说安全的间距因子。<br />\n（2）只有当 C 特别大的时候， SVM 才是一个最大间隔分类器<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-10.png\" alt=\"img.png\" /></p>\n<p>当 C 特别大时，在优化过程中，第一项会接近于 0，目标变为最小化第二项：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-11.png\" alt=\"img.png\" /></p>\n<p>我们在训练集中加入一个异常点 outlier ，如下：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-12.png\" alt=\"img.png\" /></p>\n<p>（a）如果想将样本用最大间距分开，即将 C 设置的很大。那么仅因为一个异常点，决策边界会从黑线变成那条粉线，这实在是不明智的。<br />\n（b）如果 C 设置的小一点，最终得到这条黑线。它可以忽略一些异常点的影响，而且当数据线性不可分的时候，也可以将它们恰当分开，得到更好地决策边界。</p>\n<p>另外，因为 C = 1 / λ，因此:<br />\nC 较小时，相当于 λ 较大。可能会导致欠拟合，高偏差 variance。<br />\nC 较大时，相当于 λ 较小。可能会导致过拟合，高方差 bias。<br />\n（注：这个性质在习题中考察多次）</p>\n<h1 id=\"大间距分类背后的数学-mathematics-behind-large-margin-classification\"><a class=\"anchor\" href=\"#大间距分类背后的数学-mathematics-behind-large-margin-classification\">#</a> 大间距分类背后的数学 Mathematics Behind Large Margin Classification</h1>\n<h2 id=\"向量内积\"><a class=\"anchor\" href=\"#向量内积\">#</a> 向量内积</h2>\n<p>先看一下向量内积的知识： 假设有两个二维向量 u 和 v ，uTv 叫做向量 u 和 v 之间的内积。<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-13.png\" alt=\"img.png\" /><br />\n∥u∥ 表示 u 的范数 norm，即向量 u 的欧几里得长度，是一个实数。根据毕达哥拉斯定理<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-14.png\" alt=\"img.png\" /></p>\n<p>第一种内积计算方式：首先将 v 投影至 u 向量，记其长度为 p（有正负，与 u 同向为正，反向为负，标量），则两向量的内积<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>u</mi><mi>T</mi></msub><mi>v</mi><mo>=</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>u</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mo separator=\"true\">⋅</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>v</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mo separator=\"true\">⋅</mo><mi>c</mi><mi>o</mi><mi>s</mi><mi>θ</mi><mo>=</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>u</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mo separator=\"true\">⋅</mo><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">u_{T}v = ||u|| · ||v|| · cosθ = ||u|| · p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">u</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">u</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">p</span></span></span></span><br />\n（注：||u|| 是一个实数，p 也是一个实数，因此 uTv 就是两个实数正常相乘。）<br />\n第二种内积计算公式：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>u</mi><mi>T</mi></msub><mi>v</mi><mo>=</mo><mi>u</mi><mn>1</mn><mo>×</mo><mi>v</mi><mn>1</mn><mo>+</mo><mi>u</mi><mn>2</mn><mo>×</mo><mi>v</mi><mn>2</mn><mo>=</mo><msub><mi>v</mi><mi>T</mi></msub><mi>u</mi></mrow><annotation encoding=\"application/x-tex\">u_{T}v = u1 × v1 + u2 × v2  = v_{T}u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">u</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">u</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\">u</span></span></span></span></p>\n<h2 id=\"svm-代价函数的另一种理解\"><a class=\"anchor\" href=\"#svm-代价函数的另一种理解\">#</a> SVM 代价函数的另一种理解</h2>\n<p>SVM 的 cost function 如下：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-15.png\" alt=\"img.png\" /><br />\n 如果将 C 设的很大，cost function 只剩下后面的那项。 为简化设 θ0 = 0，只剩下 θ1 和 θ2，则 cost function 为：<br />\nJ(θ) = 1/2 × ||θ||^2<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-16.png\" alt=\"img.png\" /><br />\n 而根据上面内积的公式，我们知道有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>θ</mi><mi>T</mi></msup><mi>x</mi><mo>=</mo><mi>p</mi><mo separator=\"true\">⋅</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>θ</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">θ^{T}x = p · ||θ||</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span></span></span></span>，其中 p 是 x 在 θ 上的投影。 使用<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>⋅</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>θ</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">p^{(i)} ⋅ ||θ||</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span></span></span></span> 代替之前约束中的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>θ</mi><mi>T</mi></msup><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">θ^{T}x^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> ，得到：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-17.png\" alt=\"img.png\" /></p>\n<h2 id=\"svm-如何选择更优的决策边界\"><a class=\"anchor\" href=\"#svm-如何选择更优的决策边界\">#</a> SVM 如何选择更优的决策边界</h2>\n<p>考察优化目标函数时， 假设我们的到一条绿色的决策边界。样本在决策边界上的投影 p 是粉色的线：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-18.png\" alt=\"img.png\" /><br />\n 对于正样本 x (1) 而言，想要 p (1) ⋅ ∥θ∥ &gt;= 1，现在 p (1) 长度非常短，就意味着 ||θ|| 需要非常大；<br />\n对于负样本 x (2) 而言，想要 p (1) ⋅∥θ∥ &lt;= −1，现在 p (2) 长度非常短，就意味着 ||θ|| 需要非常大。</p>\n<p>但我们的目标函数是希望最小化参数 θ 的范数，因此我们希望： 投影长度 p (i) 尽可能大。例如下面这条绿色的决策边界，就更好一些：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-19.png\" alt=\"img.png\" /></p>\n<p>θ0 = 0 的意思是我们让决策界通过原点。如果 θ0 ≠ 0，决策边界不过原点 ，SVM 产生大间距分类器的结论同样成立（在 C 特别大的情况下）</p>\n<h1 id=\"核函数-kernels-i\"><a class=\"anchor\" href=\"#核函数-kernels-i\">#</a> 核函数 Kernels I</h1>\n<p>使用高级数的多项式模型，可以解决无法用直线进行分隔的分类：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-20.png\" alt=\"img.png\" /></p>\n<p>可以用一系列的新的特征 f 来替换模型中的每一项。例如令: f1 = x1 ， f2 = x2 ， f3 = x1 x2 ， f4 = x12 ， f5= x22... 得到 hθ(x) = f1 + f2 +. . . +fn 。有没有更好的方法来构造 f1 ， f2 ， f3 ? 我们可以利用核函数来计算出新的特征。</p>\n<p>给定一个训练实例 x ，我们利用 x 的各个特征与我们预先选定的 landmarks l (1) ， l (2) ， l (3) 的近似程度来选取新的特征 f1 ， f2 ， f3 。<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-21.png\" alt=\"img.png\" /></p>\n<p>其中: ||x − l (1) || 为实例 x 中所有特征与 landmark  l (1) 距离的和。<br />\n上例中的 similarity (x， l (1) ) 就是核函数，具体来说是一个高斯核函数 (Gaussian Kernel)。（注：这个函数与正态分布没什么实际上的关系，只是看上去像而已。）</p>\n<p>如果一个训练实例 x 与 l 很近，则 f 近似于 e−0 = 1；如果一个训练实例 x 与 l 很远，则 f 近似于 e−(较大的数) = 0。 如下：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-22.png\" alt=\"img.png\" /></p>\n<p>假设 x 含有两个特征 [x1 x2]， 不同的 σ 值会有不同效果。 图中水平面的坐标为 x1， x 2 而垂直坐标轴代表 f。只有当 x 与 l (1) 重合时， f 才具有最大值。随着 x 的改变 f 值的变化速率受到 σ2 的控制。 σ2 越小，曲线越瘦<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-23.png\" alt=\"img.png\" /></p>\n<p>下图中，粉色点离 l (1) 更近，所以 f1 接近 1，而 f2 ，f3 接近 0。因此 h θ(x) ≥ 0，因此预测 y = 1；同理，绿色点离 l (2) 较近的，也预测 y = 1；但蓝绿色点离三个 landmark 都较远，预测 y = 0。<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-24.png\" alt=\"img.png\" /></p>\n<p>图中红色封闭曲线便是决策边界。在预测时我们采用的特征不是训练实例本身的特征，而是通过核函数计算出的新特征 f1 ， f2 ， f3 。</p>\n<h1 id=\"核函数-kernels-ii\"><a class=\"anchor\" href=\"#核函数-kernels-ii\">#</a> 核函数 Kernels II</h1>\n<h2 id=\"如何选择-landemark\"><a class=\"anchor\" href=\"#如何选择-landemark\">#</a> 如何选择 landemark</h2>\n<p>通常如果训练集有 m 个实例，则选取 m 个 landmark，并将 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>l</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">l^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 初始化为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> ：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-25.png\" alt=\"img.png\" /></p>\n<p>好处：新特征建立在原有特征与训练集中所有其他特征之间距离的基础之上。<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-26.png\" alt=\"img.png\" /></p>\n<p>对实例 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mtext>，</mtext><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(x^{(i)}，y^{(i)})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，有：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-27.png\" alt=\"img.png\" /></p>\n<h2 id=\"将-kernel-引入-svm\"><a class=\"anchor\" href=\"#将-kernel-引入-svm\">#</a> 将 kernel 引入 SVM</h2>\n<p>我们将 Gaussian Kernel 代入 SVM 的 cost function，如下图所示：<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-28.png\" alt=\"img.png\" /><br />\n 这里与之前的 cost function 的区别在于用核函数 f 代替了 x。<br />\n预测一个实例 x 对应结果的方法：  给定 x，计算新特征 f，当 θTf &gt;= 0 时预测 y = 1； 否则反之。</p>\n<h2 id=\"简化计算\"><a class=\"anchor\" href=\"#简化计算\">#</a> 简化计算</h2>\n<p>最后，为了简化计算， 在计算正则项 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>θ</mi><mi>T</mi></msup><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">θ^{T}θ</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span></span></span></span> 时，用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>θ</mi><mi>T</mi></msup><mi>M</mi><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">θ^{T}Mθ</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span></span></span></span> 代替 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>θ</mi><mi>T</mi></msup><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">θ^{T}θ</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span></span></span></span> ，其中 M 是一个矩阵，核函数不同则 M 不同。（注：理论上也可以在逻辑回归中使用核函数，但使用 M 简化计算的方法不适用于逻辑回归，计算将非常耗时。）</p>\n<h2 id=\"线性核函数\"><a class=\"anchor\" href=\"#线性核函数\">#</a> 线性核函数</h2>\n<p>不使用核函数又称为线性核函数 (linear kernel)。线性核函数 SVM 适用于函数简单，或特征非常多而实例非常少的情况。</p>\n<h2 id=\"svm-的参数\"><a class=\"anchor\" href=\"#svm-的参数\">#</a> SVM 的参数</h2>\n<p>带有 kernel 的 SVM 有两个参数 C 和 σ，对结果的影响如下：</p>\n<ol>\n<li>\n<p>C<br />\n 当 C 较大，相当于 λ 小，可能会导致过拟合，高方差 variance;<br />\n 当 C 较小，相当于 λ 大，可能会导致欠拟合，高偏差 bias;</p>\n</li>\n<li>\n<p>σ<br />\n 当 σ 较大时，图像扁平，可能会导致低方差，高偏差 bias;<br />\n 当 σ 较小时，图像窄尖，可能会导致低偏差，高方差 variance。<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-29.png\" alt=\"img.png\" /></p>\n</li>\n</ol>\n<h1 id=\"使用支持向量机-using-an-svm\"><a class=\"anchor\" href=\"#使用支持向量机-using-an-svm\">#</a> 使用支持向量机 Using An SVM</h1>\n<p><img data-src=\"/pic/wuenda/zhichixiangliangji-30.png\" alt=\"img.png\" /></p>\n<h2 id=\"使用现有软件包\"><a class=\"anchor\" href=\"#使用现有软件包\">#</a> 使用现有软件包</h2>\n<p>我们通常需要自己写核函数，然后使用现有的软件包 (如 liblinear，libsvm 等) 来最小化 SVM 代价函数。强烈建议使用高优化软件库中的一个，而不是尝试自己实现。</p>\n<h2 id=\"对比一下两种-svm\"><a class=\"anchor\" href=\"#对比一下两种-svm\">#</a> 对比一下两种 SVM</h2>\n<p>一种是 No kernel（linear kernel），hθ(x)=g (θ0x0+θ1x1+…+θnxn)，predict y=1 if θTx&gt;=0;<br />\n 另一种是使用 kernel f（比如 Gaussian Kernel），hθ(x)=g (θ0f0+θ1f1+…+θnfn)，这里需要选择方差参数 σ2</p>\n<h2 id=\"特征缩放\"><a class=\"anchor\" href=\"#特征缩放\">#</a> 特征缩放</h2>\n<p>特别地，如果使用高斯核函数，需要进行特征缩放。<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-31.png\" alt=\"img.png\" /></p>\n<h2 id=\"其他-kernel\"><a class=\"anchor\" href=\"#其他-kernel\">#</a> 其他 kernel</h2>\n<p>在高斯核函数之外，还有其他一些选择，如：<br />\n多项式核函数 (Polynomial Kernel)， 字符串核函数 (String kernel)， 卡方核函数 ( chi-square kernel) ，直方图交集核函数 (histogram intersection kernel) 等。<br />\n它们的目标也都是根据训练集和地标之间的距离来构建新特征。一个核函数需要满足 Mercer's 定理，才能被 SVM 的优化软件正确处理。 但是 Andrew 表示他不用其他 kernel 函数。</p>\n<p><img data-src=\"/pic/wuenda/zhichixiangliangji-32.png\" alt=\"img.png\" /></p>\n<h2 id=\"多分类问题\"><a class=\"anchor\" href=\"#多分类问题\">#</a> 多分类问题</h2>\n<p>可以训练 k 个支持向量机来解决多类分类问题。 但是大多数支持向量机软件包都有内置的多类分类功能，我们只要直接使用即可。<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-33.png\" alt=\"img.png\" /></p>\n<h2 id=\"参数设置\"><a class=\"anchor\" href=\"#参数设置\">#</a> 参数设置</h2>\n<p>下面是一些普遍使用的准则：<br />\nn 为特征数，m 为训练样本数。<br />\n(a) 如果 n » m，即训练集数据量不够支持我们训练一个复杂的非线性模型，选用逻辑回归模型或者不带核函数的 SVM。<br />\n(b) 如果 n 较小，m 中等，例如 n 在 1-1000 之间，而 m 在 10-10000 之间，使用高斯核函数的 SVM。<br />\n(c) 如果 n 较小，m 较大，例如 n 在 1-1000 之间，而 m 大于 50000，则使用 SVM 会非常慢。解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的 SVM。<br />\n如果训练集非常大，高斯核函数的 SVM 会非常慢。 通常 Andrew 会尝试手动创建特征，然后用逻辑回归或者不带核函数的 SVM。</p>\n<p>（注： 逻辑回归和不带核函数的 SVM 非常相似。但是根据实际情况，其中一个可能会更有效。随着 SVM 的复杂度增加、特征数量相当大时，不带核函数的 SVM 就会表现得相当突出。）<br />\n<img data-src=\"/pic/wuenda/zhichixiangliangji-34.png\" alt=\"img.png\" /></p>\n<p>一个设计得很好的神经网络也很有可能会非常有效。有一个缺点是，可能会特别慢。一个非常好的 SVM 实现包可能会运行得比较快比神经网络快很多，而且它的代价函数是凸函数，不存在局部最优解。 (黄海广注：当时 GPU 计算比较慢，神经网络还不流行。)</p>\n",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/11/ai/Andrew%20Ng%20Lesson/%E8%81%9A%E7%B1%BB/",
            "url": "https://love.youhuamao.xyz/2022/11/11/ai/Andrew%20Ng%20Lesson/%E8%81%9A%E7%B1%BB/",
            "title": "聚类 Clustering",
            "date_published": "2022-11-10T16:00:00.000Z",
            "content_html": "<h1 id=\"无监督学习简介-unsupervised-learning-introduction\"><a class=\"anchor\" href=\"#无监督学习简介-unsupervised-learning-introduction\">#</a> 无监督学习简介  Unsupervised Learning Introduction</h1>\n<p>现在开始学习第一个无监督学习算法：聚类。我们的数据没有附带任何标签，拿到的数据就是这样的:<br />\n<img data-src=\"/pic/wuenda/julei-01.png\" alt=\"img.png\" /></p>\n<p>例子：<br />\n<img data-src=\"/pic/wuenda/julei-02.png\" alt=\"img.png\" /></p>\n<h1 id=\"k-means算法-k-means-algorithm\"><a class=\"anchor\" href=\"#k-means算法-k-means-algorithm\">#</a> K-means 算法 K-Means Algorithm</h1>\n<p>K-Means 是最普及的聚类算法，算法接受一个未标记的数据集，然后将数据聚类成不同的组。<br />\n迭代过程为：<br />\n1）选择 K 个随机的点，称为聚类中心 (cluster centroids);<br />\n2）对于数据集中的每个数据，按照距离 K 个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。<br />\n3）计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置。<br />\n4）重复步骤 2-3 直至中心点不再变化。</p>\n<p><img data-src=\"/pic/wuenda/julei-03.png\" alt=\"img.png\" /></p>\n<p>下面是一个聚类示例:<br />\n 初始化随机的中心点，计算距离后分类，然后移动中心点<br />\n<img data-src=\"/pic/wuenda/julei-04.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/julei-05.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/julei-06.png\" alt=\"img.png\" /></p>\n<p>迭代很多次之后，得到最终聚类结果：<br />\n<img data-src=\"/pic/wuenda/julei-07.png\" alt=\"img.png\" /></p>\n<p>在没有非常明显组群的情况下，也可以使用 K-means。例如下图中，使用 K-means 确定要生产的 T - 恤衫的三种尺寸：<br />\n<img data-src=\"/pic/wuenda/julei-08.png\" alt=\"img.png\" /></p>\n<h1 id=\"优化目标-optimization-objective\"><a class=\"anchor\" href=\"#优化目标-optimization-objective\">#</a> 优化目标 Optimization Objective</h1>\n<p>K-means 最小化问题，是要最小化所有数据点与其所关联的聚类中心点之间的距离之和，因此 K-means 的代价函数 (又称畸变函数 Distortion function) 为:<br />\n<img data-src=\"/pic/wuenda/julei-09.png\" alt=\"img.png\" /></p>\n<p>目标是使其最小<br />\n<img data-src=\"/pic/wuenda/julei-10.png\" alt=\"img.png\" /></p>\n<p>由于算法第一个循环用于减小 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>c</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">c^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 引起的代价，而第二个循环则是用于减小 μi 引起的代价。会在每一次迭代都减小代价，不然便说明存在错误。<br />\n<img data-src=\"/pic/wuenda/julei-11.png\" alt=\"img.png\" /></p>\n<h1 id=\"随机初始化-random-initialization\"><a class=\"anchor\" href=\"#随机初始化-random-initialization\">#</a> 随机初始化 Random Initialization</h1>\n<p>随机初始化的聚类中心点的方法：<br />\na) 选择 K &lt; m，即聚类中心点的个数要小于所有训练集实例的数量<br />\n b) 随机选择 K 个训练实例，然后令 K 个聚类中心分别与这 K 个训练实例相等</p>\n<p><img data-src=\"/pic/wuenda/julei-12.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/julei-13.png\" alt=\"img.png\" /></p>\n<p>K-means 的一个问题在于，如果初始化不好，有可能会停留在一个局部最小值处。通常需要运行多次 K-means 算法，每一次都重新随机初始化，最后比较多次运行 K-means 的结果，选择代价函数最小的结果。这种方法在 K 较小的时候 (2-10) 可行，如果 K 较大可能不会有明显地改善。<br />\n<img data-src=\"/pic/wuenda/julei-14.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/julei-15.png\" alt=\"img.png\" /></p>\n<h1 id=\"选择聚类数-choosing-the-number-of-clusters\"><a class=\"anchor\" href=\"#选择聚类数-choosing-the-number-of-clusters\">#</a> 选择聚类数 Choosing the Number of Clusters</h1>\n<p>没有最好的选择聚类数的方法，通常是需要根据不同的问题人工选择。需要思考运用 K-means 算法的动机，然后选择能最好服务于该目的的聚类数。<br />\n这里存在一个 “肘部法则”：改变聚类数 K，运行聚类算法，然后计算成本函数 (畸变函数) J。 有可能会得到一条类似于肘部的曲线：<br />\n<img data-src=\"/pic/wuenda/julei-16.png\" alt=\"img.png\" /></p>\n<p>上图在 3 的时候达到一个肘点。在此之后，畸变值就下降的非常慢，那么我们就选 K = 3。<br />\n但是大部分情况下图像会像右图一样没有肘点。就需要人工选择。 例如，根据客户需求选择 T - 恤的尺寸数：<br />\n<img data-src=\"/pic/wuenda/julei-17.png\" alt=\"img.png\" /></p>\n<p>附，参考黄海广笔记：<br />\n<img data-src=\"/pic/wuenda/julei-18.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/julei-19.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/julei-20.png\" alt=\"img.png\" /></p>\n",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/10/ai/Andrew%20Ng%20Lesson/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/",
            "url": "https://love.youhuamao.xyz/2022/11/10/ai/Andrew%20Ng%20Lesson/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/",
            "title": "机器学习系统设计 Machine Learning System Design",
            "date_published": "2022-11-09T16:00:00.000Z",
            "content_html": "<h1 id=\"垃圾邮件分类\"><a class=\"anchor\" href=\"#垃圾邮件分类\">#</a> 垃圾邮件分类</h1>\n<p>本章中用一个实际例子： 垃圾邮件 Spam 的分类 来描述机器学习系统设计方法。首先来看两封邮件，左边是一封垃圾邮件 Spam，右边是一封非垃圾邮件 Non-Spam：<br />\n<img data-src=\"/pic/wuenda/xitongsheji-01.png\" alt=\"img.png\" /><br />\n 垃圾邮件有很多 features。如果我们想要建立一个 Spam 分类器，就要进行有监督学习，将 Spam 的 features 提取出来，而希望这些 features 能够很好的区分 Spam。<br />\n<img data-src=\"/pic/wuenda/xitongsheji-02.png\" alt=\"img.png\" /></p>\n<p>事实上，对于 spam 分类器，通常选取 spam 中词频最高的 100 个词来做 feature。<br />\n为了构建分类器算法，可能有很多策略：</p>\n<ol>\n<li>收集更多的数据，让我们有更多的垃圾邮件和非垃圾邮件的样本</li>\n<li>基于邮件的路由信息开发一系列复杂的特征</li>\n<li>基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理</li>\n<li>为探测刻意的拼写错误 (把 watch 写成 w4tch) 开发复杂的算法</li>\n</ol>\n<h1 id=\"误差分析-error-analysis\"><a class=\"anchor\" href=\"#误差分析-error-analysis\">#</a> 误差分析 Error Analysis</h1>\n<p>构建一个学习算法的推荐方法为:</p>\n<ol>\n<li>从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法</li>\n<li>绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择</li>\n<li>进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的实例，看看这些实例是否有某种系统化的趋势</li>\n</ol>\n<p>例如下图中，对 100 个分类错误的邮件进行人工分析，左边区分了它们的类型分布，右边分析没有被正确分类的原因。<br />\n<img data-src=\"/pic/wuenda/xitongsheji-03.png\" alt=\"img.png\" /></p>\n<p>在误差分析的时候，不能单纯依靠直觉 gut feeling ，而是用数字体现。<br />\n例如，对于 discount/discounts/discounted/discounting 是否被视为都含有 discount 这个 feature。如果看作含有这个 feature，结果有 3% 的 error；如果不看做有这个 feature，则有 5% 的 error。以此进行比较。<br />\n<img data-src=\"/pic/wuenda/xitongsheji-04.png\" alt=\"img.png\" /><br />\n 注：使用 Porter stemmer 这种软件可以合并类似的单词，但是也可能引发错误。</p>\n<h1 id=\"类偏斜的误差度量-error-metrics-for-skewed-classes\"><a class=\"anchor\" href=\"#类偏斜的误差度量-error-metrics-for-skewed-classes\">#</a> 类偏斜的误差度量 Error Metrics for Skewed Classes</h1>\n<p>Skewed Classes：一个分类问题，结果仅有两类 y=0 和 y=1，其中一类样本非常多、另一类非常少。<br />\n对于偏斜数据集，如果单纯考虑准确率 accuracy，会导致有时候模型预测的结果，还不如全部判断为 1 或者全部判断 0 的结果好。  所以需要引入另外一些辅助度量指标</p>\n<p>考虑一个二分问题，即将实例分成正类（positive）或负类（negative）。对一个二分问题来说，会出现四种情况：</p>\n<ol>\n<li>正确肯定 (True Positive,TP)：预测为真，实际为真</li>\n<li>正确否定 (True Negative,TN)：预测为假，实际为假</li>\n<li>错误肯定 (False Positive,FP)：预测为真，实际为假</li>\n<li>错误否定 (False Negative,FN)：预测为假，实际为真</li>\n</ol>\n<p>这样就可以建立一个 Error Metrics（下图左），并定义 precision 和 recall，如下图所示：<br />\n<img data-src=\"/pic/wuenda/xitongsheji-05.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/xitongsheji-06.png\" alt=\"img.png\" /></p>\n<p>计算公式：<br />\n<img data-src=\"/pic/wuenda/xitongsheji-07.png\" alt=\"img.png\" /></p>\n<p>precision： 正确预测的正样本 / 所有预测为正样本的<br />\n recall：正确预测正样本 / 真实值为正样本的；</p>\n<p>假设有一个 spam 分类任务，测试集只有 1% 为 spam 邮件（y=1），99% 为 non-spam 邮件（y=0）。</p>\n<p>（1）如果全都分类为 non-spam 非垃圾邮件：<br />\nprecision=0/(0+1)=0，recall=0/(0+99)=0，accurancy=(0+99)/100*100% = 99%<br />\n 可以看出虽然 acuracy 很高，但是 recall 和 precision 都是 0，模型不合格。</p>\n<p>（2）如果全都分类为 spam 垃圾邮件：<br />\nprecision=1/(99+1)*100%=1%, recall=1/(1+0)<em>100%=100%， accurancy=(1+0)/100</em>100% = 1%<br />\n precision 和 accuracy 都很低，模型也不合格。</p>\n<p>所以，无论数据集是否偏斜，需要满足 precision 和 recall 都很高才可以保证该算法的实用性。</p>\n<h1 id=\"查准率precision-和-查全率recall-之间的权衡\"><a class=\"anchor\" href=\"#查准率precision-和-查全率recall-之间的权衡\">#</a> 查准率 Precision 和 查全率 Recall 之间的权衡</h1>\n<p>分类结果在 0-1 之间，所以我们需要选择一个阈值，大于阈值的分类为 1，小于阈值的分类为 0。<br />\nprecision-recall 和阈值的关系如下：<br />\n<img data-src=\"/pic/wuenda/xitongsheji-08.png\" alt=\"img.png\" /></p>\n<p>threshould 设定越高，查准率 Precision 越高、查全率 Recall 越低。因为判断的准、但有更多正例被漏掉。<br />\nthreshould 设定越低，查准率 Precision 越低、查全率 Recall 越高。因为找的全，但有更多负例被错判为正例。</p>\n<p>那么如何选择阈值？ 我们引入一个评价标准 % F_{1}% Score，选择使 F1 值最大的阈值<br />\n<img data-src=\"/pic/wuenda/xitongsheji-09.png\" alt=\"img.png\" /></p>\n<p>下面这个例子中，算法 1 的 F1 值最高<br />\n<img data-src=\"/pic/wuenda/xitongsheji-10.png\" alt=\"img.png\" /></p>\n<h1 id=\"数据集的大小\"><a class=\"anchor\" href=\"#数据集的大小\">#</a> 数据集的大小</h1>\n<p>对于机器学习，通常可以选择很多不同的算法进行预测，随着训练集规模增大，Accuracy 一般会提高：<br />\n<img data-src=\"/pic/wuenda/xitongsheji-11.png\" alt=\"img.png\" /></p>\n<p>但事实上，单纯增大数据集并不能解决一切问题。 如果数据集中含的信息很少（比如想对房价进行预测，但是只有面积数据。这时候即使增加数据、或者对模型在面积这个 feature 上进行多项式处理，也起不到好的效果）</p>\n<p>总之，结论为：<br />\n如果模型欠拟合，即偏差 bias 大：  那就要增加特征（对神经网络增加 hidden units）;<br />\n 如果模型过拟合，即方差 variance 大： 那就要增大数据集，使得 Jcv ≈ Jtrain ，从而降低过拟合。</p>\n",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/08/Java/Java%E5%9F%BA%E7%A1%80/%E6%B3%9B%E5%9E%8B/",
            "url": "https://love.youhuamao.xyz/2022/11/08/Java/Java%E5%9F%BA%E7%A1%80/%E6%B3%9B%E5%9E%8B/",
            "title": "泛型",
            "date_published": "2022-11-07T16:00:00.000Z",
            "content_html": "<h1 id=\"泛型的好处和理解\"><a class=\"anchor\" href=\"#泛型的好处和理解\">#</a> 泛型的好处和理解</h1>\n<ul>\n<li>\n<p>使用传统方法的问题分析<br />\n不能对加入到集合 ArrayList 中的数据类型进行约束 (不安全),ArrayList 可以放的是 obj，可以容纳所有数据类型<br />\n遍历的时候，需要进行类型转换，如果集合中的数据量较大，对效率有影响</p>\n</li>\n<li>\n<p>泛型示例</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//1.当我们ArrayList<span class=\"token operator\">&lt;</span>Dog<span class=\"token operator\">></span> 表示存放到ArrayList 集合中的元素是Dog类型<span class=\"token punctuation\">(</span>细 节后面说<span class=\"token punctuation\">..</span>.<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//2.如果编译器发现添加的类型，不满足要求，就会报错</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//3.在遍历的时候，可以直接取出Dog类型而不是Object</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>ArrayL ist<span class=\"token operator\">&lt;</span>Dog<span class=\"token operator\">></span> arrayList <span class=\"token operator\">=</span> new ArrayL ist<span class=\"token operator\">&lt;</span>Dog<span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>arrayL ist <span class=\"token builtin class-name\">.</span> add<span class=\"token punctuation\">(</span>new Dog<span class=\"token punctuation\">(</span><span class=\"token string\">\"旺财\"</span>，10<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>arrayList. add<span class=\"token punctuation\">(</span>new Dog<span class=\"token punctuation\">(</span><span class=\"token string\">\"发财\"</span> ,1<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>arrayL ist <span class=\"token builtin class-name\">.</span> add<span class=\"token punctuation\">(</span>new Dog<span class=\"token punctuation\">(</span><span class=\"token string\">\"小黄\"</span>，5<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>//假如我们的程序员，不小心，添加了一只猫</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>/ /arrayList. add<span class=\"token punctuation\">(</span>new Cat<span class=\"token punctuation\">(</span><span class=\"token string\">\"招财猫\"</span>，8<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span><span class=\"token punctuation\">(</span>会出错误<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out. printLn<span class=\"token punctuation\">(</span> <span class=\"token string\">\"===使用泛型====\"</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Dog dog <span class=\"token builtin class-name\">:</span> arrayList<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    System.out.printLn<span class=\"token punctuation\">(</span>dog <span class=\"token builtin class-name\">.</span> getName<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> + <span class=\"token string\">\"-\"</span> + dog.getAge<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>泛型好处</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>编译时，检查添加元素的类型，提高了安全性</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>减少了类型转换的次数，提高效率<span class=\"token punctuation\">[</span>说明<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>不使用泛型</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Dog -加入-<span class=\"token operator\">></span> Object -取出-<span class=\"token operator\">></span> Dog //放入到ArrayList会先转成Object，在取出时，还需要转换成Dog</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>使用泛型</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>Dog-<span class=\"token operator\">></span> Dog -<span class=\"token operator\">></span> Dog //放入时，和取出时，不需要类型转换，提高效率</pre></td></tr></table></figure><h1 id=\"泛型介绍\"><a class=\"anchor\" href=\"#泛型介绍\">#</a> 泛型介绍</h1>\n<p>老韩理解：泛 (广 泛) 型 (类型) =&gt; Integer, String,Dog<br />\n1) 泛型又称参数化类型，是 Jdk5.0 出现的新特性解决数据类型的安全性问题<br />\n 2) 在类声明或实例化时只要指定好需要的具体的类型即可。<br />\n3) Java 泛型可以保证如果程序在编译时没有发出警告，运行时就不会产生 ClassCastException 异常。 同时，代码更加简洁、健壮<br />\n 4) 泛型的作用是：可以在类声明时通过一个标识表示类中某个属性的类型，或者是某个方法的返回值的类型，或者是参数类型.</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//泛型的作用是:可以在类声明时通过一个标识表示类中某个属性的类型，</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//或者是某个方法的返回值的类型，或者是参数类型</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Person<span class=\"token operator\">&lt;</span>String<span class=\"token operator\">></span> person <span class=\"token operator\">=</span> new Person<span class=\"token operator\">&lt;</span>String<span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token string\">\"幽化猫\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>cLass Person<span class=\"token operator\">&lt;</span>E<span class=\"token operator\">></span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    E s<span class=\"token punctuation\">;</span>//E表示s的数据类型，该数据类型在定义Person对象的时候指定,即在编译期间，就确定E是什么类型</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    public Person<span class=\"token punctuation\">(</span>E s<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>//E也可以是 参数类型</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        this.s <span class=\"token operator\">=</span> s<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    public E <span class=\"token function-name function\">f</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>//返 回类型使用E</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        <span class=\"token builtin class-name\">return</span> S<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h1 id=\"泛型的语法\"><a class=\"anchor\" href=\"#泛型的语法\">#</a> 泛型的语法</h1>\n<ul>\n<li>泛型的声明</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>interface接口<span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span><span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span>和class类<span class=\"token operator\">&lt;</span>K,V<span class=\"token operator\">></span><span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//比如: List , ArrayList</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>其中，T,K,V不代表值，而是表示类型。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>任意字母都可以。常用T表示，是Type的缩写</pre></td></tr></table></figure><ul>\n<li>泛型的实例化</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>要在类名后面指定类型参数的值<span class=\"token punctuation\">(</span>类型<span class=\"token punctuation\">)</span>。</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>List<span class=\"token operator\">&lt;</span>String<span class=\"token operator\">></span> strList <span class=\"token operator\">=</span> new ArrayList <span class=\"token operator\">&lt;</span>String<span class=\"token operator\">></span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Iterator <span class=\"token operator\">&lt;</span>Customer<span class=\"token operator\">></span> iterator <span class=\"token operator\">=</span> customers.iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>例题</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>public class TestGeneric2 <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    public static void main<span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> args<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    //1.HashSet</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    Set<span class=\"token operator\">&lt;</span>Student<span class=\"token operator\">></span> <span class=\"token builtin class-name\">set</span> <span class=\"token operator\">=</span> new HashSet <span class=\"token operator\">&lt;</span> Student<span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    set.add<span class=\"token punctuation\">(</span>new Student<span class=\"token punctuation\">(</span><span class=\"token string\">\"john\"</span>, <span class=\"token number\">12</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    //使用泛型后，下面的语句就会报错</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    //set.add<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    Iterator<span class=\"token operator\">&lt;</span>Student<span class=\"token operator\">></span> iterator <span class=\"token operator\">=</span> set.iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>iterator.hasNext<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        //使用泛型后，快捷键会自动返回Student类型</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        Student student <span class=\"token operator\">=</span> iterator.next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        System.out.println<span class=\"token punctuation\">(</span>student<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    //3.HashMap</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>HashMap<span class=\"token operator\">&lt;</span>String, Student<span class=\"token operator\">></span> hashMap <span class=\"token operator\">=</span> new HashMap <span class=\"token operator\">&lt;</span>String, Student<span class=\"token operator\">></span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> //keyset来遍历</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>class Student <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    public String name<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    public int age<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    public Student<span class=\"token punctuation\">(</span>String name, int age<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        super<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        this.name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        this.age <span class=\"token operator\">=</span> age<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h1 id=\"泛型使用细节\"><a class=\"anchor\" href=\"#泛型使用细节\">#</a> 泛型使用细节</h1>\n<ul>\n<li>泛型的使用形式</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//3.泛型的使用形式</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>ArrayL ist<span class=\"token operator\">&lt;</span>Integer<span class=\"token operator\">></span> List1 <span class=\"token operator\">=</span> new ArrayList<span class=\"token operator\">&lt;</span>Integer<span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>List<span class=\"token operator\">&lt;</span>Integer<span class=\"token operator\">></span> List2 <span class=\"token operator\">=</span> new ArrayList<span class=\"token operator\">&lt;</span>Integer<span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>//在实际开发中，我们往往简写</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>//编译器 会进行类型推断，老师推荐使用下面写法</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>ArrayList<span class=\"token operator\">&lt;</span>Integer<span class=\"token operator\">></span> List3 <span class=\"token operator\">=</span> new ArrayList<span class=\"token operator\">&lt;></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>List<span class=\"token operator\">&lt;</span>Integer<span class=\"token operator\">></span> List4 <span class=\"token operator\">=</span> new ArrayList<span class=\"token operator\">&lt;></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>\n<p>interface List&lt;T&gt;{}，public class HashSet&lt;E&gt;{}.. 等等<br />\n说明: T, E 只能是引用类型<br />\n看看下面语句是否正确？:<br />\nList &lt;Integer&gt; list = new ArrayList &lt;Integer&gt; 0;//OK<br />\nList&lt;int&gt; list2 = new ArrayList &lt;int&gt; ();//NO</p>\n</li>\n<li>\n<p>在指定泛型具体类型后，可以传入该类型或者其子类类型</p>\n</li>\n<li>\n<p>泛型使用形式<br />\n List&lt;Integer&gt; list1 = new ArrayList &lt;Integer&gt; ();<br />\nList&lt;Integer&gt; list2 = new ArrayList&lt; &gt; ();</p>\n</li>\n<li>\n<p>如果我们这样写 List list3 = new ArrayList (); 默认给它的泛型是 [&lt;E&gt; E 就是 Object]// 等价 ArrayL ist&lt;0bject&gt; arrayList = new ArrayList&lt;&gt;() ;</p>\n</li>\n</ul>\n<h1 id=\"自定义泛型类\"><a class=\"anchor\" href=\"#自定义泛型类\">#</a> 自定义泛型类</h1>\n<ul>\n<li>基本语法</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>class类名<span class=\"token operator\">&lt;</span>T, R<span class=\"token punctuation\">..</span><span class=\"token operator\">></span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    成员</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>注意细节</p>\n<ul>\n<li>普通成员可以使用泛型 (属性、方法)</li>\n<li>使用泛型的数组，不能初始化</li>\n<li>静态方法中不能使用类的泛型</li>\n<li>泛型类的类型，是在创建对象时确定的 (因为创建对象时，需要指定确定类型)</li>\n<li>如果在创建对象时，没有指定类型，默认为 Object</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//1. Tiger 后面泛型，所以我们把Tiger 就称为自定义泛型类</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//2，T，R, M泛型的标识符，一般是单个大写字母</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//3. 泛型标识符可以有多个。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>//4.普通成员可以使用泛型<span class=\"token punctuation\">(</span>属性、方法<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>//5. 使用泛型的数组，不能初始化</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>//6.静态方法中不能使用类的泛型</pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>cLass Tiger<span class=\"token operator\">&lt;</span>T,R,M<span class=\"token operator\">></span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    String name<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    R r<span class=\"token punctuation\">;</span> //属性使用到泛型</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    M m<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    T t<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    //因为数组在new不能确定T的类型，就无法在内存开空间</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    T<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> ts <span class=\"token operator\">=</span> new T<span class=\"token punctuation\">[</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>//因为在创建的时候要知道是什么类型，但只有标识符，无法确定类型，所有无法成功创建</pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    public Tiger<span class=\"token punctuation\">(</span>String name, R r, M m, T t<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>//构造器使用泛型</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    this.name <span class=\"token operator\">=</span> name <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    this.r <span class=\"token operator\">=</span> r<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    this.m <span class=\"token operator\">=</span> m<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    this.t <span class=\"token operator\">=</span> t<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    //因为静态是和类相关的，在类加载时，对象还没有创建</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    //所以，如果静态方法和静态属性使用了泛型，JVM就无法完成初始化</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    static R r2<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    public static void m1<span class=\"token punctuation\">(</span>M m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre></pre></td></tr><tr><td data-num=\"29\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>自定义泛型接口</li>\n<li>基本语法</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>interface接口名<span class=\"token operator\">&lt;</span>T, R<span class=\"token punctuation\">..</span><span class=\"token operator\">></span> <span class=\"token punctuation\">&#123;</span> </pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>注意细节</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>接口中，静态成员也不能使用泛型<span class=\"token punctuation\">(</span>这个和泛型类规定一样<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>泛型接口的类型，在继承接口或者实现接口时确定</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>没有指定类型，默认为Object</pre></td></tr></table></figure><ul>\n<li>实例</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//在继承接口指定泛型接口的类型</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>interface IA extends IUsb<span class=\"token operator\">&lt;</span>String, DoubLe<span class=\"token operator\">></span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>//当我们去实现IA接口时，因为IA在继承IUsu接口时，指定了U为String R为Double</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>//, 在实现IUsu接口的方法时，使用String替换U,是DoubLe替换R</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>class AA impLements IA <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    pubTic Double get<span class=\"token punctuation\">(</span>String s<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        <span class=\"token builtin class-name\">return</span> nulL<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    public void hi<span class=\"token punctuation\">(</span>DoubLe aDouble<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    pubLic void run<span class=\"token punctuation\">(</span>DoubLe r1, DoubLe r2, String U1, String u2<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>interface IUsb<span class=\"token operator\">&lt;</span>U, R<span class=\"token operator\">></span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    int n <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    //U name<span class=\"token punctuation\">;</span>不能这样使用,接口中默认为静态</pre></td></tr><tr><td data-num=\"29\"></td><td><pre></pre></td></tr><tr><td data-num=\"30\"></td><td><pre></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    //普通方法中，可以使用接口泛型</pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    R get<span class=\"token punctuation\">(</span>U u<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    void hi<span class=\"token punctuation\">(</span>R r<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>    void run<span class=\"token punctuation\">(</span>R r1, R r2,U U1, U U2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>    //在jdk8中，可以在接口中，使用默认方法</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>    default R method<span class=\"token punctuation\">(</span>U u<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        <span class=\"token builtin class-name\">return</span> nuLL<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>//没有指定类型，默认为0bject</pre></td></tr><tr><td data-num=\"43\"></td><td><pre>cLass CC implements IUsb <span class=\"token punctuation\">&#123;</span> //等价cLass CC impLements IUsb<span class=\"token operator\">&lt;</span>Object ，Object<span class=\"token operator\">></span> </pre></td></tr><tr><td data-num=\"44\"></td><td><pre></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>    pubLic object get<span class=\"token punctuation\">(</span>Object o<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>    <span class=\"token builtin class-name\">return</span> null<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>    pubLic void hi<span class=\"token punctuation\">(</span>0bject o<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>    public void run<span class=\"token punctuation\">(</span>0bject r1, object r2， Object u1, Object u2<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h1 id=\"自定义泛型方法\"><a class=\"anchor\" href=\"#自定义泛型方法\">#</a> 自定义泛型方法</h1>\n<ul>\n<li>基本语法</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>修饰符<span class=\"token operator\">&lt;</span>T,R<span class=\"token punctuation\">..</span><span class=\"token operator\">></span>返回类型方法名<span class=\"token punctuation\">(</span>参数列表<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>注意细节</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>泛型方法，可以定义在普通类中，也可以定义在泛型类中</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token number\">2</span>.当泛型方法被调用时，类型会确定</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token number\">3</span>. public void eat<span class=\"token punctuation\">(</span>E e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span>,修饰符后没有<span class=\"token operator\">&lt;</span>T,R<span class=\"token punctuation\">..</span><span class=\"token operator\">></span> eat</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>方法不是泛型方法，而是使用了泛型</pre></td></tr></table></figure><ul>\n<li>实例</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Car car <span class=\"token operator\">=</span> new Car<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>car.fly<span class=\"token punctuation\">(</span><span class=\"token string\">\"宝马\"</span>，100<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//当调用方法时，传入参数，编译器，就会确定类型</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>//泛型方法，可以定义在普通类中，也可以定义在泛型类中</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>cLass Car <span class=\"token punctuation\">&#123;</span>//普通类</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    pubLic void <span class=\"token function-name function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>//普通方法</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    //说明泛型方法</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    //1. <span class=\"token operator\">&lt;</span>T,R<span class=\"token operator\">></span> 就是泛型</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    //2. 是提供给fly使用的</pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    public <span class=\"token operator\">&lt;</span>T, R<span class=\"token operator\">></span> void fly<span class=\"token punctuation\">(</span>T t, R r<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>//泛型方法</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>//说明</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>//1. 下面hi方法不是泛型方法</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>//2.是hi方法使用了类声明的泛型</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>pubLic void hi<span class=\"token punctuation\">(</span>T t<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>//泛型方法，可以使用类声明的泛型，也可以使用自己声明泛型</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>pubLic<span class=\"token operator\">&lt;</span>K<span class=\"token operator\">></span> void heLlo<span class=\"token punctuation\">(</span>R r,K k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    System. out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span>r.getClass<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    System <span class=\"token builtin class-name\">.</span> out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span>k .getCLass<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h1 id=\"泛型的继承和通配符\"><a class=\"anchor\" href=\"#泛型的继承和通配符\">#</a> 泛型的继承和通配符</h1>\n<ul>\n<li>泛型不具备继承性<br />\n List &lt;Object&gt; list = new ArrayList&lt;String&gt;(); // 是错误的</li>\n<li>&lt;?&gt; : 支持任意泛型类型</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//说明: List<span class=\"token operator\">&lt;</span>?<span class=\"token operator\">></span> 表示任意的泛型类型都可以接受</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>public static void printCollection1<span class=\"token punctuation\">(</span>List<span class=\"token operator\">&lt;</span>?<span class=\"token operator\">></span> c<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>0bject object <span class=\"token builtin class-name\">:</span> c<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span> //通配符，取出时，就是0bject</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        System <span class=\"token builtin class-name\">.</span> out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>&lt;? extends A&gt;: 支持 A 类以及 A 类的子类，规定了泛型的上限</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>// ? extends AA表示上限，可以接受AA或者AA子类</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>pubLic static void printColLection2<span class=\"token punctuation\">(</span>List<span class=\"token operator\">&lt;</span>? extends AA c<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>0bject object <span class=\"token builtin class-name\">:</span> c<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        System <span class=\"token builtin class-name\">.</span> out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>&lt;? super A&gt;: 支持 A 类以及 A 类的父类，不限于直接父类，规定了泛型的下限</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>// ? super 子类类名AA:支持AA类及AA类的父类，不限于直接父类，</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//规定了泛型的下限</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>public static void printCollection3<span class=\"token punctuation\">(</span>List<span class=\"token operator\">&lt;</span>? super AA<span class=\"token operator\">></span> c<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Object object <span class=\"token builtin class-name\">:</span> c<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        System.out.printLn<span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h1 id=\"junit\"><a class=\"anchor\" href=\"#junit\">#</a> JUnit</h1>\n<ul>\n<li>在方法前加上 @Test 可直接运行该方法</li>\n</ul>\n",
            "tags": [
                "学习Java",
                "Java基础",
                "java"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/08/ai/Andrew%20Ng%20Lesson/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8%E5%BB%BA%E8%AE%AE/",
            "url": "https://love.youhuamao.xyz/2022/11/08/ai/Andrew%20Ng%20Lesson/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8%E5%BB%BA%E8%AE%AE/",
            "title": "机器学习应用",
            "date_published": "2022-11-07T16:00:00.000Z",
            "content_html": "<h1 id=\"如何调试一个机器学习算法\"><a class=\"anchor\" href=\"#如何调试一个机器学习算法\">#</a> 如何调试一个机器学习算法</h1>\n<p>有多种方案：</p>\n<p>1、获得更多训练数据；2、尝试更少特征；3、尝试更多特征；4、尝试添加多项式特征；5、减小 λ；6、增大 λ<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-01.png\" alt=\"img.png\" /><br />\n 为了避免一个方案一个方案的尝试，可以通过评估机器学习算法的性能，来进行调试。</p>\n<p>机器学习诊断法 Machine learning diagnostic 的定义：<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-02.png\" alt=\"img.png\" /></p>\n<h1 id=\"评估一个假设\"><a class=\"anchor\" href=\"#评估一个假设\">#</a> 评估一个假设</h1>\n<p>想要评估一个算法是否过拟合<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-03.png\" alt=\"img.png\" /></p>\n<p>（一）首先，划分测试集和训练集<br />\n如果数据已经随机分布了， 可以选择前 70% 数据作为训练集，剩下的 30% 作为测试集；<br />\n如果数据不是随机分布的，最好先打乱，或者随机选择 70% 数据作为训练集，剩下的 30% 作为测试集<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-04.png\" alt=\"img.png\" /></p>\n<p>（二）然后，计算测试误差<br />\n 1、对于回归问题。例如线性回归。首先使用训练集进行训练，然后使用测试集计算测试误差：<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-05.png\" alt=\"img.png\" /><br />\n2、对于分类问题。例如逻辑回归，也是一样的：<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-06.png\" alt=\"img.png\" /><br />\n 有一种更易理解的测试误差定义方式，叫做 错分率 Misclassification error (也叫 0/1 错分率)：<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-07.png\" alt=\"img.png\" /><br />\nerr (hθ(x),y) 的意思是：如果分类预测结果 hθ(x) 错误，则 err 值为 1；如果 hθ(x) 预测正确，则 err 值为 0。   整体的测试误差就是所有 err 值的加和。</p>\n<h1 id=\"模型选择-和-训练验证测试集\"><a class=\"anchor\" href=\"#模型选择-和-训练验证测试集\">#</a> 模型选择 和 &quot;训练 / 验证 / 测试&quot; 集</h1>\n<p>产生过拟合的一个原因是：仅仅在测试集合上调试 θ 得到的训练误差，通常不能作为对实际泛化误差的一个好的估测。<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-08.png\" alt=\"img.png\" /></p>\n<p>那么究竟应该选择几次多项式来作为我们的模型呢？<br />\n假设针对 x 有 10 个模型：一次方程 直到 十次方程。对每个多项式，在训练集上训练出 θ 。然后分别使用 test 集合计算误差，分别得到 Jtest (θ(1)),...Jtest (θ(10))，发现 Jtest (θ(5)) 的值最小，因此选择 d=5 这个模型。<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-09.png\" alt=\"img.png\" /></p>\n<p>但这里有个问题：我们选的这个模型，就是能够最好地拟合测试集的参数 d 的值及多项式的度。因此，再使用同样的测试集来评价假设，显然很不公平，很可能导致过拟合。<br />\n所以，我们改为将数据集分为 6:2:2 三部分：training set、cross validation set (cv, 或者直接简称 validation set)、test set<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-10.png\" alt=\"img.png\" /><br />\n 每个集合上的误差计算公式：<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-11.png\" alt=\"img.png\" /></p>\n<p>现在我们是用 cv 集合计算误差，分别得到 Jcv (θ(1)),...Jcv (θ(10))，发现 Jcv (θ(4)) 的值最小，因此选择 d=4 这个模型，最后在 test 集合上进行预测，能得到一个更理想的泛化误差。<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-12.png\" alt=\"img.png\" /></p>\n<h1 id=\"检验误差和方差-diagnosing-bias-vs-variance\"><a class=\"anchor\" href=\"#检验误差和方差-diagnosing-bias-vs-variance\">#</a> 检验误差和方差 Diagnosing bias vs. variance</h1>\n<p>模型表现不好，通常有两种情况：<br />\n(1) 误差 bias 过大，导致欠拟合 underfitting；<br />\n(2) 方差 variance 过大，导致过拟合 overfitting<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-13.png\" alt=\"img.png\" /></p>\n<p>使用多项式的度 d 作为横轴，在训练集和 cv 集上分别计算 J (θ)，得到曲线：<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-14.png\" alt=\"img.png\" /></p>\n<p>下面说如何根据两条曲线判断模型是高误差 (欠拟合)、还是高方差 (过拟合)。<br />\n(1) 先看曲线左边，当 d=1 ，训练集和 cv 集的误差都很大，说明欠拟合<br />\n (2) 再看曲线右边，当 d=4 ，训练集误差很小、cv 集误差远大于训练误差，说明在训练集上过拟合<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-15.png\" alt=\"img.png\" /></p>\n<h1 id=\"正规化-和-偏差方差\"><a class=\"anchor\" href=\"#正规化-和-偏差方差\">#</a> 正规化 和 偏差 / 方差</h1>\n<p>考虑正则化的线性回归模型：<br />\n(1) 当 λ 过大，θ 被惩罚后会变得很小、接近于 0，最后方程只剩下 θ0 这一项，成为一条直线，导致高偏差 bias、欠拟合。<br />\n(2) 当 λ 过小，正则项不起作用，导致高方差 variance、过拟合。<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-16.png\" alt=\"img.png\" /></p>\n<p>那怎么选择 λ 的值呢？<br />\n首先，当我们定义每个集合上的误差函数时，不考虑 λ。<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-17.png\" alt=\"img.png\" /></p>\n<p>然后按照步长两倍的方式递增 λ，针对每个 λ 训练 θ。然后分别计算对应的 Jcv (θ)，得到最小的 Jcv (θ(5))。然后在 test 集合上进行测试。<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-18.png\" alt=\"img.png\" /></p>\n<p>现在我们看一下，λ 的大小对损失函数的影响。<br />\n(1) 先看曲线左边，当 λ 很小 ，Jcv (θ) 的值远大于 Jtrain (θ)，说明过拟合<br />\n (2) 再看曲线右边，当 λ 很大 ，Jcv (θ) 和 Jtrain (θ) 都很大，说明欠拟合<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-18.png\" alt=\"img.png\" /></p>\n<h1 id=\"学习曲线\"><a class=\"anchor\" href=\"#学习曲线\">#</a> 学习曲线</h1>\n<p>m 指训练样本的个数，曲线显示不同的 m 对于 J (θ) 的影响<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-19.png\" alt=\"img.png\" /></p>\n<p>高偏差 bias、欠拟合：<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-20.png\" alt=\"img.png\" /></p>\n<p>高方差 variance、过拟合。两个曲线会有一个很大的 gap：<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-21.png\" alt=\"img.png\" /></p>\n<h1 id=\"接下来\"><a class=\"anchor\" href=\"#接下来\">#</a> 接下来</h1>\n<p>每种解决方案对应的问题如下（箭头右侧指向的是表现出的问题，左侧是解决方案）：<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-22.png\" alt=\"img.png\" /></p>\n<p>对于神经网络，开始可以尝试一个相对比较简单的神经网络模型，计算量小。<br />\n如果使用大型神经网络，使用正则化来修正过拟合。<br />\n如果不知道选择几层 hidden layer，可以将数据分为三个数据集之后，分别做测试。<br />\n<img data-src=\"/pic/wuenda/jiqixuexiyingyong-23.png\" alt=\"img.png\" /></p>\n<h1 id=\"附\"><a class=\"anchor\" href=\"#附\">#</a> 附</h1>\n<p>关于偏差和方差的解释，参考：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA2MjY5MzcvYXJ0aWNsZS9kZXRhaWxzLzc0NDM1MTA5\">https://blog.csdn.net/u010626937/article/details/74435109</span></p>\n<ul>\n<li>\n<p>偏差：描述的是预测值的期望与真实值之间的差距。偏差越大，越偏离真实数据集。（Ps: 假设靶心是最适合给定数据的模型，离靶心越远，我们的预测就越糟糕）</p>\n</li>\n<li>\n<p>方差：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，预测结果数据的分布越散。</p>\n</li>\n<li>\n<p>基于偏差的误差：所谓基于偏差的误差是我们模型预期的预测与我们将要预测的真实值之间的差值。偏差是用来衡量我们的模型的预测同真实值的差异。</p>\n</li>\n<li>\n<p>基于方差的误差：基于方差的误差描述了一个模型对给定的数据进行预测的可变性。比如，当你多次重复构建完整模型的进程时，方差是在预测模型的不同关系间变化的多少。</p>\n</li>\n<li>\n<p><img data-src=\"/pic/wuenda/jiqixuexiyingyong-24.png\" alt=\"img.png\" /></p>\n</li>\n</ul>\n<p>左上：低偏差 bias，低方差 variance。预测结果准确率很高，并且模型比较健壮（稳定），预测结果高度集中。<br />\n右上：低偏差 bias，高方差 variance。预测结果准确率较高，但是模型不稳定，预测结果比较发散。<br />\n左下：高偏差 bias，低方差 variance。预测结果准确率较低，但是模型稳定，预测结果比较集中。<br />\n右下：高偏差 bias，高方差 variance。预测结果准确率较低，并且模型不稳定，预测结果比较发散。</p>\n",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/07/ai/Andrew%20Ng%20Lesson/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/",
            "url": "https://love.youhuamao.xyz/2022/11/07/ai/Andrew%20Ng%20Lesson/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/",
            "title": "神经网络的表述 Neural Networks Representation",
            "date_published": "2022-11-06T16:00:00.000Z",
            "content_html": "<h1 id=\"代价函数-cost-function\"><a class=\"anchor\" href=\"#代价函数-cost-function\">#</a> 代价函数 Cost Function</h1>\n<p>假设神经网络的训练样本有𝑚个，每个包含一组输入 𝑥 和一组输出信号 𝑦，𝐿 表示神经网络层数，𝑆𝐼表示每层神经元的个数 (𝑆𝑙 表示输出层神经元个数)，𝑆𝐿代表最后一层中处理单元的个数。<br />\n　　神经网络分类分两种：<br />\n　　（1）二类分类： <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>𝑆</mi><mi>𝐿</mi></msub></mrow><annotation encoding=\"application/x-tex\">𝑆_{𝐿}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">L</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>  = 0, 𝑦 = 0 𝑜𝑟 1 表示哪一类；<br />\n　　（2）𝐾类分类： <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>𝑆</mi><mi>𝐿</mi></msub></mrow><annotation encoding=\"application/x-tex\">𝑆_{𝐿}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">L</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>  = 𝑘, 𝑦𝑖 = 1 表示分到第 i 类；(𝑘&gt; 2)<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-01.png\" alt=\"img.png\" /></p>\n<p>之前定义逻辑回归的 Cost Function 如下（前半部分表示 hypothesis 与真实值之间的距离，后半部分是对参数进行 regularization 的 bias 项）：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-02.png\" alt=\"img.png\" /><br />\n 神经网络的 cost function 同理：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-03.png\" alt=\"img.png\" /><br />\n 原理都是希望得到预测结果与真实情况的误差。不同的是结果有 k 个。hypothesis 与真实值之间的距离为 每个样本 — 每个个类输出的加和。</p>\n<p>对参数进行 regularization 的 bias 项是排除了每一层𝜃0 后，每一层的 𝜃 矩阵平方和。即所有参数的平方和。</p>\n<h1 id=\"反向传播算法\"><a class=\"anchor\" href=\"#反向传播算法\">#</a> 反向传播算法</h1>\n<p>为了最小化 J (Θ)，需要求偏导。<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-04.png\" alt=\"img.png\" /></p>\n<p>采用一种反向传播算法：首先计算最后一层（最右）的误差，然后再反向（向左）求出各层的误差，直到倒数第二层（第一层是输入变量，不存在误差）。<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-05.png\" alt=\"img.png\" /><br />\n（1）最后一层误差是激活单元的预测 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>a</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mn>4</mn><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><annotation encoding=\"application/x-tex\">a_{j}^{(4)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.4577719999999998em;vertical-align:-0.4129719999999999em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">4</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4129719999999999em;\"><span></span></span></span></span></span></span></span></span></span> 与实际值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>𝑦</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">𝑦_{j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 之间的误差（ j = 1:𝑘），设其为 𝛿_{j}^{(4)}<br />\n𝛿^{(4)} = a^{(4)} - y<br />\n（2）计算第三层的误差：<br />\n𝛿^{(3)} = (θ^(3))^{T}𝛿^{(4)} * 𝑔′(z^(3))<br />\n 其中 (θ<sup>(3))</sup><ruby>T}𝛿<rp>(</rp><rt>{(4)</rt><rp>)</rp></ruby> 则是权重导致的误差的和， 𝑔′(𝑧(3)) 是 sigmoid 函数的导数，sigmoid 函数导数有一个特点：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>𝑔</mi><mtext>′</mtext><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo><mo>=</mo><msup><mi>a</mi><mrow><mo stretchy=\"false\">(</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo>∗</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msup><mi>a</mi><mo stretchy=\"false\">(</mo></msup><mn>3</mn><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">𝑔′(z^{(3)}) = a^{(3)} * (1-a^(3))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord\">′</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">3</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">3</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mopen mtight\">(</span></span></span></span></span></span></span></span><span class=\"mord\">3</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span></p>\n<p>（3）计算第二层的误差：<br />\n𝛿^{(2)} = (θ^(2))^{T}𝛿^{(3)} * 𝑔′(z^(2))</p>\n<p>(4) 有了误差，开始计算代价函数的偏导。假设 𝜆=0（即不做任何正则化处理），有：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-06.png\" alt=\"img.png\" /><br />\n　𝑙 ：目前所计算的是第几层。<br />\n　𝑗 ：目前层中的激活单元下标（下一层的第 j 个输入变量的下标）<br />\n　𝑖 ：下一层中误差单元的下标（受到权重矩阵中第 𝑖 行影响的下一层中误差的下标）</p>\n<p>上面得到了 error 变量 δ 的计算，下面来看 backpropagation 算法的伪代码 ：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-07.png\" alt=\"img.png\" /></p>\n<p>然后计算代价函数的偏导数，公式如下：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-08.png\" alt=\"img.png\" /></p>\n<h1 id=\"反向传播算法的直观理解\"><a class=\"anchor\" href=\"#反向传播算法的直观理解\">#</a> 反向传播算法的直观理解</h1>\n<p>现在说反向传播模型的学习过程。<br />\n首先，前向传播算法 forward propagation 从前往后计算 z (j),a (j) 的过程如下：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-09.png\" alt=\"img.png\" /></p>\n<p>然后将原 cost function 进行简化，去掉 regularization 项，得到 cost (i)：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-10.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-11.png\" alt=\"img.png\" /></p>\n<p>即对于每一层来说，δ 分量都等于后面一层所有的 δ 的加权和，其中权值就是参数 θ：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-12.png\" alt=\"img.png\" /></p>\n<h1 id=\"实现注意展开参数\"><a class=\"anchor\" href=\"#实现注意展开参数\">#</a> 实现注意：展开参数</h1>\n<p>在 Octave 中，如果要使用 fminc 这样的优化算法来求解权重矩阵，需要将矩阵展开成为向量，再利用算法求出最优解后再重新转回矩阵。<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-13.png\" alt=\"img.png\" /></p>\n<p>假设有三个权重矩阵：Theta1,Theta2,Theta3 。下面是将其向量化 unroll into vector，再变回矩阵的方法<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-14.png\" alt=\"img.png\" /></p>\n<p>实现代码</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span> Theta1 <span class=\"token operator\">=</span> ones<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">11</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token operator\">>></span> Theta2 <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token operator\">*</span>ones<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">11</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token operator\">>></span> Theta3 <span class=\"token operator\">=</span> <span class=\"token number\">3</span><span class=\"token operator\">*</span>ones<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">11</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>转换成向量</pre></td></tr><tr><td data-num=\"29\"></td><td><pre><span class=\"token operator\">>></span> thetaVec <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>Theta1<span class=\"token punctuation\">(</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>Theta2<span class=\"token punctuation\">(</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>Theta3<span class=\"token punctuation\">(</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token operator\">>></span> size<span class=\"token punctuation\">(</span>thetaVec<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>   <span class=\"token number\">231</span>     <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>转回矩阵：</pre></td></tr><tr><td data-num=\"34\"></td><td><pre><span class=\"token operator\">>></span> reshape<span class=\"token punctuation\">(</span>thetaVec<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token number\">110</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">11</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span>   <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre></pre></td></tr><tr><td data-num=\"46\"></td><td><pre><span class=\"token operator\">>></span> reshape<span class=\"token punctuation\">(</span>thetaVec<span class=\"token punctuation\">(</span><span class=\"token number\">111</span><span class=\"token punctuation\">:</span><span class=\"token number\">220</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">11</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span>   <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre><span class=\"token operator\">>></span> reshape<span class=\"token punctuation\">(</span>thetaVec<span class=\"token punctuation\">(</span><span class=\"token number\">221</span><span class=\"token punctuation\">:</span><span class=\"token number\">231</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">11</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span>   <span class=\"token number\">3</span></pre></td></tr></table></figure><h1 id=\"梯度检验\"><a class=\"anchor\" href=\"#梯度检验\">#</a> 梯度检验</h1>\n<p>为了验证复杂模型内部是否呀运行正常，我们是用一种叫做 Numerical gradient checking 的方法来验证梯度是否在下降。</p>\n<p>对于下面这个 J (θ) 图，取 θ 点左右各一点（θ+ε）,（θ-ε），则点 θ 的导数（梯度）近似等于 (J (Θ+ε)-J (θ-ε))/(2ε)。<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-15.png\" alt=\"img.png\" /></p>\n<p>因此，针对每个 θ，其导数都可以近似为：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-16.png\" alt=\"img.png\" /></p>\n<p>将这个近似值，与 back-propagation 算法中每一步得到的 J (θ) 的导数 D（derivative）进行比较。如果这两个结果相近，则 code 正确，否则错误。上面描述的算法如下：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-17.png\" alt=\"img.png\" /></p>\n<p>步骤：</p>\n<ul>\n<li>在 back propagation 中计算出 J (θ) 对 θ 的导数 D，并向量化成 Dvec (unroll D (1),D (2),D (3))</li>\n<li>用 numerical gradient check 方法计算梯度近似值 gradApprox</li>\n<li>确保这两个值很接近<br />\n -（这一点非常重要）只在测试的时候进行校验。真正使用 back propagation 进行神经网络学习的时候，要停止校验，否则会非常慢</li>\n</ul>\n<h1 id=\"随机初始化\"><a class=\"anchor\" href=\"#随机初始化\">#</a> 随机初始化</h1>\n<p>之前对于逻辑回归，我们将参数 θ 全部初始化为 0。 然而对于神经网络，此方法不可行： 如果第一层参数 θ 都相同 (不管是不是 0)，意味着第二层的所有激活单元的值会完全相同。</p>\n<p>注：这里考了几道选择题。<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-18.png\" alt=\"img.png\" /></p>\n<p>通常初始参数为正负 ε 之间的随机值，代码如下：<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-19.png\" alt=\"img.png\" /></p>\n<h1 id=\"综合起来\"><a class=\"anchor\" href=\"#综合起来\">#</a> 综合起来</h1>\n<p>选择神经网络。通常情况下隐藏层神经单元的个数越多越好。<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-20.png\" alt=\"img.png\" /></p>\n<p>训练神经网络：</p>\n<ol>\n<li>参数的随机初始化</li>\n<li>利用正向传播方法计算所有的  ℎ𝜃(𝑥)</li>\n<li>编写计算代价函数  𝐽 的代码</li>\n<li>利用反向传播方法计算所有偏导数</li>\n<li>利用数值检验方法这些偏导</li>\n<li>使用优化算法来最小代价函数</li>\n</ol>\n<p><img data-src=\"/pic/wuenda/shenjingwangluoxuexi-21.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-22.png\" alt=\"img.png\" /></p>\n<p>神经网络的直观表示如下。因为 J (𝜃) 不是一个凸函数，因此我们可以到达一个局部最小点。<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-23.png\" alt=\"img.png\" /></p>\n<h1 id=\"自主驾驶\"><a class=\"anchor\" href=\"#自主驾驶\">#</a> 自主驾驶</h1>\n<p>ALVINN (Autonomous Land Vehicle In a Neural Network) 是一个基于神经网络的智能系统<br />\n<img data-src=\"/pic/wuenda/shenjingwangluoxuexi-24.png\" alt=\"img.png\" /></p>\n<p>神经网络过拟合有两种情况，可以通过两种方式解决：<br />\n（1）引入 Validate 数据集<br />\n（2）规则化</p>\n<p>加入规则化因子之后，整个模型其实是奔着选取较小的 w 而进化的，因为如果需要损失函数值小的话，一旦选取了比较大的 w，那么只有等式右边第一项式子的值比较小的情况下才行，因此规则化的目的其实是减轻比较大的 w 值对损失函数的影响，为什么需要这么做，我们假设对于线性回归而言，有一个数据特别偏离主模型，这样的话，往往会导致模型受这个影响比较大，从而偏离主模型，这时候就需要抵消这个数据对结果的影响，这就用到了规范化，目的是消除其某些损失函数值过大的点影响，对于神经网络，正则化的目的是为了消除太大的 w 对结果的影响，其结果就是局部的变化因素（个别 w 的变化）不会影响整个模型的数据，只有对全部模型起变化的因素才能影响到模型的建立，这样就消除了局部噪声的影响。</p>\n",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/06/ai/Andrew%20Ng%20Lesson/%E6%AD%A3%E5%88%99%E5%8C%96/",
            "url": "https://love.youhuamao.xyz/2022/11/06/ai/Andrew%20Ng%20Lesson/%E6%AD%A3%E5%88%99%E5%8C%96/",
            "title": "正则化 Regularization",
            "date_published": "2022-11-05T16:00:00.000Z",
            "content_html": "<h1 id=\"过拟合问题-the-problem-of-overfitting\"><a class=\"anchor\" href=\"#过拟合问题-the-problem-of-overfitting\">#</a> 过拟合问题 The Problem of Overfitting</h1>\n<ul>\n<li>欠拟合 / 高偏差  underfitting 预测不准确</li>\n<li>刚好　　          just right</li>\n<li>过拟合 / 高方差  overfitting   泛化能力差（为了符合数据集，用高阶多项式使用过多的 x，即特征来契合这些点）<br />\n回归问题：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-01.png\" alt=\"img.png\" /></li>\n</ul>\n<p>分类问题：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-02.png\" alt=\"img.png\" /></p>\n<p>解决方法：<br />\n（1）减少 feature（特征） 的个数:<br />\nManually select which features to keep.<br />\nUse a model selection algorithm .</p>\n<p>（2）正则化：<br />\nKeep all the features, but reduce the magnitude of parameters.<br />\nRegularization works well when we have a lot of slightly useful features.</p>\n<h1 id=\"代价函数-cost-function\"><a class=\"anchor\" href=\"#代价函数-cost-function\">#</a> 代价函数 Cost Function</h1>\n<p 4=\"\">如果线性回归出现过拟合，曲线方程如下：<br />\nΘ_{0}+Θ_{1}x+Θ_{2}x^{2}+Θ_{3}x^{3}+Θ_{4}x^</p>\n<p>如果想消除高次幂项的影响，可以修改代价函数 ，在某些参数上设置一些惩罚，一定程度上减小这些参数的影响:<br />\n<img data-src=\"/pic/wuenda/zhengzehua-03.png\" alt=\"img.png\" /></p>\n<p>要使代价函数趋于 0，则需降低 θ3 和 θ4 的值，因为二次项≥0，所以令它们为 0 时代价函数最小，降低了他们在 hypothesis function 的影响，从而减少了过拟合。这就是正则化的思想。<br />\n<img data-src=\"/pic/wuenda/zhengzehua-04.png\" alt=\"img.png\" /></p>\n<p>实际使用中，因为不知道具体应该惩罚那些参数。所以给所有参数都加一个系数 λ：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-05.png\" alt=\"img.png\" /></p>\n<p>λ or lambda 叫做 regularization parameter，加号后面这一项叫做 regularization term。<br />\n　1 如果 λ = 0 或者特别小，起不到作用，仍然过拟合。<br />\n　1 如果 λ 选的太大，所有参数都遭到惩罚。最后假设方程可能变成 h (x) = <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_{0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，导致欠拟合 underfitting。</p>\n<h1 id=\"正则化线性回归-regularized-linear-regression\"><a class=\"anchor\" href=\"#正则化线性回归-regularized-linear-regression\">#</a> 正则化线性回归  Regularized Linear Regression</h1>\n<p>正则化线性回归的代价函数为：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-06.png\" alt=\"img.png\" /></p>\n<p>因为正则化不涉及到 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_{0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，梯度下降算法如下：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-07.png\" alt=\"img.png\" /></p>\n<p>对上面的算法第二个式子调整可得<br />\n<img data-src=\"/pic/wuenda/zhengzehua-08.png\" alt=\"img.png\" />( j ∈ 1,2 ... n)<br />\n 正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令 θ 减少了一个额外的值。</p>\n<p>如果使用正规方程 Normal Equation 方法，引入一个 (n+1)×(n+1) 维的方阵 L，正则化如下：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-09.png\" alt=\"img.png\" /><br />\n　注：当 m &lt; n 时，是个奇异矩阵（退化矩阵）。</p>\n<h1 id=\"正则化的逻辑回归模型-regularized-logistic-regression\"><a class=\"anchor\" href=\"#正则化的逻辑回归模型-regularized-logistic-regression\">#</a> 正则化的逻辑回归模型 Regularized Logistic Regression</h1>\n<p>逻辑回归的代价函数为：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-10.png\" alt=\"img.png\" /><br />\n 加上正则项之后：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-11.png\" alt=\"img.png\" /><br />\n 注：这个代价函数看上去同正则化线性回归的式子一样，但是两个 ℎ 不同，所以有很大差别。<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_{0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 不参与任何正则化</p>\n<p>效果（蓝色线是正则化之前，粉色线是正则化之后）：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-12.png\" alt=\"img.png\" /></p>\n<p>仍然可以用 fminuc 函数来求解代价函数最小化的参数 ，但我们实现的 costFunction 函数中进行了正则化：<br />\n<img data-src=\"/pic/wuenda/zhengzehua-13.png\" alt=\"img.png\" /></p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span> <span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"2\"></td><td><pre> <span class=\"token number\">2</span> <span class=\"token keyword\">def</span> <span class=\"token function\">costReg</span><span class=\"token punctuation\">(</span>theta<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> learningRate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre> <span class=\"token number\">3</span>     theta <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>matrix<span class=\"token punctuation\">(</span>theta<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre> <span class=\"token number\">4</span>     X <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>matrix<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre> <span class=\"token number\">5</span>     y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>matrix<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre> <span class=\"token number\">6</span>     first <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>multiply<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>y<span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>sigmoid<span class=\"token punctuation\">(</span>X<span class=\"token operator\">*</span>theta<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre> <span class=\"token number\">7</span>     second <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>multiply<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token operator\">-</span> y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token operator\">-</span> sigmoid<span class=\"token punctuation\">(</span>X<span class=\"token operator\">*</span>theta<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre> <span class=\"token number\">8</span>     reg <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>learningRate <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span> <span class=\"token operator\">*</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>power<span class=\"token punctuation\">(</span>theta<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span>the</pre></td></tr><tr><td data-num=\"9\"></td><td><pre> <span class=\"token number\">9</span> ta<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token number\">10</span>     <span class=\"token keyword\">return</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>first <span class=\"token operator\">-</span> second<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> reg</pre></td></tr></table></figure><h1 id=\"术语\"><a class=\"anchor\" href=\"#术语\">#</a> 术语</h1>\n<p>···bash<br />\ndecision boundary 决策边界<br />\n loophole　漏洞<br />\n nonlinear 非线性<br />\n penalize the parameter  惩罚参数<br />\n regularization term 正则项<br />\n regularization parameter 正则化参数<br />\n wiggly/curvy 摆动的 弯曲的<br />\n optimization objective 优化目标<br />\n lamda  即 λ<br />\nshrinking  收缩<br />\n magnitude  量级，重要性<br />\n・・・</p>\n",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/06/ai/Andrew%20Ng%20Lesson/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%A1%A8%E8%BF%B0/",
            "url": "https://love.youhuamao.xyz/2022/11/06/ai/Andrew%20Ng%20Lesson/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%A1%A8%E8%BF%B0/",
            "title": "神经网络的表述 Neural Networks Representation",
            "date_published": "2022-11-05T16:00:00.000Z",
            "content_html": "<p>神经网络是一种受大脑工作原理启发的模式。 它在许多应用中广泛使用：当您的手机解释并理解您的语音命令时，很可能是神经网络正在帮助理解您的语音；当您兑现支票时，自动读取数字的机器也使用神经网络。</p>\n<h1 id=\"非线性假设-non-linear-classification\"><a class=\"anchor\" href=\"#非线性假设-non-linear-classification\">#</a> 非线性假设 Non-linear Classification</h1>\n<p>线性回归和逻辑回归的缺点： 当输入数据特征过多，计算负荷大。<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-01.png\" alt=\"img.png\" /></p>\n<p>计算机视觉中，图片的表示是通过像素矩阵表示的。假设一个图片是 50×50px，其特征数为 2500（灰度图，如果是 RGB 图则为 7500）。如果两两特征组合将达到百万级别（从 2500 里选两个组合，2500 * 2499 / 2 ≈ 3 * 10^6），逻辑回归将无法适用。<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-02.png\" alt=\"img.png\" /></p>\n<h1 id=\"神经元与大脑\"><a class=\"anchor\" href=\"#神经元与大脑\">#</a> 神经元与大脑</h1>\n<p>大脑好神奇，找到触觉的那块区域，把眼睛连接上，能根据看到的感到触觉，青蛙接种第三只眼，也能学会使用第三只眼</p>\n<h1 id=\"模型表示1\"><a class=\"anchor\" href=\"#模型表示1\">#</a> 模型表示 1</h1>\n<p>为模仿大脑的工作方式，神经网络可以类似的分为：输入的数据特征，中间的数据处理层，最后的输出。</p>\n<p>神经网络模型建立在很多神经元之上，每一个都是一个学习模型。这些神经元（也叫激活单元，activation unit）采纳一些特征，并且根据本身的模型提供一个输出。<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-03.png\" alt=\"img.png\" /></p>\n<p>下图是一个以逻辑回归模型作为自身学习模型的神经元示例。参数 θ 也可以称为权重 weights。<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-04.png\" alt=\"img.png\" /></p>\n<p>神经网络模型是许多逻辑单元按照不同层级组织起来的，每一输出变量都是下一层的输入变量。</p>\n<p>逻辑单元：输入向量 x（input layer），中间层 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>a</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><annotation encoding=\"application/x-tex\">a_{i}^{(j)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.321664em;vertical-align:-0.27686399999999994em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span></span></span></span>（hidden layer）, 输出层 h (x)（output layer）。<br />\n每一层的输入都可以增加一个偏执单元  bias unit，通常取值为 1。<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-05.png\" alt=\"img.png\" /></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>a</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><annotation encoding=\"application/x-tex\">a_{i}^{(j)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.321664em;vertical-align:-0.27686399999999994em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span></span></span></span>  是第 j 层的第 i 个激活结点（activation units）。j 表示是第几层，i 表示从上到下第几个元素。<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>θ</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">θ^{(j)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span>   是将第 j 层映射到 j+1 层的权重矩阵<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-06.png\" alt=\"img.png\" /></p>\n<ul>\n<li>θ 的维度</li>\n</ul>\n<p>如果网络在第 j 层有 Sj 个单元（加上偏执单元），在 j+1 层有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>S</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">S_{j+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 个单元（不算偏执单元），<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>θ</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">θ^{(j)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 的维度将是  <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>S</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>X</mi><mo stretchy=\"false\">(</mo><msub><mi>S</mi><mi>j</mi></msub><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">S_{j+1} X (S_{j}+1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span>。如上面的例子，theta1=3×4，theta2=1×4。</p>\n<p>注：很重要，容易搞反。row 为下一层单元数，column 数为当前层单元数 + 1。</p>\n<p>神经网络中，从上到下的每个原点是 feature 特征 x0, x1, x2...。不是实例。它做的事情其实就是 feature 映射的过程，一层转换之后，feature 可能变多、也可能变少。下一层 feature 的个数是通过权重矩阵 θ 的 row 来控制。</p>\n<h1 id=\"模型表示-2\"><a class=\"anchor\" href=\"#模型表示-2\">#</a> 模型表示 2</h1>\n<p>我们把这样从左到右（input-&gt;activation-&gt;output）的算法称为前向传播 FORWARD PROPAGATION<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-07.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-08.png\" alt=\"img.png\" /></p>\n<p>如果遮住前几层，神经网络就像 logistic regression，只不过我们把 logistic regression 中的输入向量 [x1~x3] 变成了中间层的 [a1 (2)~a3 (2)], 即<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-09.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-10.png\" alt=\"img.png\" /><br />\n 将输入的驯良样本，向前传递，得到更好的特征，最后到输出层再进行输出值的计算<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-11.png\" alt=\"img.png\" /><br />\na 由 x 决定，并随着梯度下降变化越来越大，效果优于 x 的几次方。</p>\n<h1 id=\"特征和直观理解\"><a class=\"anchor\" href=\"#特征和直观理解\">#</a> 特征和直观理解</h1>\n<p>用神经网络实现逻辑表达式<br />\n单层神经网络可用来表示逻辑运算，比如 AND、OR<br />\n1 AND<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-12.png\" alt=\"img.png\" /></p>\n<p>2 OR<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-13.png\" alt=\"img.png\" /></p>\n<p>3 取非<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-14.png\" alt=\"img.png\" /></p>\n<p>4 x1<mark>0 &amp;&amp; x2</mark>0<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-19.png\" alt=\"img.png\" /></p>\n<p>5 XNOR 异或非（和 异或 XOR 操作相反：值相同为真）<br />\n比较复杂，需要结合 AND、NOT AND 和 OR 三个运算。<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-15.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-16.png\" alt=\"img.png\" /><br />\na21 = x1 &amp;&amp; x2<br />\na22 = （﹁x1）&amp;&amp;（﹁x2）<br />\na31 =a21 || a21 =(x1 &amp;&amp; x2) ||  （﹁x1）&amp;&amp;（﹁x2） = x1 XNOR x2；</p>\n<h1 id=\"多元分类\"><a class=\"anchor\" href=\"#多元分类\">#</a> 多元分类</h1>\n<p>one-vs-all 方法是把二类分类问题到多类分类的一个推广。用神经网络进行多分类：<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-17.png\" alt=\"img.png\" /></p>\n<p>输入向量 x 有三个维度，两个中间层，输出层有 4 类。输出为 4 维向量，向量中对应类型处值为 1。<br />\n<img data-src=\"/pic/wuenda/shengjingwangluobiaoshu-18.png\" alt=\"img.png\" /></p>\n",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/05/ai/Andrew%20Ng%20Lesson/%E5%90%91%E9%87%8F%E5%8C%96/",
            "url": "https://love.youhuamao.xyz/2022/11/05/ai/Andrew%20Ng%20Lesson/%E5%90%91%E9%87%8F%E5%8C%96/",
            "title": "向量化",
            "date_published": "2022-11-04T16:00:00.000Z",
            "content_html": "<h1 id=\"向量化-vectorization\"><a class=\"anchor\" href=\"#向量化-vectorization\">#</a> 向量化 Vectorization</h1>\n<p>下面是向量化的小例子，如果将所有 u (j) 、所有 v (j)、所有 w (j) 都看成列向量，则公式变为为向量加法 u = 2v + 5w<br />\n<img data-src=\"/pic/wuenda/xianglianghua-01.png\" alt=\"img.png\" /></p>\n<p j=\"\">再复杂一些，在线性回归中 h (x) 的公式如下：<br />\nh_{Θ}(x) = \\sum_{0}^{n}Θ_{j}x_</p>\n<p>假设此时 n=2，只有两个特征。将其向量化：<br />\n<img data-src=\"/pic/wuenda/xianglianghua-02.png\" alt=\"img.png\" /></p>\n<p>在 Octave 中，如果使用 for 循环实现，则为左边的代码。使用看做向量相乘，则只需要右边一行代码：<br />\n<img data-src=\"/pic/wuenda/xianglianghua-03.png\" alt=\"img.png\" /></p>\n<p>当 n = 2 时，梯度下降的公式如下：<br />\n<img data-src=\"/pic/wuenda/xianglianghua-04.png\" alt=\"img.png\" /></p>\n<p>实现这三个方程的方式之一，是用一个 for 循环，让 j 分别等于 0、1、2 来更新 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"normal\">Θ</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">Θ_{j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\">Θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>。</p>\n<ul>\n<li>因为三个参数是同步更新，可以用向量化的方法来实现。我们使用 δ 替代公式中下面这项（注意最右边 x 没有下标）：<br />\n<img data-src=\"/pic/wuenda/xianglianghua-05.png\" alt=\"img.png\" /></li>\n</ul>\n<p>则 δ 是一个 n+1 维向量（在这里是 3 维）<br />\n<img data-src=\"/pic/wuenda/xianglianghua-06.png\" alt=\"img.png\" /></p>\n<p>α 是一个实数，α δ 也是 n+1 维向量</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 是一个 n+1 维向量（在这里是 3 维）<br />\n<img data-src=\"/pic/wuenda/xianglianghua-07.png\" alt=\"img.png\" /></p>\n<p>公式变为一个向量减法：<br />\nΘ := Θ -  α δ</p>\n<p>有时我们使用几十或几百个特征量来计算线性归回，当使用向量化地实现线性回归，通常运行速度就会比 for 循环快的多</p>\n<h1 id=\"术语\"><a class=\"anchor\" href=\"#术语\">#</a> 术语</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>digram 对角线</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>plot 制图</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>semicolon 分号</pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token function\">column</span> vector 列向量</pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>row vector 行向量</pre></td></tr></table></figure>",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/05/ai/Andrew%20Ng%20Lesson/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/",
            "url": "https://love.youhuamao.xyz/2022/11/05/ai/Andrew%20Ng%20Lesson/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/",
            "title": "逻辑回归",
            "date_published": "2022-11-04T16:00:00.000Z",
            "content_html": "<h1 id=\"分类问题-classification\"><a class=\"anchor\" href=\"#分类问题-classification\">#</a> 分类问题 Classification</h1>\n<p>二值分类问题 binary classification problem 定义如下：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-01.png\" alt=\"img.png\" /><br />\n 我们可以设置阈值为一个值，比如 0.5，若<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi mathvariant=\"normal\">Θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_{Θ}(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">Θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>&gt;0.5 则被划分为 1，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi mathvariant=\"normal\">Θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_{Θ}(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">Θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>&lt;0.5 则被划分为 0；</p>\n<h1 id=\"假设表示-hypothesis-representation\"><a class=\"anchor\" href=\"#假设表示-hypothesis-representation\">#</a> 假设表示 Hypothesis Representation</h1>\n<p>引入一个新的模型：逻辑回归。该输出变量范围始终在 0 和 1 之间。 逻辑回归模型的假设是：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-02.png\" alt=\"img.png\" /></p>\n<p>𝑋 代表特征向量；<br />\n𝑔 代表逻辑函数 Logistic Function 也叫 Sigmoid Function，其曲线如下：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-03.png\" alt=\"img.png\" /></p>\n<p>给定输入变量 x，根据选择的参数 Θ，h (x) 给出 y=1 的概率。y=0 的概率是 1 - h (x)<br />\n<img data-src=\"/pic/wuenda/luojihuigui-04.png\" alt=\"img.png\" /></p>\n<h1 id=\"决策边界-decision-boundary\"><a class=\"anchor\" href=\"#决策边界-decision-boundary\">#</a> 决策边界 Decision Boundary</h1>\n<p>决策边界就是模型中预测为 1 和预测为 0 的区域的分界线。The decision boundary is the line that separates the area where y = 0 and where y = 1. It is created by our hypothesis function.<br />\n<img data-src=\"/pic/wuenda/luojihuigui-05.png\" alt=\"img.png\" /></p>\n<p>线性的决策边界：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-06.png\" alt=\"img.png\" /></p>\n<p>非线性的决策边界：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-07.png\" alt=\"img.png\" /></p>\n<h1 id=\"代价函数-cost-function\"><a class=\"anchor\" href=\"#代价函数-cost-function\">#</a> 代价函数  Cost Function</h1>\n<p>如果沿用线性回归里的代价函数，则会导致 J (𝜃) 不是凸函数，引发很多局部最优解。<br />\n<img data-src=\"/pic/wuenda/luojihuigui-08.png\" alt=\"img.png\" /></p>\n<p>为了拟合逻辑回归模型的参数 𝜃，代价函数如下：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-09.png\" alt=\"img.png\" /></p>\n<p>根据上面的公式计算代价，当预测和实际一致时代价为 0，反之代价为无穷大。<br />\ny = 1 时，h (x) 和 J (Θ) 对应曲线如下：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-10.png\" alt=\"img.png\" /><br />\ny = 0 时， h (x) 和 J (Θ) 对应曲线如下：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-11.png\" alt=\"img.png\" /></p>\n<p>即有以下规律：<br />\nCost(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">h_{θ}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>(x),y) = 0 　　if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">h_{θ}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>(x)=y</p>\n<p>Cost(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">h_{θ}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>(x),y)→∞ 　　if y=0 and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">h_{θ}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>(x)→1</p>\n<p>Cost(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">h_{θ}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>(x) ,y)→∞ 　　if y=1 and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">h_{θ}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>(x)→0</p>\n<h1 id=\"简化的代价函数和梯度下降\"><a class=\"anchor\" href=\"#简化的代价函数和梯度下降\">#</a> 简化的代价函数和梯度下降</h1>\n<p>将上面两个式子 简化为下面一个式子（当 y 分别等于 0 或 1 时，式子只剩下两项中的一项）：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-12.png\" alt=\"img.png\" /></p>\n<p>完整的代价函数如下：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-13.png\" alt=\"img.png\" /></p>\n<p>一个向量实现如下：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-14.png\" alt=\"img.png\" /></p>\n<p>梯度下降过程如下：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-15.png\" alt=\"img.png\" /></p>\n<p>使用数学方法推倒上式中 J (Θ) 的导数：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-16.png\" alt=\"img.png\" /></p>\n<p>带入更新算法中，得到下面算法：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-17.png\" alt=\"img.png\" /></p>\n<p>上面这个梯度下降算法 看起来和线性回归一样，但事实上是完全不同的。因为之前 h (x) 是线性函数，而逻辑回归中 h (x) 定义如下：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi mathvariant=\"normal\">Θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><msup><mi mathvariant=\"normal\">Θ</mi><mi>T</mi></msup><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">h_{Θ}(x) = \\frac{1}{1+e^{-Θ^{T}x}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">Θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.402304em;vertical-align:-0.557196em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.5011349999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9840928571428572em;\"><span style=\"top:-2.984092857142857em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.698092857142857em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mtight\">Θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.97733em;\"><span style=\"top:-2.97733em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.6833299999999998em;\"></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord mathnormal mtight\">x</span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.557196em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n<p>一个梯度下降的向量化实现如下<br />\n<img data-src=\"/pic/wuenda/luojihuigui-18.png\" alt=\"img.png\" /></p>\n<h1 id=\"高级优化-advanced-optimization\"><a class=\"anchor\" href=\"#高级优化-advanced-optimization\">#</a> 高级优化 Advanced Optimization</h1>\n<ul>\n<li>除梯度下降算法以外，还有一些常被用来令代价函数最小的算法。这些算法更加复杂和优越，而且通常不需要人工选择学习率，比梯度下降算法要更加快速。这些有： 共轭梯度 （Conjugate Gradient）， 局部优化法 （Broyden fletcher goldfarb shann,BFGS）和有限内存局部优化法 （LBFGS）。</li>\n<li>这些算法有一个智能的内部循环，称为线性搜索 (line search) 算法，它可以自动尝试不同的学习速率 。只需要给这些算法提供计算导数项和代价函数的方法，就可以返回结果。适用于大型机器学习问题。</li>\n<li>它们太复杂，不应该自己实现，而是调用 MATLAB 方法。例如一个无约束最小值函数 fminunc 。它会使用众多高级优化算法中的一个，就像加强版的梯度下降法，自动选择学习速率，找到最佳的 Θ 值。</li>\n<li>使用时需要提供代价函数和每个参数的求导，我们自己实现 costFunction 函数，传入参数 Θ，可以一次性返回以下两个值：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">Θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(Θ)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\">Θ</span><span class=\"mclose\">)</span></span></span></span><br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>θ</mi><mi>j</mi></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial J(\\theta)}{\\partial\\theta_j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.55232em;vertical-align:-0.5423199999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.02778em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2818857142857143em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5423199999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>(参数本来就是一个向量)</li>\n</ul>\n<p>例子，调用 fminunc () 函数，用 @传入 costFunction 函数的指针，初始化的 theta，还可以增加 options（GradObj = on 指 “打开梯度目标参数”，即我们会给这个函数提供梯度参数）：<br />\n<img data-src=\"/pic/wuenda/luojihuigui-21.png\" alt=\"img.png\" />\\</p>\n<h1 id=\"多类别分类一对多-multiclass-classification_-one-vs-all\"><a class=\"anchor\" href=\"#多类别分类一对多-multiclass-classification_-one-vs-all\">#</a> 多类别分类：一对多 Multiclass Classification_ One-vs-all</h1>\n<p>多分类问题中，y 有 {0,1...n} 一共 n+1 中可能值。方法：<br />\n（1）拆分成  n+1 个二分类问题。<br />\n（2）对每个分类，都预测出一个 h (x) 值。代表 y 是这个类型的可能性。<br />\n（3）最后结果为可能性最大的那个类型。<br />\n<img data-src=\"/pic/wuenda/luojihuigui-19.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/luojihuigui-20.png\" alt=\"img.png\" /></p>\n<h1 id=\"术语\"><a class=\"anchor\" href=\"#术语\">#</a> 术语</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>decision boundary 决策边界</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>loophole　漏洞</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>nonlinear 非线性</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>penalize 使不利</pre></td></tr></table></figure>",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/04/ai/Andrew%20Ng%20Lesson/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/",
            "url": "https://love.youhuamao.xyz/2022/11/04/ai/Andrew%20Ng%20Lesson/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/",
            "title": "单变量线性回归",
            "date_published": "2022-11-03T16:00:00.000Z",
            "content_html": "<h1 id=\"模型表示-model-representation\"><a class=\"anchor\" href=\"#模型表示-model-representation\">#</a> 模型表示 Model Representation</h1>\n<p>引入第一个监督学习算法：线性回归 Linear regression。其中只有一个参数的线性回归算法叫做 单变量线性回归 Linear regression with one variable。</p>\n<h2 id=\"线性回归-linear-regression\"><a class=\"anchor\" href=\"#线性回归-linear-regression\">#</a> 线性回归 Linear regression</h2>\n<p>还是房价预测的例子， 训练集如下：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-01.png\" alt=\"img.png\" /><br />\n 定义各个变量的含义如下：</p>\n<ul>\n<li>m 　　　  代表训练集中实例的数量</li>\n<li>x 　　　　代表特征 / 输入变量</li>\n<li>y 　　　　代表目标变量 / 输出变量</li>\n<li>(x,y) 　　  代表训练集中的实例</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo separator=\"true\">,</mo><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(x^{(i)} , y^{(i)})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>    代表第 i 个观察实例：其中<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 代表第 i 个输入变量，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">y^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 代表第 i 个目标变量</li>\n<li>h 　　　　代表学习算法的解决方案或函数，也称为假设（hypothesis）</li>\n</ul>\n<h2 id=\"单变量线性回归-linear-regression-with-one-variable\"><a class=\"anchor\" href=\"#单变量线性回归-linear-regression-with-one-variable\">#</a> 单变量线性回归  Linear regression with one variable</h2>\n<p>h 根据输入的 x 值来得出 y 值， y 值对应房子的价。因此， h 是一个从 x 到 y 的函数映射。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-02.png\" alt=\"img.png\" /></p>\n<p>h 的一种可能的表达方式如下。因为只含有一个特征 / 输入变量，这样的问题叫作单变量线性回归问题。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-03.png\" alt=\"img.png\" /></p>\n<h1 id=\"代价函数-cost-function\"><a class=\"anchor\" href=\"#代价函数-cost-function\">#</a> 代价函数 Cost Function</h1>\n<p>线性回归算法优化的目标是：选取最有可能与数据相拟合的直线。数据与直线的误差，称为建模误差 modeling error。为了使建模误差最小，我们需要调整参数<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，使得代价函数 Cost function <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(θ_{0}, θ_{1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 的值最小。</p>\n<p>在各种代价函数中，最常用的是平方误差代价函数 Squared error cost function。</p>\n<h2 id=\"如何选择模型的参数-θ\"><a class=\"anchor\" href=\"#如何选择模型的参数-θ\">#</a> 如何选择模型的参数 θ</h2>\n<p>因为 h 是一次方程，它对应两个模型参数 (parameters) <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>： 在这里<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>i</mi><mtext>‘</mtext><mi>s</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">θ_{i‘s}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">‘</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 指的是<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-04.png\" alt=\"img.png\" /></p>\n<p>选取不同的参数 θ0 和 θ1，产生的 h 不同，最终的直线也不同：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-05.png\" alt=\"img.png\" /></p>\n<h2 id=\"建模误差-modeling-error\"><a class=\"anchor\" href=\"#建模误差-modeling-error\">#</a> 建模误差 modeling error</h2>\n<p>参数决定了直线相对于训练集的准确程度，模型所预测值 与 训练集实际值 之间的差距（下图中蓝线所指）就是 建模误差（modeling error）。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-06.png\" alt=\"img.png\" /><br />\n 调整参数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_{0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_{1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，目标：使建模误差的平方和最小</p>\n<h2 id=\"平方误差代价函数-squared-error-cost-function\"><a class=\"anchor\" href=\"#平方误差代价函数-squared-error-cost-function\">#</a> 平方误差代价函数 Squared error cost function</h2>\n<p>为了使建模误差最小，需要 使代价函数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(θ_{0}, θ_{1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 最小，公式如下。其中 h (x) - y 是预测值和实际值的差，取其平方和。m 指的是数据集的大小，乘以 1/2m 是为了便于计算。这个<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(θ_{0}, θ_{1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>  通常称为 平方误差函数 (Squared error function)，有时也被称为 平方误差代价函数 (Squared error cost function)。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-07.png\" alt=\"img.png\" /></p>\n<p>下面公式的意思是：寻找<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">θ_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，使得 J 值最小。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-08.png\" alt=\"img.png\" /></p>\n<p>我们绘制一个等高线图， 三个坐标分别为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(θ_{0}, θ_{1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，则可以看出在三维空间中存在一个点，使得 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(θ_{0}, θ_{1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 最小<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-09.png\" alt=\"img.png\" /></p>\n<h1 id=\"代价函数的直观理解-i\"><a class=\"anchor\" href=\"#代价函数的直观理解-i\">#</a> 代价函数的直观理解 I</h1>\n<p>线性回归模型的假设、参数、代价函数、目标如下：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-10.png\" alt=\"img.png\" /></p>\n<p>取将 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 固定为 0 时，代价函数简化为只关于 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 的函数：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-11.png\" alt=\"img.png\" /></p>\n<p>下面的例子里，三个数据点的坐标是（1,1）（2,2）（3,3）。当将 θ0 固定为 0，只变化 θ1 时， 代价函数是一条二次曲线。</p>\n<p>当 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 分别取值 1，0.5，0 的时候，对应左边从上到下三条曲线。<br />\n当 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 取 1 时，J (<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>) = 0 , 此时 J (<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>) 最小，处于曲线最低点，是我们想要的结果。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-12.png\" alt=\"img.png\" /></p>\n<h1 id=\"代价函数的直观理解-ii\"><a class=\"anchor\" href=\"#代价函数的直观理解-ii\">#</a> 代价函数的直观理解 II</h1>\n<p>当 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 都发生变化时，代价函数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(θ_{0}, θ_{1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 在三维空间中图形如下：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-13.png\" alt=\"img.png\" /></p>\n<p>因为三维图像看起来太复杂， 将它投射到二维平面。引入等高线 contour plot 的概念，也叫 contour figure。等高线上的点，对应的代价函数 J (<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> , <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>) 取值相同。<br />\n下面两个图，右边红点对应的直线如左图，可以看出拟合的都不好。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-14.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-15.png\" alt=\"img.png\" /></p>\n<p>下图取值位于三维图形的最低点，在二维图形上位于等高线的中心。对应的假设函数 h (x) 直线如左图。虽然拟合数据有一些误差（蓝色竖线），但是已经很接近最小值了<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-16.png\" alt=\"img.png\" /></p>\n<h1 id=\"梯度下降\"><a class=\"anchor\" href=\"#梯度下降\">#</a> 梯度下降</h1>\n<h2 id=\"局部最优解-local-optimum\"><a class=\"anchor\" href=\"#局部最优解-local-optimum\">#</a> 局部最优解 local optimum</h2>\n<p>已有一个代价函数，我们的目的是使其最小化。通常情况下，始于<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>=0 , <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>=0，调整<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> , <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{θ_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>，止于<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J({θ_0} , {θ_1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 的最小值。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-17.png\" alt=\"img.png\" /></p>\n<p>下面这个例子，θ0 和 θ1 没有开始于 0,0。当选取两个不同的起始点，并向着不同方向进行梯度下降时，到达两个不同的最优解，它们称为局部最优解 local optimum。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-18.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-19.png\" alt=\"img.png\" /></p>\n<h2 id=\"梯度下降算法-gradient-descent-algorithm\"><a class=\"anchor\" href=\"#梯度下降算法-gradient-descent-algorithm\">#</a> 梯度下降算法 Gradient descent algorithm</h2>\n<p>梯度下降算法对 θ 赋值， 使得 J (θ) 按梯度下降最快方向进行， 一直迭代下去， 最终得到局部最小值，即收敛 convergence。梯度下降算法不只用于线性回归， 可以用来最小化任何代价函数 J。公式如下，<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-20.png\" alt=\"img.png\" /></p>\n<p>梯度下降算法中，两个参数 同步更新 simultaneous update（左下）。如果是非同步更新 non-simultaneous update （右下），则不是梯度下降。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-21.png\" alt=\"img.png\" /></p>\n<p>a := b 是赋值操作 assignment ，将 b 的值赋值给 a。<br />\na = b  是真值断言 Truth assertion，判断 a 和 b 是否相等。</p>\n<p>α 是学习速率 learning rate，决定了沿着能让代价函数下降程度最大的方向向下迈出的步子有多大</p>\n<h1 id=\"梯度下降的直观理解\"><a class=\"anchor\" href=\"#梯度下降的直观理解\">#</a> 梯度下降的直观理解</h1>\n<h2 id=\"梯度下降法的更新规则\"><a class=\"anchor\" href=\"#梯度下降法的更新规则\">#</a> 梯度下降法的更新规则</h2>\n<p>梯度下降算法如下图：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-22.png\" alt=\"img.png\" /></p>\n<p>求导的目的，基本上可以说取这个红点的切线，即这条红色直线。由于曲线右侧斜率为正，导数为正。 因此，θ1 减去一个正数乘以 α，值变小。<br />\n曲线左侧斜率为负，导数为负。 因此，θ1 减去一个负数乘以 α，值变大。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-23.png\" alt=\"img.png\" /></p>\n<h2 id=\"学习速率-α-的选择\"><a class=\"anchor\" href=\"#学习速率-α-的选择\">#</a> 学习速率 α 的选择</h2>\n<p>如果 α 太小，只能小碎步下降，需要很多步才能到达全局最低点，很慢。<br />\n如果 α 太大，那么算法可能会越过最低点。一次次越过最低点，离它越来越远。会导致无法收敛， 甚至发散。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-24.png\" alt=\"img.png\" /></p>\n<h2 id=\"不调整学习速率-α-也能收敛\"><a class=\"anchor\" href=\"#不调整学习速率-α-也能收敛\">#</a> 不调整学习速率 α 也能收敛</h2>\n<p>假设将 θ1 初始化在局部最低点。导数为 0，会使得 θ1 不再改变，不会改变参数的值。也解释了为什么即使学习速率 α 保持不变时， 梯度下降也可以收敛到局部最低点。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-25.png\" alt=\"img.png\" /></p>\n<p>为什么不用调整 α 也能到达局部最优点？因为梯度下降一步后， 新的导数会变小，移动的幅度会自动变小。直到最终移动幅度非常小时，已经收敛到局部极小值。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-26.png\" alt=\"img.png\" /></p>\n<h1 id=\"梯度下降的线性回归-gradient-descent-for-linear-regression\"><a class=\"anchor\" href=\"#梯度下降的线性回归-gradient-descent-for-linear-regression\">#</a> 梯度下降的线性回归 Gradient Descent For Linear Regression</h1>\n<h2 id=\"梯度下降和线性回归相结合\"><a class=\"anchor\" href=\"#梯度下降和线性回归相结合\">#</a> 梯度下降和线性回归相结合</h2>\n<p>将平方误差函数 h (x)， 结合梯度下降法， 以及平方代价函数 J (Θ)，得出第一个机器学习算法， 即线性回归 Linear Regression。<br />\n梯度下降算法和线性回归模型的比较：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-27.png\" alt=\"img.png\" /></p>\n<p>对之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-28.png\" alt=\"img.png\" /></p>\n<p>j 分别取 0 和 1 时，其导数如下：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-29.png\" alt=\"img.png\" /></p>\n<p>将上面两个导数带入梯度下降算法中，替代原来的</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>θ</mi><mi>j</mi></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial J({θ_0} , {θ_1})}{\\partial\\theta_j}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.399108em;vertical-align:-0.972108em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.972108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>梯度下降算法变为：<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-30.png\" alt=\"img.png\" /><br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-31.png\" alt=\"img.png\" /></p>\n<p>虽然梯度下降一般易受局部最小值影响 susceptible to local minima，但我们在线性回归中提出的优化问题只有一个全局最优解，而没有其他局部最优解，代价函数是凸二次函数。因此，梯度下降总是收敛到全局最小值（假设学习率 α 不是太大）。<br />\n<img data-src=\"/pic/wuenda/danbianliangxianxinghuigui-31.png\" alt=\"img.png\" /></p>\n<h2 id=\"批处理梯度下降-batch-gradient-descent\"><a class=\"anchor\" href=\"#批处理梯度下降-batch-gradient-descent\">#</a> 批处理梯度下降 batch gradient descent</h2>\n<ul>\n<li>\n<p>上面使用的算法也叫批处理梯度下降 batch gradient descent，指的是梯度下降的每一步都涉及到所有的训练实例。也有其他类型的非批处理梯度下降法，每次只关注训练集中一些小子集。</p>\n</li>\n<li>\n<p>高等线性代数中有一种计算代价函数 J 最小值的数值解法，不需要梯度下降这种迭代算法，也能解出代价函数 J 的最小值，这是另一种称为正规方程 (normal equations) 的方法。实际上在数据量较大的情况下，梯度下降法比正规方程要更适用一些。</p>\n</li>\n</ul>\n<h1 id=\"相关术语\"><a class=\"anchor\" href=\"#相关术语\">#</a> 相关术语</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>线性回归    Linear regression</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>单变量线性回归  Linear regression with one variable</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>代价函数    Cost Function</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>平方误差代价函数 Squared error cost <span class=\"token keyword\">function</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>建模误差    Modeling error</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>等高线　　contour plot 、contour figure</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>梯度下降    Gradient descent</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>批处理梯度下降     Batch gradient descent</pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>学习效率 　Learning rate</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>同步更新  simultaneous update</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>非同步更新 non-simultaneous update</pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>局部最优    <span class=\"token builtin class-name\">local</span> optimum</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>全局最优    global optimum</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>全局最小值     global minimum</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>局部最小值     <span class=\"token builtin class-name\">local</span> minimum</pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>微分项        derivative term</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>微积分        calculus</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>导数　　　 derivatives</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>偏导数        partial derivatives</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>负导数        nagative derivative</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>负斜率        nagative slope</pre></td></tr><tr><td data-num=\"26\"></td><td><pre></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>收敛            converge</pre></td></tr><tr><td data-num=\"28\"></td><td><pre>发散            diverge</pre></td></tr><tr><td data-num=\"29\"></td><td><pre>陡峭            steep</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>碗型            bow-shaped <span class=\"token keyword\">function</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>凸函数        convex <span class=\"token keyword\">function</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>线性代数     linear algebra</pre></td></tr><tr><td data-num=\"34\"></td><td><pre>迭代算法     iterative algorithm</pre></td></tr><tr><td data-num=\"35\"></td><td><pre>正规方程组     normal equations methods</pre></td></tr><tr><td data-num=\"36\"></td><td><pre>梯度下降的泛化     a generalization of the gradient descent algorithm</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>越过最低点        overshoot the minimum</pre></td></tr></table></figure>",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/04/ai/Andrew%20Ng%20Lesson/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%A4%8D%E4%B9%A0/",
            "url": "https://love.youhuamao.xyz/2022/11/04/ai/Andrew%20Ng%20Lesson/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%A4%8D%E4%B9%A0/",
            "title": "线性代数复习",
            "date_published": "2022-11-03T16:00:00.000Z",
            "content_html": "<h1 id=\"加法和标量乘法\"><a class=\"anchor\" href=\"#加法和标量乘法\">#</a> 加法和标量乘法</h1>\n<p><img data-src=\"/pic/wuenda/xianxingdaishu-01.png\" alt=\"img.png\" /></p>\n<p><img data-src=\"/pic/wuenda/xianxingdaishu-02.png\" alt=\"img.png\" /></p>\n<h1 id=\"矩阵向量乘法\"><a class=\"anchor\" href=\"#矩阵向量乘法\">#</a> 矩阵向量乘法</h1>\n<p><img data-src=\"/pic/wuenda/xianxingdaishu-03.png\" alt=\"img.png\" /></p>\n<p><img data-src=\"/pic/wuenda/xianxingdaishu-04.png\" alt=\"img.png\" /></p>\n<p><img data-src=\"/pic/wuenda/xianxingdaishu-05.png\" alt=\"img.png\" /></p>\n<p>应用，以预测房子价格为例<br />\n<img data-src=\"/pic/wuenda/xianxingdaishu-06.png\" alt=\"img.png\" /></p>\n<h1 id=\"矩阵乘法\"><a class=\"anchor\" href=\"#矩阵乘法\">#</a> 矩阵乘法</h1>\n<p><img data-src=\"/pic/wuenda/xianxingdaishu-07.png\" alt=\"img.png\" /></p>\n<p><img data-src=\"/pic/wuenda/xianxingdaishu-08.png\" alt=\"img.png\" /></p>\n<p>应用，以预测房子价格为例</p>\n<p><img data-src=\"/pic/wuenda/xianxingdaishu-9.png\" alt=\"img.png\" /></p>\n<h1 id=\"矩阵乘法特征\"><a class=\"anchor\" href=\"#矩阵乘法特征\">#</a> 矩阵乘法特征</h1>\n<ul>\n<li>\n<p>不符合交换律 commutative　<br />\nA × B ≠ B× A　　【但是对于单位矩阵，有 AI = IA = A】<br />\n<img data-src=\"/pic/wuenda/xianxingdaishu-10.png\" alt=\"img.png\" /></p>\n</li>\n<li>\n<p>符合组合律 associative<br />\nA ×（B× C） =（A × B）× C<br />\n<img data-src=\"/pic/wuenda/xianxingdaishu-10.png\" alt=\"img.png\" /></p>\n</li>\n<li>\n<p>单位矩阵<br />\n<img data-src=\"/pic/wuenda/xianxingdaishu-11.png\" alt=\"img.png\" /></p>\n</li>\n</ul>\n<h1 id=\"逆-转置\"><a class=\"anchor\" href=\"#逆-转置\">#</a> 逆、转置</h1>\n<h2 id=\"矩阵的逆-inverse-matrix\"><a class=\"anchor\" href=\"#矩阵的逆-inverse-matrix\">#</a> 矩阵的逆 Inverse Matrix</h2>\n<p>矩阵的逆 A-1  Inverse Matrix。如矩阵 A 是一个 m× m 矩阵（方阵）， 如果有逆矩阵 A-1 ，则：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>=</mo><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>A</mi><mo>=</mo><mi>I</mi></mrow><annotation encoding=\"application/x-tex\">AA^{-1}=A^{-1}A=I</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\">A</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span></span></span></span><br />\nI 称为单位矩阵 Identity Matrix<br />\n 没有逆矩阵的矩阵称为 奇异矩阵 singular matrix 或者 退化矩阵 degenerate matrix。</p>\n<ul>\n<li>规则：</li>\n</ul>\n<ol>\n<li>只有方阵有逆矩阵。</li>\n<li>零矩阵没有逆矩阵 （还有其他一些矩阵没有逆矩阵，可以想成是一些特别接近零矩阵的矩阵）</li>\n</ol>\n<h2 id=\"矩阵的转置-transpose-matrix\"><a class=\"anchor\" href=\"#矩阵的转置-transpose-matrix\">#</a> 矩阵的转置 Transpose Matrix</h2>\n<ul>\n<li T=\"\">\n<p>矩阵转置 Transpose Matrix ，符号为A^</p>\n</li>\n<li>\n<p>定义：设 A 为 m×n 阶矩阵（即 m 行 n 列），第 i 行 j 列的元素是 a (i,j)，即：A = a (i,j)。定义 A 的转置为这样一个 n×m 阶矩阵 B，满足 B=a (j,i)，即 b (i,j)=a (j,i)（B 的第 i 行第 j 列元素是 A 的第 j 行第 i 列元素），记 AT=B。 (有些书记为 A'=B)<br />\n 直观来看，将 A 的所有元素绕着一条从第 1 行第 1 列元素出发的右下方 45 度的射线作镜面反转，即得到 A 的转置。<br />\n<img data-src=\"/pic/wuenda/xianxingdaishu-12.png\" alt=\"img.png\" /></p>\n</li>\n<li>\n<p>矩阵的转置基本性质<br />\n (A ± B) T = AT ± BT<br />\n(A × B) T= BT × AT<br />\n(AT) T = A<br />\n(KA) T = KAT</p>\n</li>\n<li>\n<p>MATLAB 和 Octave 中矩阵转置：直接打一撇， B = A'。</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span> octave:<span class=\"token operator\"><span class=\"token file-descriptor important\">7</span>></span> B <span class=\"token operator\">=</span> A'</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token number\">2</span> B <span class=\"token operator\">=</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token number\">3</span>     <span class=\"token number\">3</span>    <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token number\">4</span>     <span class=\"token number\">4</span>   <span class=\"token number\">16</span></pre></td></tr></table></figure><h1 id=\"术语\"><a class=\"anchor\" href=\"#术语\">#</a> 术语</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>up to the numerical precision 由于计算精度的问题</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>essentially 根本上</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>ten to the minus seventeen  <span class=\"token number\">10</span>的-17次方</pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>round off 四舍五入</pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>optimal matrices 最优矩阵</pre></td></tr></table></figure>",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/04/ai/Andrew%20Ng%20Lesson/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/",
            "url": "https://love.youhuamao.xyz/2022/11/04/ai/Andrew%20Ng%20Lesson/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/",
            "title": "多变量线性回归",
            "date_published": "2022-11-03T16:00:00.000Z",
            "content_html": "<h1 id=\"多维特征-multiple-features\"><a class=\"anchor\" href=\"#多维特征-multiple-features\">#</a> 多维特征 Multiple Features</h1>\n<p>Multivariate linear regression 多维线性回归<br />\n之前讨论单变量回归模型。现在讨论多变量模型，模型中的特征为（x1,x2,...,xn）。<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-01.png\" alt=\"fenlei.png\" /></p>\n<ul>\n<li>引入新的注释：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>x</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><annotation encoding=\"application/x-tex\">x^{(i)}_{j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.4577719999999998em;vertical-align:-0.4129719999999999em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4129719999999999em;\"><span></span></span></span></span></span></span></span></span></span>  = value of feature j in the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>i</mi><mi>t</mi></msub><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">i_th</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">i</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\">h</span></span></span></span> training example　　特征矩阵中第 i 行的第 j 个特征，也就是第 i 个训练实例的第 j 个特征。<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> = the input (features) of the ith training example 　第 i 个训练实例，是特征矩阵中的第 i 行，是一个向量（vector）。<br />\nm = the number of training examples 　　　　　　　 训练实例的个数<br />\n n = the number of features　　　　　　　　　　　　特征的数量</li>\n<li>支持多变量的假设 h 表示为<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msub><mi>θ</mi><mn>0</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_{θ}{(x)} = θ_{0}+θ_{1}x_{1}+θ_{2}x_{2}+\\cdots+(θ_{n}x_{n})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span><br />\n 这个公式中有 n+1 个参数和 n 个变量，为了使得公式能够简化一些，引入 x^<ruby>0}=1，则公式转化为：\n$h_{θ}{(x)} = θ_{0} x_{0}+θ_{1} x_{1}+θ_{2} x_{2}+\\cdots+(θ_{n} x_{n})$\n此时模型中的参数是一个 n+1 维的向量，任何一个训练实例也都是 n+1 维的向量，特征矩阵 X 的维度是 m * (n+1)。公式可以简化为\n$h_{θ}{(x)} = θ<rp>(</rp><rt>{T</rt><rp>)</rp></ruby>X$</li>\n</ul>\n<h1 id=\"多变量梯度下降-gradient-descent-for-multiple-variables\"><a class=\"anchor\" href=\"#多变量梯度下降-gradient-descent-for-multiple-variables\">#</a> 多变量梯度下降 Gradient Descent for Multiple Variables</h1>\n<p>在具有多变量的线性回归中，定义代价函数 J (θ) 如下：<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-02.png\" alt=\"fenlei.png\" /><br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-03.png\" alt=\"fenlei.png\" /></p>\n<p>多变量线性回归模型如下。为了简化，我们加入<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>X</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">X_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> = 1，参数 θ 为一个 n+1 维向量 vector。算法会同步更新每一个<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">θ_{j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>(j = 0 到 n)<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-04.png\" alt=\"fenlei.png\" /><br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-05.png\" alt=\"fenlei.png\" /></p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">computeCost</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> theta<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>　　inner <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>power<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>X <span class=\"token operator\">*</span> theta<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>　　<span class=\"token keyword\">return</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>inner<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span> <span class=\"token operator\">*</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"梯度下降法实践-1-特征缩放-gradient-descent-in-practice-i-feature-scaling\"><a class=\"anchor\" href=\"#梯度下降法实践-1-特征缩放-gradient-descent-in-practice-i-feature-scaling\">#</a> 梯度下降法实践 1 - 特征缩放 Gradient Descent in Practice I - Feature Scaling</h1>\n<ul>\n<li>多维特征问题中，帮助梯度下降算法更快地收敛，特征需要具有相近的尺度（similar scale），这就需要我们进行 特征缩放 Feature Scaling。</li>\n<li>假设两个特征，房屋尺寸的值为 0-2000 平方英尺，而房间数量的值为 0-5，对应的代价函数等高线图会显得很扁（skewed elliptical shape），梯度下降算法需要非常多次的迭代才能收敛 (左图)<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-06.png\" alt=\"fenlei.png\" /></li>\n</ul>\n<p>尺度也不是必须要 -1 到 1，但是范围不能很大，也不能很小，例如：<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-07.png\" alt=\"fenlei.png\" /></p>\n<p>最简单的方法是均值归一化 Mean normalization，令：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mtext> </mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>μ</mi><mi>i</mi></msub></mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_{i} = \\ frac{x_{i}-μ_{i}}{s_{i}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\"> </span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">c</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span><br />\n 其中<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>μ</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">μ_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是第 i 维所有取值的平均值。<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是第 i 维取值的范围 range（或标准差 standard deviation）<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-08.png\" alt=\"fenlei.png\" /></p>\n<h1 id=\"梯度下降法实践-2-学习率-gradient-descent-in-practice-ii-learning-rate\"><a class=\"anchor\" href=\"#梯度下降法实践-2-学习率-gradient-descent-in-practice-ii-learning-rate\">#</a> 梯度下降法实践 2 - 学习率 Gradient Descent in Practice II - Learning Rate</h1>\n<ul>\n<li>为保证梯度下降算法正确运行，可以绘制 迭代次数 iteration numbers 和 代价函数的图表，观测算法在何时趋于收敛（左边）。<br />\n还有一些自动测试是否收敛的方法 automatic convergence test，例如使用阈值 ε（右边）。因为阈值的大小很难选取，还是左侧的图表比较好。<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-09.png\" alt=\"fenlei.png\" /></li>\n<li>随着迭代次数增加，代价函数应该呈下降趋势。如果上升或者频繁升降，说明 α 取得太大，可能导致不能收敛。如果 α 取值太小，算法会运行的很慢，但还是下降的，通常会迭代很多次后收敛。<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-10.png\" alt=\"fenlei.png\" /></li>\n</ul>\n<p>学习率可以尝试如下值：<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-11.png\" alt=\"fenlei.png\" /></p>\n<h1 id=\"特征和多项式回归-features-and-polynomial-regression\"><a class=\"anchor\" href=\"#特征和多项式回归-features-and-polynomial-regression\">#</a> 特征和多项式回归 Features and Polynomial Regression</h1>\n<h2 id=\"创造新的特征\"><a class=\"anchor\" href=\"#创造新的特征\">#</a> 创造新的特征</h2>\n<p>不一定非要用已有特征，可以创造新的特征，例如：面积 = 长 * 宽。这时二次函数变成了单变量函数。<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-12.png\" alt=\"fenlei.png\" /></p>\n<h2 id=\"多项式回归-polynomial-regression\"><a class=\"anchor\" href=\"#多项式回归-polynomial-regression\">#</a> 多项式回归 Polynomial Regression</h2>\n<p>二次方程模型：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msub><mi>θ</mi><mn>0</mn></msub><msub><mi>x</mi><mn>0</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>2</mn></msub><msubsup><mi>x</mi><mn>2</mn><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_{θ}{(x)} = θ_{0}x_{0}+θ_{1}x_{1}+(θ_{2}x_{2}^{2})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p>三次方程模型：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>θ</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msub><mi>θ</mi><mn>0</mn></msub><msub><mi>x</mi><mn>0</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo stretchy=\"false\">(</mo><msub><mi>θ</mi><mn>2</mn></msub><msubsup><mi>x</mi><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><msub><mi>θ</mi><mn>3</mn></msub><msubsup><mi>x</mi><mn>3</mn><mn>3</mn></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_{θ}{(x)} = θ_{0}x_{0}+θ_{1}x_{1}+(θ_{2}x_{2}^{2}+θ_{3}x_{3}^{3})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">3</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">3</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">3</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p>因为实际生活中，随着房屋面积上升、房价不可能减小，而二次曲线会先上升后下降。选择三次方模型，引入另外的变量替换高次幂，将其转换为线性回归模型。<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-13.png\" alt=\"fenlei.png\" /></p>\n<p>了和曲线拟合的更好，还可以使用 平方根 square root<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-14.png\" alt=\"fenlei.png\" /></p>\n<h1 id=\"正规方程-normal-equation\"><a class=\"anchor\" href=\"#正规方程-normal-equation\">#</a> 正规方程 Normal Equation</h1>\n<h2 id=\"正规方程-normal-equation-2\"><a class=\"anchor\" href=\"#正规方程-normal-equation-2\">#</a> 正规方程 Normal Equation</h2>\n<p>正规方程的思想：假设代价函数 J (Θ) 的偏导数等于 0，求解方程，得到使代价函数 J (Θ) 最小的参数 Θ。即求曲线的最低点（切线斜率为 0）。<br />\n最简单的情况，只有一维，代价函数是二次曲线：<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-15.png\" alt=\"fenlei.png\" /></p>\n<p>如果有 n 个特征，则 Θ 为 n+1 维。针对代价函数 J (Θ) 的每一项 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">Θ</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(Θ_{j})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\">Θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> ，设其偏导数为 0。通过数学方法求解方程，得到使代价函数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">Θ</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(Θ_{j})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\">Θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 最小的 Θj。<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-16.png\" alt=\"fenlei.png\" /></p>\n<h2 id=\"正规方程的解\"><a class=\"anchor\" href=\"#正规方程的解\">#</a> 正规方程的解</h2>\n<p>假设训练集特征矩阵为  X（包含<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_{0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> = 1），结果为向量 y，则解 Θ 可以通过公式求出：<br />\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Θ</mi><mo>=</mo><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">(</mo><msup><mi>X</mi><mi>T</mi></msup><msup><mo stretchy=\"false\">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">)</mo><msup><mi>X</mi><mi>T</mi></msup><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">Θ = ((X^{T})^{-1})X^Ty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Θ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0913309999999998em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span><br />\n 例子，四个数据：<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-17.png\" alt=\"fenlei.png\" /></p>\n<p>解 Θ 为：<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-18.png\" alt=\"fenlei.png\" /></p>\n<p>正规方程方法中，不用进行特征缩放 Feature Scaling。<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-19.png\" alt=\"fenlei.png\" /></p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>pinv<span class=\"token punctuation\">(</span>X’ * X <span class=\"token punctuation\">)</span> * X‘ * y</pre></td></tr></table></figure><h2 id=\"梯度下降和正规方程的比较\"><a class=\"anchor\" href=\"#梯度下降和正规方程的比较\">#</a> 梯度下降和正规方程的比较</h2>\n<p>1、梯度下降需要选择学习率 α，迭代很多步，正规方程只需要一步。<br />\n2、正规方程依赖于矩阵计算。由于计算逆矩阵的时间复杂度是 O (n3)，当 n 比较大时，计算过程会特别慢<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-20.png\" alt=\"fenlei.png\" /><br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-21.png\" alt=\"fenlei.png\" /></p>\n<ul>\n<li>\n<p>总结<br />\n 1、特征变量的数目 n 不大的时候，推荐使用正规方程。<br />\n2、n 比较大的时候（例如 10000），考虑梯度下降。<br />\n3、某些算法（例如分类算法中的逻辑回归）不能使用正规方程法，只能使用梯度下降。</p>\n</li>\n<li>\n<p>正规方程 python 实现</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span> <span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token number\">2</span> <span class=\"token keyword\">def</span> <span class=\"token function\">normalEqn</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token number\">3</span>     theta <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>inv<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>T@X<span class=\"token punctuation\">)</span>@X<span class=\"token punctuation\">.</span>T@y <span class=\"token comment\">#X.T@X 等价于 X.T.dot (X)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token number\">4</span>     <span class=\"token keyword\">return</span> theta</pre></td></tr></table></figure><h1 id=\"正规方程及不可逆性-normal-equation-noninvertibility\"><a class=\"anchor\" href=\"#正规方程及不可逆性-normal-equation-noninvertibility\">#</a> 正规方程及不可逆性 Normal Equation Noninvertibility</h1>\n<p>当矩阵 XTX 不可逆怎么办？ 不可逆的问题很少发生，即使发生，使用 pinv () 也能正常算出结果。</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>pinv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>    pseudo-inverse伪逆  即使 singular degenerate 也能算出来逆矩阵</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>inv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  　 inverse逆 　　　　　引入了先进的数值计算的概念</pre></td></tr></table></figure><p>两种情况可能导致不可逆：<br />\n1、有冗余特征 redundant features，即特征值线性相关（例如 x1 = 常数 * x2）<br />\n解决：删除冗余特征<br />\n 2、特征维数 n  ≤ 数据规模 m （例如 10 个样本适应 100+1 个参数）<br />\n解决：删除特征，或者使用线性代数中的正则化 regularization 方法<br />\n<img data-src=\"/pic/wuenda/duobianliangxianxinghuigui-21.png\" alt=\"fenlei.png\" /></p>\n<h1 id=\"相关术语\"><a class=\"anchor\" href=\"#相关术语\">#</a> 相关术语</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>skewed elliptical shape 偏斜椭圆形</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>poorly scaled feature 范围不好</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>mean normalization 均值归一化</pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>feature scaling 特征缩放</pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>iteration numbers 迭代步数</pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>polynomial regression 多项式回归</pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>quadratic <span class=\"token keyword\">function</span> 二次函数</pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>cubic <span class=\"token keyword\">function</span> 三次函数</pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>square root 平方根</pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre> </pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>regulazation 正规化</pre></td></tr><tr><td data-num=\"22\"></td><td><pre></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>redundant features 冗余特征</pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>noninvertibility 不可逆</pre></td></tr><tr><td data-num=\"26\"></td><td><pre></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>pseudo-inverse 伪逆</pre></td></tr></table></figure>",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/03/utility/MarkDown/%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/",
            "url": "https://love.youhuamao.xyz/2022/11/03/utility/MarkDown/%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/",
            "title": "数学公式",
            "date_published": "2022-11-02T16:00:00.000Z",
            "content_html": "",
            "tags": [
                "工具",
                "MarkDown",
                "MarkDown"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/02/Java/Java%E5%9F%BA%E7%A1%80/%E9%9B%86%E5%90%88/",
            "url": "https://love.youhuamao.xyz/2022/11/02/Java/Java%E5%9F%BA%E7%A1%80/%E9%9B%86%E5%90%88/",
            "title": "集合",
            "date_published": "2022-11-01T16:00:00.000Z",
            "content_html": "<h1 id=\"集合\"><a class=\"anchor\" href=\"#集合\">#</a> 集合</h1>\n<ul>\n<li>集合主要是两组 (单列集合，双列集合)</li>\n<li>CoLLection 接口有两个重要的子接口 List Set, 他们的实现子类都是单列集合</li>\n<li>Map 接口的实现子类 是双列集合，存放的 K-V</li>\n</ul>\n<h1 id=\"collection接口实现类的特点\"><a class=\"anchor\" href=\"#collection接口实现类的特点\">#</a> Collection 接口实现类的特点</h1>\n<p>public interface Collection&lt;E&gt; extends Iterable&lt;E&gt;</p>\n<ul>\n<li>collection 实现子类可以存放多个元素，每个元素可以是 Object</li>\n<li>有些 Collection 的实现类，可以存放重复的元素，有些不可以</li>\n<li>有些 Collection 的实现类，有些是有序的 (List)，有些不是有序 (Set)</li>\n<li>Collection 接口没有直接的实现子类，是通过它的子接口 Set 和 List 来实现的</li>\n</ul>\n<h1 id=\"collection接口常用方法\"><a class=\"anchor\" href=\"#collection接口常用方法\">#</a> Collection 接口常用方法</h1>\n<p>Collection 接口常用方法，以实现子类 ArrayList 来演示（因为 Collection 无法直接实例化）</p>\n<ul>\n<li>常用方法</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>L ist List <span class=\"token operator\">=</span> new</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>ArrayList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>add:添加单个元素</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>list.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"jack\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>list.add<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//1ist。add<span class=\"token punctuation\">(</span>new Integer<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>List.add<span class=\"token punctuation\">(</span>true<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span><span class=\"token string\">\"list=\"</span> + List<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>remove:删除指定元素</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>1ist.remove<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//删除第一个元素</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>List.remove<span class=\"token punctuation\">(</span>true<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//指定删除某个元素</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"List=\"</span> + List<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>contains:查找元素是否存在</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>list <span class=\"token builtin class-name\">.</span> contains<span class=\"token punctuation\">(</span><span class=\"token string\">\"jack\"</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//T</pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>size:获取元素个数</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>System.out. println<span class=\"token punctuation\">(</span>list. size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//2</pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>isEmpty:判断是否为空</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span>List.isEmpty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//F</pre></td></tr><tr><td data-num=\"22\"></td><td><pre></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>cLear:清空</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>List. cLear<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>addALL:添加多个元素</pre></td></tr><tr><td data-num=\"27\"></td><td><pre>ArrayList List2 <span class=\"token operator\">=</span> new ArrayList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>List2.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"红楼梦\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>List2.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"三国演义\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>List.addALL<span class=\"token punctuation\">(</span>List2<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"list=\"</span> + List<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>containsALL:查找多个元素是否都存在</pre></td></tr><tr><td data-num=\"34\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>list.containsAlL<span class=\"token punctuation\">(</span>list2<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//T</pre></td></tr><tr><td data-num=\"35\"></td><td><pre></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>removeAll:删除多个元素</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>List.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"聊斋\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>List.removeAlL<span class=\"token punctuation\">(</span>tist2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"List=\"</span> + List<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//<span class=\"token punctuation\">[</span>聊斋<span class=\"token punctuation\">]</span></pre></td></tr></table></figure><h1 id=\"iterator迭代器\"><a class=\"anchor\" href=\"#iterator迭代器\">#</a> Iterator (迭代器)</h1>\n<ul>\n<li>Collection 接口遍历元素方式 1: 使用 Iterator (迭代器)</li>\n<li>Iterator 对象称为迭代器，主要用于遍历 Collection 集合中的元素。</li>\n<li>所有实现了 Collection 接口的集合类都有一个 iterator (方法，用以返回个实现了 lterator 接口的对象，即可以返回一个迭代器。</li>\n<li>Iterator 仅用于遍历集合，Iterator 本身并不存放对象。</li>\n<li>迭代器的执行原理</li>\n<li>在调用 iterator.next () 方法之 前必须要调用 iterator.hasNext (进行检测。若不调用，且下一条记录无效，直接调用 it.next (会抛出 NoSuchElementException 异常。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Iterator iterator <span class=\"token operator\">=</span> coll.iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> //得到一个集合的迭代器</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//hasNext<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>:判断是否还有下一个元素</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>while<span class=\"token punctuation\">(</span>iterator.hasNext<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    //next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>:①指针下移②将下移以后集合位置上的元素返回</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    System. out.println<span class=\"token punctuation\">(</span>iterator.next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>Collection col <span class=\"token operator\">=</span> new ArrayList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"11\"></td><td><pre>col.add<span class=\"token punctuation\">(</span>new Book<span class=\"token punctuation\">(</span><span class=\"token string\">\"三国演义\"</span>, <span class=\"token string\">\"罗贯中\"</span>,10.1<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>col.add<span class=\"token punctuation\">(</span>new Book<span class=\"token punctuation\">(</span><span class=\"token string\">\"小李飞刀\"</span>, <span class=\"token string\">\"古龙\"</span>,5.1<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>col.add<span class=\"token punctuation\">(</span>new Book<span class=\"token punctuation\">(</span><span class=\"token string\">\"红楼梦\"</span>, <span class=\"token string\">\"曹雪芹\"</span>,34.6<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>//得到迭代器</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>Iterator iterator <span class=\"token operator\">=</span> col.iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>//使用while遍历</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>while<span class=\"token punctuation\">(</span>iterator.hasNext<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>Object next <span class=\"token operator\">=</span> iterator.next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>next<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>//再次遍历需要重置迭代器.</pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>iterator <span class=\"token operator\">=</span> col.iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"for循环增强\"><a class=\"anchor\" href=\"#for循环增强\">#</a> for 循环增强</h1>\n<ul>\n<li>Collection 接口遍 历对象方式 2-for 循环增强.</li>\n<li>增强 for 循环，可以代替 iterator 迭代器， 特点：增强 for 就是简化版的 iterator , 本质一样。只能用于遍历集合或数组。</li>\n<li>基本语法</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>for<span class=\"token punctuation\">(</span>元素类型元素名:集合名或数组名<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    访问元素</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>使用</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Collection col <span class=\"token operator\">=</span> new ArrayList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>col.add<span class=\"token punctuation\">(</span>new Book<span class=\"token punctuation\">(</span><span class=\"token string\">\"三国演义\"</span>, <span class=\"token string\">\"罗贯中\"</span>,10.1<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>col.add<span class=\"token punctuation\">(</span>new Book<span class=\"token punctuation\">(</span><span class=\"token string\">\"小李飞刀\"</span>, <span class=\"token string\">\"古龙\"</span>,5.1<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>col.add<span class=\"token punctuation\">(</span>new Book<span class=\"token punctuation\">(</span><span class=\"token string\">\"红楼梦\"</span>, <span class=\"token string\">\"曹雪芹\"</span>,34.6<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>/,使用增强for</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>0bject book <span class=\"token builtin class-name\">:</span> col<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>s</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"book=\"</span> + book<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>//增强for, 也可以直接在数组使用</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>int<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> nums <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token number\">1</span>, <span class=\"token number\">8</span>，10，90<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>int i <span class=\"token builtin class-name\">:</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"i=\"</span> + i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h1 id=\"list接口\"><a class=\"anchor\" href=\"#list接口\">#</a> List 接口</h1>\n<ul>\n<li>List 接口是 Collection 接口的子接口 List java</li>\n<li>List 集合类中元素有序 (即添加顺序和取出顺序一致)、且可重复</li>\n<li>List 集合中的每个元素都有其对应的顺序索引，即支持索引。</li>\n<li>List 容器中的元素都对应一个整数型的序号记载其在容器中的位置，可以根据序号存取容器中的元素。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//List集合类中元素有序<span class=\"token punctuation\">(</span>即添加顺序和取出顺序一致<span class=\"token punctuation\">)</span>、且可重复</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>List list <span class=\"token operator\">=</span> new ArrayList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>List.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"jack\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>List.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"tom\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>List.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"mary\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>List.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"hsp\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>List.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"tom\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>System. out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"List=\"</span> + list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"list接口常用方法\"><a class=\"anchor\" href=\"#list接口常用方法\">#</a> List 接口常用方法</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>List List <span class=\"token operator\">=</span> new ArrayList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>List.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"张三丰\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>list.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"贾宝玉\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>//void add<span class=\"token punctuation\">(</span>int index, Object ele<span class=\"token punctuation\">)</span> :在index位置插入eLe元素</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>//在index <span class=\"token operator\">=</span> <span class=\"token number\">1</span>的位置插入一个对象</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>list.add<span class=\"token punctuation\">(</span><span class=\"token number\">1</span>, <span class=\"token string\">\"幽化猫\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span><span class=\"token string\">\"list=\"</span> + List<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>booLean addAll<span class=\"token punctuation\">(</span>int index, Collection eLes<span class=\"token punctuation\">)</span>: 从index位置开始将eLes中的所有元素添加进来</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>List List2 <span class=\"token operator\">=</span> new ArrayList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>list2.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"jack\"</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>list2.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"tom\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"14\"></td><td><pre>list.addALL<span class=\"token punctuation\">(</span><span class=\"token number\">1</span>, List2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"list=\"</span> + List<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>//Object get<span class=\"token punctuation\">(</span>int index<span class=\"token punctuation\">)</span> :获取指定index位置的元素</pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>int index0f<span class=\"token punctuation\">(</span>0bject obj<span class=\"token punctuation\">)</span> :返回obj在集合中首次出现的位置</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span>list <span class=\"token builtin class-name\">.</span> index0f<span class=\"token punctuation\">(</span><span class=\"token string\">\"tom\"</span> <span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//2</pre></td></tr><tr><td data-num=\"23\"></td><td><pre></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>int LastIndex0f<span class=\"token punctuation\">(</span>Object obj<span class=\"token punctuation\">)</span> :返回obj在当前集合中末次出现的位置</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>List. add<span class=\"token punctuation\">(</span><span class=\"token string\">\"幽化猫\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"List=\"</span> + List<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>System.out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span>list. LastIndex0f<span class=\"token punctuation\">(</span><span class=\"token string\">\"幽化猫\"</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>Object remove <span class=\"token punctuation\">(</span>int index<span class=\"token punctuation\">)</span> :移除指定index位置的元素，并返回此元素</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>List.remove<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span><span class=\"token string\">\"list=\"</span> + List<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>Object set<span class=\"token punctuation\">(</span>int index, Object ele<span class=\"token punctuation\">)</span>: 设置指定index位置的元素为eLe，相当于 是替换。</pre></td></tr><tr><td data-num=\"34\"></td><td><pre>List.set<span class=\"token punctuation\">(</span><span class=\"token number\">1</span>, <span class=\"token string\">\"玛丽\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>System. out。printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"List=\"</span> + list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>List subList<span class=\"token punctuation\">(</span>int fromIndex, int toIndex<span class=\"token punctuation\">)</span> :返回从fromIndex到toIndex位置的子集合</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>//注意返回的子集合fromIndex <span class=\"token operator\">&lt;=</span> subList <span class=\"token operator\">&lt;</span> toIndex</pre></td></tr><tr><td data-num=\"39\"></td><td><pre>List returnList <span class=\"token operator\">=</span> List. subList<span class=\"token punctuation\">(</span><span class=\"token number\">0</span> ,2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"returnList=\"</span> + returntist<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"list的三种遍历方式\"><a class=\"anchor\" href=\"#list的三种遍历方式\">#</a> List 的三种遍历方式</h1>\n<ul>\n<li>方式一：使用 iterator</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Iterator iter <span class=\"token operator\">=</span> col.iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>while<span class=\"token punctuation\">(</span>iter.hasNext<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    Object o <span class=\"token operator\">=</span> iter.next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>方式二：使用增强 for</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>for<span class=\"token punctuation\">(</span>Object o:col<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>方式三：使用普通 for</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>for<span class=\"token punctuation\">(</span>int <span class=\"token assign-left variable\">i</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span>i<span class=\"token operator\">&lt;</span> list.size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>i+ +<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    Object object <span class=\"token operator\">=</span> list.get<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    System.out.println<span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h1 id=\"arraylist底层结构和源码分析\"><a class=\"anchor\" href=\"#arraylist底层结构和源码分析\">#</a> ArrayList 底层结构和源码分析</h1>\n<ul>\n<li>permits all elements, including null , ArrayList 可以加入 null, 并且多个</li>\n<li>ArrayList 是由数组来实现数据存储的</li>\n<li>ArrayList 基本等同于 Vector，除了 ArrayList 是线程不安全 (执行效率高) 看源码。在多线程情况下，不建议使用 ArrayList</li>\n</ul>\n<h1 id=\"arraylist扩容机制\"><a class=\"anchor\" href=\"#arraylist扩容机制\">#</a> ArrayList 扩容机制</h1>\n<ul>\n<li>ArrayList 中维护了一个 Object 类型的数组 elementData. [debug 看源码]<br />\ntransient Object[] elementData;</li>\n<li>当创建 ArrayList 对象时，如果使用的是无参构造器，则初始 elementData 容量为 0, 第 1 次添加，则扩容 elementData 为 10, 如需要再次扩容，则扩容 elementData 为 1.5 倍。</li>\n<li>如果使用的是指定大小的构造器，则初始 elementData 容量为指定大小，如果需要扩容，则直接扩容 elementData 为 1.5 倍。</li>\n</ul>\n<h1 id=\"vector底层结构和源码剖析\"><a class=\"anchor\" href=\"#vector底层结构和源码剖析\">#</a> Vector 底层结构和源码剖析</h1>\n<ul>\n<li>Vector 类的定义说明</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>public class Vector<span class=\"token operator\">&lt;</span>E<span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>extends AbstractList<span class=\"token operator\">&lt;</span>E<span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>implements List<span class=\"token operator\">&lt;</span>E<span class=\"token operator\">></span>, RandomAccess, Cloneable, Serializable</pre></td></tr></table></figure><ul>\n<li>Vector 底层也是一一个对象数组，protected Object [] elementData;</li>\n<li>Vector 是线程同步的，即线程安全，Vector 类的操作方法带有 synchronized</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>public synchronized E get<span class=\"token punctuation\">(</span>int index<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>index <span class=\"token operator\">></span> <span class=\"token operator\">=</span> elementCount<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        throw new ArrayIndexOutOfBoundsException<span class=\"token punctuation\">(</span>index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token builtin class-name\">return</span> elementData<span class=\"token punctuation\">(</span>index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>在开发中，需要线程同步安全时，考虑使用 Vector</li>\n</ul>\n<h1 id=\"linkedlist底层结构\"><a class=\"anchor\" href=\"#linkedlist底层结构\">#</a> LinkedList 底层结构</h1>\n<ul>\n<li>LinkedList 实现了双向链表和双端队列特点</li>\n<li>可以添加任意元素 (元素可以重复)，包括 null</li>\n<li>线程不安全，没有实现同步</li>\n</ul>\n<h1 id=\"linkedlist底层操作机制\"><a class=\"anchor\" href=\"#linkedlist底层操作机制\">#</a> LinkedList 底层操作机制</h1>\n<ul>\n<li>LinkedList 底层维护了一个双向链息</li>\n<li>LinkedList 中维护了两个属性 first 和 last 分别指向首节点和尾节点</li>\n<li>每个节点 (Node 对象) , 里面又维护了 prev、next、 item 三个属性，其中通过 prev 指向前一个，通过 next 指向后一个节点。最终实现双向链表.</li>\n<li>所以 LinkedList 的元素的添加和删除，不是通过数组完成的，相对来说效率较高。</li>\n<li>模拟一个简单的双向链表</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>LinkedList linkedList <span class=\"token operator\">=</span> new LinkedList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>LinkedList.add<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"LinkedList=\"</span> + LinkedList<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"arraylist和linkedlist比较\"><a class=\"anchor\" href=\"#arraylist和linkedlist比较\">#</a> ArrayList 和 LinkedList 比较</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>底层结构        增删的效率      改查的效率</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>ArrayList       可变数组        较低            较高    </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                                数组扩容</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>LinkedList      双向链表        较高            较低</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                                通过链表追加</pre></td></tr></table></figure><ul>\n<li>如果我们改查的操作多，选择 ArrayList</li>\n<li>如果我们增删的操作多，选择 LinkedList</li>\n<li>一般来说，在程序中，80%-90% 都是查询，因此大部分情况下会选择 ArrayList</li>\n<li>在一 个项目中，根据业务灵活选择，也可能这样，一个模块使用的是 ArrayList, 另外一个模块是 LinkedList.</li>\n</ul>\n<h1 id=\"set接口基本介绍\"><a class=\"anchor\" href=\"#set接口基本介绍\">#</a> Set 接口基本介绍</h1>\n<ul>\n<li>无序 (添加和取出的顺序不一致)，没有索引</li>\n<li>不允许重复元素，所以最多包含一个 null</li>\n<li>和 List 接口 - 样，Set 接口也是 Collection 的子接口，因此，常用方法和 Collection 接一样.</li>\n</ul>\n<h1 id=\"set接口遍历方式\"><a class=\"anchor\" href=\"#set接口遍历方式\">#</a> Set 接口遍历方式</h1>\n<ul>\n<li>同 Collection 的遍历方式样，因为 Set 接口是 Collection 接口的子接口。</li>\n</ul>\n<ol>\n<li>可以使用迭代器</li>\n<li>增强 for</li>\n<li>不能使用索引的方式来获取（因为没有索引）</li>\n</ol>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//1.以Set接口的实现类HashSet 来讲解Set接口的方法</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//2.</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>set接口的实现类的对象<span class=\"token punctuation\">(</span>Set接口对象<span class=\"token punctuation\">)</span>，不能存放重复的元素，可以添加一个nulL</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>//3.set接口对象存放数据是无序<span class=\"token punctuation\">(</span>即添加的顺序和取出的顺序不一一致<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>//4.注意:取出的顺序的顺序虽然不是添加的顺序，但是他固定.</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>Set <span class=\"token builtin class-name\">set</span> <span class=\"token operator\">=</span> new HashSet<span class=\"token punctuation\">(</span> <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>set.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"john\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>set.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"lLucy\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>set.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"john\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//重复</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>set.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"jack\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>set.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"hsp\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>set.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"hsp\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>set.add<span class=\"token punctuation\">(</span>nuLl<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>set.add<span class=\"token punctuation\">(</span>nulL<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//再次添加null</pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>//遍历</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>//方式1:使用迭代器</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"=====使用迭代器====\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>Iterator iterator <span class=\"token operator\">=</span> set.iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>iterator. hasNext<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span> <span class=\"token punctuation\">&#123;</span> </pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    Object obj <span class=\"token operator\">=</span> iterator.next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"obj=\"</span> + obj<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>//方式2:增强for</pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Object o <span class=\"token builtin class-name\">:</span> <span class=\"token builtin class-name\">set</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    System.out.print<span class=\"token punctuation\">(</span><span class=\"token string\">\"0=\"</span> + o<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h1 id=\"set接口实现类-hashset\"><a class=\"anchor\" href=\"#set接口实现类-hashset\">#</a> Set 接口实现类 - HashSet</h1>\n<ul>\n<li>HashSet 实现了 Set 接口</li>\n<li>HashSet 实际上是 HashMap，看下源码. (图)<br />\npublic HashSet() {<br />\nmap = new HashMap&lt;&gt;();<br />\n}</li>\n<li>可以存放 nul 值，但是只能有一个 null</li>\n<li>HashSet 不保证元素是有序的，取决于 hash 后，再确定索引的结果。(不保证存放元素的顺序和取出顺序一致)</li>\n<li>不能有重复元素 / 对象 (注意，判断的是哈希值（hashCode 是否一样），不一样才会认为是不同的，比如创建一个新的实例，就不会认为是同一个（就算成员一样）)</li>\n</ul>\n<h1 id=\"hashset扩容机制\"><a class=\"anchor\" href=\"#hashset扩容机制\">#</a> HashSet 扩容机制</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span>. HashSet底层是HashMap</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token number\">2</span>.添加一个元素时，先得到hash值会转成-<span class=\"token operator\">></span> 索引值</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token number\">3</span>.找到存储数据表table ,看这个索引位置是否已经存放的有元素</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token number\">4</span>.如果没有，直接加入</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token number\">5</span>.如果有，调用equals比较，如果相同，就放弃添加，如果不相同，则添加到最后</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token number\">6</span>.在Java8中，如果一条链表的元素个数超过TREEIFY THRESHOLD<span class=\"token punctuation\">(</span>默认是8<span class=\"token punctuation\">)</span>,并且table的大小<span class=\"token operator\">>=</span>MIN TREEIFY CAPACITY<span class=\"token punctuation\">(</span>默认64<span class=\"token punctuation\">)</span>,就会进行树化<span class=\"token punctuation\">(</span>红黑树<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"hashset实例\"><a class=\"anchor\" href=\"#hashset实例\">#</a> HashSet 实例</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>要重写equals和hashCode让其在看到完全相同的成员时返回相同的哈希值（实例里边的）</pre></td></tr></table></figure><h1 id=\"set接口实现类linkedhashset\"><a class=\"anchor\" href=\"#set接口实现类linkedhashset\">#</a> Set 接口实现类 LinkedHashSet</h1>\n<ul>\n<li>LinkedHashSet 是 HashSet 的子类</li>\n<li>LinkedHashSet 底层是一个 LinkedHashMap, 底层维护了一个数组 + 双向链表</li>\n<li>LinkedHashSet 根据元素的 hashCode 值来决定元素的存储位置，同时使用链表维护元素的次序 (图)，这使得元素看起来是以插入顺序保存的。</li>\n<li>LinkedHashSet 不允许添重复元素</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span>.在LinkedHastSet 中维护了一个hash表和双向链表<span class=\"token punctuation\">(</span> LinkedHashSet有head和tail <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token number\">2</span>.每一个节点有pre和next属性，这样可以形成双向链表</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token number\">3</span>.在添加一个元素时，先求hash值，在求索引.确定该元素在hashtable的位置，然后将添加的元素加入到双向链表<span class=\"token punctuation\">(</span>如果已经存在，不添加<span class=\"token punctuation\">[</span>原则和hashset-样<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>tail.next <span class=\"token operator\">=</span> newElement //简单指定</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>newElement.pre <span class=\"token operator\">=</span> <span class=\"token function\">tail</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token function\">tail</span> <span class=\"token operator\">=</span> newEelment<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token number\">4</span>.这样的话，我们遍历LinkedHashSet也能确保插入顺序和遍历顺序一致</pre></td></tr></table></figure><h1 id=\"map接口\"><a class=\"anchor\" href=\"#map接口\">#</a> Map 接口</h1>\n<ul>\n<li>Map 与 Collection 并列存在。用于保存具有映射关系的数据：Key-Value</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Map map <span class=\"token operator\">=</span> new HashMap<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"no1\"</span>, <span class=\"token string\">\"幽化猫\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//k-v</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"no2\"</span>, <span class=\"token string\">\"张无忌\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//k-v</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"map=\"</span> + map<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>Map 中的 key 和 value 可以是任何引用类型的数据，会封装到 HashMap$Node 对象中</li>\n<li>Map 中的 key 不允许重复，原因和 HashSet 一样</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Map map <span class=\"token operator\">=</span> new HashMap<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>map. put<span class=\"token punctuation\">(</span><span class=\"token string\">\"no1\"</span>, <span class=\"token string\">\"幽化猫\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//k-v</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>map <span class=\"token builtin class-name\">.</span> put<span class=\"token punctuation\">(</span><span class=\"token string\">\"no2\"</span>, <span class=\"token string\">\"张无忌\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//k-v</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"map=\"</span> + map<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>map. put<span class=\"token punctuation\">(</span><span class=\"token string\">\"no1\"</span>, <span class=\"token string\">\"张三丰\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//当有相同的k，就等价于替换.</pre></td></tr></table></figure><ul>\n<li>Map 中的 value 可以重复</li>\n<li>Map 的 key 可以为 null, value 也可以为 null , 注意 key 为 null, 只能有一个，value 为 null , 可以多个.</li>\n<li>常用 String 类作为 Map 的 key</li>\n<li>key 和 value 之间存在单向一对一关系，即通过指定的 key 总能找到对应的 value</li>\n</ul>\n<h1 id=\"map接口和常用方法\"><a class=\"anchor\" href=\"#map接口和常用方法\">#</a> Map 接口和常用方法</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>put:添加</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>remove:根据键删除映射关系</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>get:根据键获取值</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>size:获取元素个数</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>isEmpty:判断个数是否为0</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>clear:清除</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>containsKey:查找键是否存在</pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>Map map <span class=\"token operator\">=</span> new HashMap<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"邓超\"</span>，new Book<span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span>,100<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"邓超\"</span>，<span class=\"token string\">\"孙俪\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"王宝强\"</span>，<span class=\"token string\">\"马蓉\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"宋喆\"</span>，<span class=\"token string\">\"马蓉\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"刘令博\"</span>，null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>map.put<span class=\"token punctuation\">(</span>null,<span class=\"token string\">\"刘亦菲\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"鹿晗\"</span>，<span class=\"token string\">\"关晓彤\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>Object object <span class=\"token operator\">=</span> map.get<span class=\"token punctuation\">(</span><span class=\"token string\">\"邓超\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>map.remove<span class=\"token punctuation\">(</span><span class=\"token string\">\"鹿晗\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>System. out.println<span class=\"token punctuation\">(</span>map<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>boolean containsKey <span class=\"token operator\">=</span> map.containsKey<span class=\"token punctuation\">(</span>nulI<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>System. out.println<span class=\"token punctuation\">(</span>containsKey<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>9ystem. out.printmn<span class=\"token punctuation\">(</span>map.containsValue<span class=\"token punctuation\">(</span><span class=\"token string\">\"刘办菲\"</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>map.size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>map.isEmpty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>map.clear<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"map六大遍历方式\"><a class=\"anchor\" href=\"#map六大遍历方式\">#</a> Map 六大遍历方式</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Map map <span class=\"token operator\">=</span> new HashMap<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"邓超\"</span>，new Book<span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span>,100<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"邓超\"</span>，<span class=\"token string\">\"孙俪\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"王宝强\"</span>，<span class=\"token string\">\"马蓉\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"宋喆\"</span>，<span class=\"token string\">\"马蓉\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"刘令博\"</span>，null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>map.put<span class=\"token punctuation\">(</span>null,<span class=\"token string\">\"刘亦菲\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>map.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"鹿晗\"</span>，<span class=\"token string\">\"关晓彤\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>一</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//第一组: 先取出所有的Key,</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>通过Key取出对应的Value</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Set keyset <span class=\"token operator\">=</span> map.keySet<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>//<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>增强for</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"-----第一种 方式-------\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>0bject key <span class=\"token builtin class-name\">:</span> keyset<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span>key + <span class=\"token string\">\"-\"</span> + map.get<span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>二</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>System. out. printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"----第二二种方式---\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Iterator iterator <span class=\"token operator\">=</span> keyset <span class=\"token builtin class-name\">.</span> iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>iterator.hasNext<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Object key <span class=\"token operator\">=</span> iterator.next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>System。out. println<span class=\"token punctuation\">(</span>key + <span class=\"token string\">\"_\"</span> + map.get<span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>三</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>ColLection values <span class=\"token operator\">=</span> map 。values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//这 里可以使用所有的Collections使用的遍历 方法</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>增强for</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>System. out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"---取出所有的value----\"</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>0bject value <span class=\"token builtin class-name\">:</span> values<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    System <span class=\"token builtin class-name\">.</span> out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>四</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>System. out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span><span class=\"token string\">\"---取出所有的value迭代器----\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Iterator iterator2 <span class=\"token operator\">=</span> values. iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>iterator2. hasNext<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Object vaLue <span class=\"token operator\">=</span> iterator2.next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    System <span class=\"token builtin class-name\">.</span> out.printLn<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>五</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Set entrySet <span class=\"token operator\">=</span> map <span class=\"token builtin class-name\">.</span> entrySet<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>// EntrySet<span class=\"token operator\">&lt;</span>Map 。Entry<span class=\"token operator\">&lt;</span>K,V<span class=\"token operator\">>></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> 增强for</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>System. out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span><span class=\"token string\">\"----使用EntrySet的for增 强(第3种)----\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>0bject entry <span class=\"token builtin class-name\">:</span> entrySet<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>//将entry 转成Map. Entry</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>Map.Entry m <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>Map. Entry<span class=\"token punctuation\">)</span> entry<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span>m <span class=\"token builtin class-name\">.</span> getKey<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> + <span class=\"token string\">\"-\"</span> + m. getValue<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><ul>\n<li>六</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"----使用EntrySet的迭代器(第4种)----\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Iterator iterator3 <span class=\"token operator\">=</span> entrySet <span class=\"token builtin class-name\">.</span> iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>iterator3. hasNext<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    Object entry <span class=\"token operator\">=</span> iterator3.next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    //System <span class=\"token builtin class-name\">.</span> out。printLn<span class=\"token punctuation\">(</span>next <span class=\"token builtin class-name\">.</span> getClass<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span> //HashMap<span class=\"token variable\">$Node</span> - 实现-<span class=\"token operator\">></span> Map <span class=\"token builtin class-name\">.</span> Entry <span class=\"token punctuation\">(</span>getKey, getValue <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    //向下转型Map. Entry</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    Map.Entry m <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>Map <span class=\"token builtin class-name\">.</span> Entry<span class=\"token punctuation\">)</span> entry<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    System. out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span>m. getKey<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> + <span class=\"token string\">\"_\"</span> + m. getVaLue<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h1 id=\"hashmap小结\"><a class=\"anchor\" href=\"#hashmap小结\">#</a> HashMap 小结</h1>\n<ul>\n<li>Map 接的常用实现类: HashMap、Hashtable 和 Properties.</li>\n<li>HashMap 是 Map 接口使用频率最高的实现类。</li>\n<li>HashMap 是以 key-val 对的方式来存储数据 [案例 Entry]</li>\n<li>key 不能重复，但是是值可以重复，允许使用 null 键和 nulI 值。</li>\n<li>如果添加相同的 key，则会覆盖原来的 key-val , 等同于修改.(key 不会替换，val 会替换)</li>\n<li>与 HashSet - 样，不保证映射的顺序，因为底层是以 hash 表的方式来存储的.</li>\n<li>HashMap 没有实现同步，因此是线程不安全的</li>\n<li>也会进行扩容，当他自己的一个元素有超过八个节点，就会将数组扩容到 64</li>\n</ul>\n<h1 id=\"hashtable的基本介绍\"><a class=\"anchor\" href=\"#hashtable的基本介绍\">#</a> HashTable 的基本介绍</h1>\n<ul>\n<li>存放的元素是键值对：即 K-V</li>\n<li>hashtable 的键和值都不能为 null</li>\n<li>hashTable 使用方法基本上和 HashMap - 样</li>\n<li>hashTable 是线程安全的，hashMap 是线程不安全的</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Hashtable table <span class=\"token operator\">=</span> new Hashtable<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//ok </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>table.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"john\"</span>, <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> //ok</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>table.put<span class=\"token punctuation\">(</span>null, <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> //异常</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>table.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"john\"</span>, nul<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//异常</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>table.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"lucy\"</span>, <span class=\"token number\">100</span><span class=\"token punctuation\">)</span>:<span class=\"token punctuation\">;</span>//ok</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>table.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"lic\"</span>, <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//ok</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>table.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"lic\"</span>, <span class=\"token number\">88</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//替换</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"hashtable扩容机制\"><a class=\"anchor\" href=\"#hashtable扩容机制\">#</a> HashTable 扩容机制</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//简单说明一下Hashtable的底层</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//1.底层有数组Hashtable<span class=\"token variable\">$Entry</span><span class=\"token punctuation\">[</span> <span class=\"token punctuation\">]</span>初始化大小为11</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//2.临界值threshold <span class=\"token number\">8</span> <span class=\"token operator\">=</span> <span class=\"token number\">11</span> * <span class=\"token number\">0.75</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>//3.扩容:按照自己的扩容机制来进行即可。</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>//4.执行方法addEntry<span class=\"token punctuation\">(</span>hash, key, value, index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> 添加K-V封装到Entry</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>//5.当if <span class=\"token punctuation\">(</span>count <span class=\"token operator\">>=</span> threshoLd<span class=\"token punctuation\">)</span> 满足时，就进行扩容</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>//5.按照int newCapacity <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>oldCapacity <span class=\"token operator\">&lt;&lt;</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> + <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> 的大小扩容.</pre></td></tr></table></figure><h1 id=\"map接口实现类properties\"><a class=\"anchor\" href=\"#map接口实现类properties\">#</a> Map 接口实现类 Properties</h1>\n<ul>\n<li>Properties 类继承自 Hashtable 类并且实现了 Map 接口，也是使用一种键值对的形式来保存数据。</li>\n<li>他的使用特点和 Hashtable 类似</li>\n<li>Properties 还可以用于从 xxx.properties 文件中，加载数据到 Properties 类对象，并进行读取和修改</li>\n<li>说明：工作后 xxx.properties 文件通常作为配置文件，这个知识点在 IO 流举例</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//1. Properties 继承HashtabLe</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//2. 可以通过k-V存放数据，当然key和value 不能为nu1l</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//增加</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Properties properties <span class=\"token operator\">=</span> new</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>Properties<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>/ /properties。put<span class=\"token punctuation\">(</span>null, <span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//抛出 空指针异常</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>//properties. put<span class=\"token punctuation\">(</span><span class=\"token string\">\"abc\"</span>, nuLl<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> //抛出空指针异常</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>properties <span class=\"token builtin class-name\">.</span> put<span class=\"token punctuation\">(</span><span class=\"token string\">\"john\"</span>, <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//k-V</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>properties. put<span class=\"token punctuation\">(</span><span class=\"token string\">\"Lucy\"</span>, <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>properties <span class=\"token builtin class-name\">.</span> put<span class=\"token punctuation\">(</span><span class=\"token string\">\"Tic\"</span>, <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>properties. put<span class=\"token punctuation\">(</span><span class=\"token string\">\"Lir\"</span>, <span class=\"token number\">88</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//如果有相同的key，value被替换</pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>//删除</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>properties.remove<span class=\"token punctuation\">(</span><span class=\"token string\">\"lic\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>//改</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>properties.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"john\"</span>, <span class=\"token string\">\"北京大学\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>properties<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>//查</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>System.out.printIn<span class=\"token punctuation\">(</span>properties.get<span class=\"token punctuation\">(</span><span class=\"token string\">\"john\"</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>System.out.printin<span class=\"token punctuation\">(</span>properties.getProperty<span class=\"token punctuation\">(</span><span class=\"token string\">\"john\"</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"如何进行选择\"><a class=\"anchor\" href=\"#如何进行选择\">#</a> 如何进行选择</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span>）先判断存储的类型<span class=\"token punctuation\">(</span>一组对象或一组键值对<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token number\">2</span>）一-组对象: Collection接口</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>允许重复: List</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    增删多: LinkedList <span class=\"token punctuation\">[</span>底层维护了一个双向链表<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    改查多: ArrayList <span class=\"token punctuation\">[</span>底层维护Object类型的可变数组<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>不允许重复: Set</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    无序: HashSet <span class=\"token punctuation\">[</span>底层是HashMap ，维护了一个哈希表即<span class=\"token punctuation\">(</span>数组+链表+红黑树<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    排序: TreeSet</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    插入和取出顺序一致: LinkedHashSet ， 维护数组+双向链表</pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token number\">3</span>）一组键值对: Map</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    键无序: HashMap <span class=\"token punctuation\">[</span>底层是:哈希表jdk7: 数组+链表，jdk8: 数组+链表+红黑树<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    键排序: TreeMap</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    键插入和取出顺序-致: LinkedHashMap</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    读取文件Properties</pre></td></tr></table></figure><h1 id=\"treemap\"><a class=\"anchor\" href=\"#treemap\">#</a> TreeMap</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//使用默认的构造器，创建TreeMap,是无序的<span class=\"token punctuation\">(</span>也没有排序<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>TreeMap treeMap <span class=\"token operator\">=</span> new</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>TreeMap<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>treeMap. put<span class=\"token punctuation\">(</span><span class=\"token string\">\"jack\"</span>, <span class=\"token string\">\"杰克\"</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>treeMap. put<span class=\"token punctuation\">(</span><span class=\"token string\">\"tqm\"</span>,<span class=\"token string\">\"汤姆\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>treeMap.put<span class=\"token punctuation\">(</span><span class=\"token string\">\"kristina\"</span>,<span class=\"token string\">\"克瑞斯提诺\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>treeMap. put<span class=\"token punctuation\">(</span><span class=\"token string\">\"smith\"</span>, <span class=\"token string\">\"斯密斯\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>System. out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span><span class=\"token string\">\"treemap=\"</span> + treeMap<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>按照传入的k<span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">)</span>的大小进行排序</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>TreeMap treeMap <span class=\"token operator\">=</span> new TreeMap<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>TreeMap treeMap <span class=\"token operator\">=</span> new TreeMap <span class=\"token punctuation\">(</span>new Comparator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    @override</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    public int compare<span class=\"token punctuation\">(</span>0bject o1, object o2<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        //按照传入的k<span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">)</span> 的大小进行排序</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        <span class=\"token builtin class-name\">return</span> <span class=\"token punctuation\">((</span>String<span class=\"token punctuation\">)</span>o1<span class=\"token punctuation\">)</span> <span class=\"token builtin class-name\">.</span> compareTo<span class=\"token punctuation\">((</span>String<span class=\"token punctuation\">)</span>o2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>TreeMap treeMap <span class=\"token operator\">=</span> new TreeMap <span class=\"token punctuation\">(</span>new <span class=\"token function-name function\">Comparator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    @override</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    public int compare<span class=\"token punctuation\">(</span>0bject o1, object o2<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        //按照传入的k<span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">)</span> 的长度大小进行排序</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        <span class=\"token builtin class-name\">return</span> <span class=\"token punctuation\">((</span>String<span class=\"token punctuation\">)</span>o1<span class=\"token punctuation\">)</span>.length<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> -<span class=\"token punctuation\">((</span>String<span class=\"token punctuation\">)</span>o2<span class=\"token punctuation\">)</span>.length<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"collections工具类\"><a class=\"anchor\" href=\"#collections工具类\">#</a> Collections 工具类</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//创建ArrayList集合，用于测试。</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>L ist list <span class=\"token operator\">=</span> new</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>ArrayList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>list.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"tom\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>List.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"smith\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>list.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"king\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>tist.add<span class=\"token punctuation\">(</span><span class=\"token string\">\"'milan\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>reverse<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">)</span>:反转List 中元素的顺序</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>Collections <span class=\"token builtin class-name\">.</span> reverse<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"List=\"</span> + List<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>shuffle<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">)</span>:对List 集合元素进行随机排序</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>for<span class=\"token punctuation\">(</span>inti<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span>i<span class=\"token operator\">&lt;</span><span class=\"token number\">5</span><span class=\"token punctuation\">;</span>i++<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    ColLections .shuffle<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    System. out. printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"tist=\"</span> + List<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>sort<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">)</span>:根据元素的自然顺序对指定List 集合元素按升序排序</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>ColLections.sort<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>System. out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span><span class=\"token string\">\"自然排序后\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out. println<span class=\"token punctuation\">(</span><span class=\"token string\">\"list=\"</span> + list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>sort<span class=\"token punctuation\">(</span>List, Comparator<span class=\"token punctuation\">)</span>: 根据指定的Comparator 产生的顺序对List 集合元素</pre></td></tr><tr><td data-num=\"27\"></td><td><pre>//我们希望按照字符串的长度大小排序</pre></td></tr><tr><td data-num=\"28\"></td><td><pre>ColLections <span class=\"token builtin class-name\">.</span> sort<span class=\"token punctuation\">(</span>list, new <span class=\"token function-name function\">Comparator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>        @override</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        public int compare<span class=\"token punctuation\">(</span>0bject o1, Object o2<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        <span class=\"token builtin class-name\">return</span> <span class=\"token punctuation\">((</span>String<span class=\"token punctuation\">)</span>o1<span class=\"token punctuation\">)</span>.Length<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> 一 <span class=\"token punctuation\">((</span>String<span class=\"token punctuation\">)</span>o2<span class=\"token punctuation\">)</span>.Length<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>swap<span class=\"token punctuation\">(</span>List, int, int<span class=\"token punctuation\">)</span>:将指定list集合中的i处元素和j处元素进行交换</pre></td></tr><tr><td data-num=\"36\"></td><td><pre>Object max<span class=\"token punctuation\">(</span>Collection<span class=\"token punctuation\">)</span>:根据元素的自然顺序，返回给定集合中的最大元素</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>Object max<span class=\"token punctuation\">(</span>Collection, Comparator<span class=\"token punctuation\">)</span>: 根据Comparator指定的顺序，返回给定集合中的最大元素</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>Object min<span class=\"token punctuation\">(</span>Collection<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>Object min<span class=\"token punctuation\">(</span>Collection, Comparator<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>int frequency<span class=\"token punctuation\">(</span>Collection, Object<span class=\"token punctuation\">)</span>: 返回指定集合中指定元素的出现次数</pre></td></tr><tr><td data-num=\"41\"></td><td><pre>void copy<span class=\"token punctuation\">(</span>List dest,List src<span class=\"token punctuation\">)</span>: 将src中的内容复制到dest中</pre></td></tr><tr><td data-num=\"42\"></td><td><pre>boolean replaceAll<span class=\"token punctuation\">(</span>List list, Object oldVal, Object newVal<span class=\"token punctuation\">)</span>:使用新值替换List对象的所有旧值</pre></td></tr></table></figure>",
            "tags": [
                "学习Java",
                "Java基础",
                "java"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/01/Java/Java%E5%9F%BA%E7%A1%80/Math%E7%B1%BB/",
            "url": "https://love.youhuamao.xyz/2022/11/01/Java/Java%E5%9F%BA%E7%A1%80/Math%E7%B1%BB/",
            "title": "Math类",
            "date_published": "2022-10-31T16:00:00.000Z",
            "content_html": "<h1 id=\"math类常见方法\"><a class=\"anchor\" href=\"#math类常见方法\">#</a> Math 类常见方法</h1>\n<ul>\n<li>均为静态方法</li>\n<li>abs 绝对值</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>int abs <span class=\"token operator\">=</span> Math.abs<span class=\"token punctuation\">(</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>abs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>pow 求幂</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>double pow <span class=\"token operator\">=</span> Math.pow<span class=\"token punctuation\">(</span>-3.5, <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>pow<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>ceil 向上取整</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//3.ceil向上取整,返回<span class=\"token operator\">></span> <span class=\"token operator\">=</span>该参数的最小整数<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>double ceil <span class=\"token operator\">=</span> Math.ceil<span class=\"token punctuation\">(</span>-3.0001<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Svstem.out. println<span class=\"token punctuation\">(</span>ceil<span class=\"token punctuation\">)</span>:</pre></td></tr></table></figure><ul>\n<li>floor 向下取整</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//4.floor向下取整，返回<span class=\"token operator\">&lt;</span> <span class=\"token operator\">=</span>该参数的最大整数</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>double floor <span class=\"token operator\">=</span> Math.floor<span class=\"token punctuation\">(</span>-4.999<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>floor<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>round 四舍五入</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//5.round四舍五入Math.floor<span class=\"token punctuation\">(</span>该参数+ <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>long round <span class=\"token operator\">=</span> Math.round<span class=\"token punctuation\">(</span>-5.001<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>round<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>sqrt 求开方</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>double sqrt <span class=\"token operator\">=</span> Math.sqrt<span class=\"token punctuation\">(</span>-9.0<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>sqrt<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>random 求随机数 // 思考：请写出获取 a-b 之间的一个随机整数，a,b 均为整数？2-7</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//7.random返回随机数<span class=\"token punctuation\">[</span><span class=\"token number\">0</span>--1<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//<span class=\"token punctuation\">[</span>a-b<span class=\"token punctuation\">]</span>:int num <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>int<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>Math.random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>* <span class=\"token punctuation\">(</span>b-a+1<span class=\"token punctuation\">)</span> +a<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>double random <span class=\"token operator\">=</span> Math.random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>max 求两个数的最大值</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>int abs <span class=\"token operator\">=</span> Math.abs<span class=\"token punctuation\">(</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>abs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>min 求两个数的最小值</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>int abs <span class=\"token operator\">=</span> Math.abs<span class=\"token punctuation\">(</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>abs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure>",
            "tags": [
                "学习Java",
                "Java基础",
                "java"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/01/Java/Java%E5%9F%BA%E7%A1%80/Arrays,%E5%A4%A7%E6%95%B0,%E6%97%A5%E6%9C%9F/",
            "url": "https://love.youhuamao.xyz/2022/11/01/Java/Java%E5%9F%BA%E7%A1%80/Arrays,%E5%A4%A7%E6%95%B0,%E6%97%A5%E6%9C%9F/",
            "title": "Arrays,大数,日期",
            "date_published": "2022-10-31T16:00:00.000Z",
            "content_html": "<h1 id=\"arrays\"><a class=\"anchor\" href=\"#arrays\">#</a> Arrays</h1>\n<p>Arrays 里面包含了 - - 系列静态方法，用于管理或操作数组 (比如排序和搜索)。</p>\n<ul>\n<li>toString 返回数组的字符串形式<br />\n Arrays.toString (arr)</li>\n<li>sort 排序 (自然排序和定制排序) Integer arr [] = {1,-1, 7, 0, 89};</li>\n<li>binarySearch 通过二分搜索法进行查找，要求必须排好序<br />\n int index = Arrays.binarySearch (arr, 3);</li>\n<li>copyOf 数组元素的复制<br />\n Integer [] newArr = Arrays.copyOf (arr, arr.length);</li>\n<li>fill 数组元素的填充<br />\n Integer [] num = new Integer<span 9,3,2=\"\"></span>;<br />\nArrays.fill(num, 99);</li>\n<li>equals 比较两个数组元素内容是否完全<br />\n致<br />\n boolean equals = Arrays.equals (arr, arr2);</li>\n<li>asList 将一组值，转换成 list<br />\nList&lt; Integer&gt; asList = Arrays.asList(2,3,4,5,6, 1);<br />\nSystem.out.println(&quot;asList=&quot; + asList);</li>\n</ul>\n<h1 id=\"system类\"><a class=\"anchor\" href=\"#system类\">#</a> System 类</h1>\n<ul>\n<li>exit 退出当前程序</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//exit 退出当前程序</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"ok1\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//老韩解读</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>//exit<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> 表示程序退出</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>//0表示一个状态 正常的状态</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>System.exit<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//</pre></td></tr></table></figure><ul>\n<li>arraycopy : 复制数组元素，比较适合底层调用，一般使用 Arrays.copyOf 完成复制数组.</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>int<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token assign-left variable\">src</span><span class=\"token operator\">=</span><span class=\"token punctuation\">&#123;</span><span class=\"token number\">1,2</span>,3<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>int<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> dest <span class=\"token operator\">=</span> new int<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>System.arraycopy<span class=\"token punctuation\">(</span>src, <span class=\"token number\">0</span>, dest, <span class=\"token number\">0</span>, <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"dest=\"</span> + Arrays.toString<span class=\"token punctuation\">(</span>dest<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//<span class=\"token punctuation\">[</span><span class=\"token number\">0</span>, <span class=\"token number\">2</span>, <span class=\"token number\">3</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>//源数组</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>//* @param  src   the <span class=\"token builtin class-name\">source</span> array。</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>//srcPos:从源数组的哪个索引位置开始拷贝</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>//* @param  srcPos  starting position <span class=\"token keyword\">in</span> the <span class=\"token builtin class-name\">source</span> array 。</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>//dest:目标数组，即把源数组的数据拷贝到哪个数组</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>//* @param dest    the destination array <span class=\"token builtin class-name\">.</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>//destPos:把源数组的数据拷贝到目标数组的哪个索引</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>//* @param destPos  starting position <span class=\"token keyword\">in</span> the destination data 。</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>//Length:从源数组拷贝多少个数据到目标数组</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>//* @param  Length </pre></td></tr><tr><td data-num=\"16\"></td><td><pre>the number of array eLements to be copied.</pre></td></tr></table></figure><ul>\n<li>currentTimeMillens: 返回当前时间距离 1970-1-1 的毫秒数</li>\n<li>gc: 运行垃圾回收机制 System.gc (0;</li>\n</ul>\n<h1 id=\"大数处理biginteger和bigdecimal类\"><a class=\"anchor\" href=\"#大数处理biginteger和bigdecimal类\">#</a> 大数处理（BigInteger 和 BigDecimal 类）</h1>\n<p>BigInteger 适合保存比较大的整型<br />\n BigDecimal 适合保存精度更高的浮点型 (小数)</p>\n<h1 id=\"biginteger和bigdecimal类常见方法\"><a class=\"anchor\" href=\"#biginteger和bigdecimal类常见方法\">#</a> BigInteger 和 BigDecimal 类常见方法</h1>\n<ul>\n<li>add 加</li>\n<li>subtract 减</li>\n<li>multiply 乘</li>\n<li>divide 除</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>BigInteger b1 <span class=\"token operator\">=</span> new BigInteger<span class=\"token punctuation\">(</span><span class=\"token string\">\"1234567890\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>BigInteger b2 <span class=\"token operator\">=</span> new BigInteger<span class=\"token punctuation\">(</span><span class=\"token string\">\"200\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>// <span class=\"token number\">2</span>.调用常见的运算方法</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>// System.out.println<span class=\"token punctuation\">(</span>b1 + b2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>不能使用这样的+方法运行</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>b1.add<span class=\"token punctuation\">(</span>b2<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//加</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>b1.subtract<span class=\"token punctuation\">(</span>b2<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//减</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>b1.multiply<span class=\"token punctuation\">(</span>b2<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//乘</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>b1.divide<span class=\"token punctuation\">(</span>b2<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//除</pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>BigDecimal b1 <span class=\"token operator\">=</span> new BigDecimal<span class=\"token punctuation\">(</span><span class=\"token string\">\" 1234567890.567\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>BigDecimal b2 <span class=\"token operator\">=</span> new BigDecimal<span class=\"token punctuation\">(</span><span class=\"token string\">\" 123\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>/ <span class=\"token number\">2</span>.调用常见的运算方法</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>”System.out.println<span class=\"token punctuation\">(</span>b1 +b2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>不能使用+号运算<span class=\"token punctuation\">..</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>b1 .add<span class=\"token punctuation\">(</span>b2<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//加</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>b1.subtract<span class=\"token punctuation\">(</span>b2<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//减</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>b1.multiply<span class=\"token punctuation\">(</span>b2<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>//乘</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>//后面这个BigDecimal.ROUND CEILING需要指定，是精度</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>//没有这个参数，则会提示:错误</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>//在调用divide方法时，指定精度即可。BigDecimal. ROUND_ CEILING</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>//如果有无限循环小数，就会保留分子的精度</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>b1.divide<span class=\"token punctuation\">(</span>b2, BigDecimal.ROUND_CEILING<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span>// 除</pre></td></tr></table></figure><h1 id=\"date\"><a class=\"anchor\" href=\"#date\">#</a> Date</h1>\n<ul>\n<li>Date: 精确到毫秒，代表特定的瞬间</li>\n<li>SimpleDateFormat: 格式和解析日期的类 SimpleDateFormat 格式化和解析日期的具体类。它允许进行格式化 (日期 -&gt; 文本) 解析 (文本 -&gt; 日期) 和规范化.</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//1.获取当前系统时间</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//2.这里的Date 类是在java。util包</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//3.默认输出的日期格式是国外的方式，因此通常需要对格式进行转换</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Date d1 <span class=\"token operator\">=</span> new Date<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//获取当前系统时间</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"当前日期=\"</span> + d1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>//</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>Date d2 <span class=\"token operator\">=</span> new Date<span class=\"token punctuation\">(</span><span class=\"token number\">9234567</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> //通过指定毫秒数得到时间</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>//</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span>d1.getTime<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span> //获取某个时间对应的亳秒数</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>SimpLeDateFormat sdf <span class=\"token operator\">=</span> new SimpLeDateFormat<span class=\"token punctuation\">(</span> <span class=\"token string\">\"yyyy年MM月dd日hh:mm:ss E\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>String <span class=\"token function\">format</span> <span class=\"token operator\">=</span> sdf.format<span class=\"token punctuation\">(</span>d1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> // format:将日期转换成指定格式的字符串</pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>//1. 可以把一个格式化的String 转成对应的Date</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>String S <span class=\"token operator\">=</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token string\">\"1996年01月01日10:20:30 星期一\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>Date parse <span class=\"token operator\">=</span> sdf.parse<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"日期类\"><a class=\"anchor\" href=\"#日期类\">#</a> 日期类</h1>\n<ul>\n<li>第二代日期类，主要就是 Calendar 类 (日历)。</li>\n<li>Calendar 类是一 个抽象类，它为特定瞬间导一 组诸如 YEAR、 MONTH、DAY OF MONTH、HOUR 等日历字段之间的转换提供了些方法， 并为操作日历字段 (例如获得下星期的日期) 提供了一些方法。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span>.CaLendar是一个抽象类，并且构造器是private</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token number\">2</span>.可以通过getInstance<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> 来获取实例</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//2. 获取日历对象的某个日历字段</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>CaLendar c <span class=\"token operator\">=</span> CaLendar <span class=\"token builtin class-name\">.</span> getInstance<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> //创建日历类对象//比较简单，自由</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>System. out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>System .out. printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"年: \"</span> + c. get<span class=\"token punctuation\">(</span>CaLendar. YEAR<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>System. out. printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"月:\"</span>+ <span class=\"token punctuation\">(</span>c. get<span class=\"token punctuation\">(</span>CaLendar .MONTH<span class=\"token punctuation\">)</span> + <span class=\"token number\">1</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>System. out. printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"日:\"</span>+ c.get <span class=\"token punctuation\">(</span>CaLendar.DAY_0F_MONTH<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>System. out. printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"小时:\"</span>+ C. get <span class=\"token punctuation\">(</span>CaLendar <span class=\"token builtin class-name\">.</span> HOUR<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out. println<span class=\"token punctuation\">(</span><span class=\"token string\">\"分钟:\"</span>+ c.get<span class=\"token punctuation\">(</span>CaLendar .MINUTE<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out。printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"秒:\"</span>+ C. get <span class=\"token punctuation\">(</span>CaLendar. SECOND<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>//Calender没有专门的格式化方法，所以需要程序员自己来组合显示</pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>//Calender没有专门的格式化方法，所以需要程序员自己来组合显示</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>System. out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span>c <span class=\"token builtin class-name\">.</span> get<span class=\"token punctuation\">(</span>CaLendar.YEAR<span class=\"token punctuation\">)</span> + <span class=\"token string\">\"年\"</span> + <span class=\"token punctuation\">(</span>c. get<span class=\"token punctuation\">(</span>CaLendar .MONTH<span class=\"token punctuation\">)</span> + <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> + <span class=\"token string\">\"月\"</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ul>\n<li>Calendar 问题</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>可变性:像日期和时间这样的类应该是不可变的。</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>偏移性: Date中的年份是从1900开始的，而月份都从0开始。</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>格式化:格式化只对Date有用，Calendar则不行。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>此外，它们也不是线程安全的:不能处理闰秒等<span class=\"token punctuation\">(</span>每隔2天，多出1s<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"第三代日期类\"><a class=\"anchor\" href=\"#第三代日期类\">#</a> 第三代日期类</h1>\n<ul>\n<li>LocalDate (日期 / 年月日)、LocalTime (时间 / 时分秒)、 LocalDateTime (日期时间 / 年月日时分秒分 JDK8 加入</li>\n<li>LocalDate 只包含日期，可以获取日期字段<br />\n LocalTime 只包含时间，可以获取时间字段<br />\n LocalDateTime 包含日期 + 时间，可以获取日期和时间字段</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>LocaLDateTime Ldt <span class=\"token operator\">=</span> LocaLDateTime .now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> //LocaLDate 。now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//LocaLTime <span class=\"token builtin class-name\">.</span> now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>System. out <span class=\"token builtin class-name\">.</span> println<span class=\"token punctuation\">(</span>Ldt<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>System.out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"年=\"</span> + Ldt.getYear<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"月=\"</span> + Ldt .getMonth<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"月=\"</span> + Ldt. getMonthValue<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>System.out.println<span class=\"token punctuation\">(</span><span class=\"token string\">\"日=\"</span> + Ldt. getDayOfMonth<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"时=\"</span> + Ldt <span class=\"token builtin class-name\">.</span> getHour<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"分=\"</span> + Ldt. getMinute<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"秒=\"</span> + Ldt <span class=\"token builtin class-name\">.</span> getSecond<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>LocaLDate now <span class=\"token operator\">=</span> LogaLDate.now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span>now.getYear<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>日期类格式</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>LocalDateTime ldt <span class=\"token operator\">=</span> LocalDateTime.now0<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//关于DateTimeFormatter的各个格式参数，需要看jdk8的文档.</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Date TimeFormatter dtf <span class=\"token operator\">=</span> Date TimeFormatter. ofPattern<span class=\"token punctuation\">(</span><span class=\"token string\">\"yyyy年MM月dd日HHI时mm分钟ss秒\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>String strDate <span class=\"token operator\">=</span> dtf.format<span class=\"token punctuation\">(</span>ldt<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>Instant 时间戳</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>类似于Date</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>提供了一系列和Date类转换的方式</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Instant --<span class=\"token operator\">></span> Date:</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Date <span class=\"token function\">date</span> <span class=\"token operator\">=</span> Date.from<span class=\"token punctuation\">(</span>instant<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>Date --<span class=\"token operator\">></span> Instant:</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>Instant instant <span class=\"token operator\">=</span> date.tolnstant<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>//1.通过静态方法now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>获取表示当前时间戳的对象</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>Instant now <span class=\"token operator\">=</span> Instant.now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>System.out.printLn<span class=\"token punctuation\">(</span>now<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>//2.通过from可以把Instant转成Date</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>Date <span class=\"token function\">date</span> <span class=\"token operator\">=</span> Date.from <span class=\"token punctuation\">(</span>now<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>//3.通过date的toInstant<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>可以把date 转成Instant对象</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>Instant instant <span class=\"token operator\">=</span> date.toInstant<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>//提供pLus和minus方法可以对当前时间进行加或者减</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>//看看890天后，是什么时候把年月日-时分秒</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>LocaLDateTime LocalDateTime <span class=\"token operator\">=</span> Ldt. pLusDays<span class=\"token punctuation\">(</span><span class=\"token number\">890</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>System <span class=\"token builtin class-name\">.</span> out <span class=\"token builtin class-name\">.</span> printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"890天后=\"</span>+ dateTimeFormatter <span class=\"token builtin class-name\">.</span> format<span class=\"token punctuation\">(</span>LocaLDateTime<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>//看看在3456分钟前是什么时候，把年月日-时分秒输出</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>LocaLDateTime LocaLDateTime2 <span class=\"token operator\">=</span> Ldt 。minusMinutes <span class=\"token punctuation\">(</span><span class=\"token number\">3456</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>System. out.printLn<span class=\"token punctuation\">(</span><span class=\"token string\">\"3456分钟前日期=\"</span> + dateTimeFormatter. <span class=\"token function\">format</span> <span class=\"token punctuation\">(</span>LocaLDateTime2<span class=\"token punctuation\">))</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure>",
            "tags": [
                "学习Java",
                "Java基础",
                "java"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/11/01/ai/Andrew%20Ng%20Lesson/%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/",
            "url": "https://love.youhuamao.xyz/2022/11/01/ai/Andrew%20Ng%20Lesson/%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/",
            "title": "介绍和基本概念",
            "date_published": "2022-10-31T16:00:00.000Z",
            "content_html": "<h1 id=\"机器学习是什么\"><a class=\"anchor\" href=\"#机器学习是什么\">#</a> 机器学习是什么</h1>\n<h2 id=\"机器学习的定义\"><a class=\"anchor\" href=\"#机器学习的定义\">#</a> 机器学习的定义</h2>\n<ul>\n<li>Arthur Samuel (1959). Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.<br />\n 机器学习：在进行特定编程的情况下，给予计算机学习能力的领域。</li>\n<li>Tom Mitchell (1998) Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.<br />\n 卡内基梅隆大学 Tom 定义：一个程序被认为能从经验 E 中学习，解决任务 T，达到性能度量值 P，当且仅当，有了经验 E 后，经过 P 评判，程序在处理 T 时的性能有所提升。</li>\n</ul>\n<h2 id=\"机器学习算法\"><a class=\"anchor\" href=\"#机器学习算法\">#</a> 机器学习算法</h2>\n<ul>\n<li>\n<p>Supervised Learning 监督学习：学习数据带有标签</p>\n</li>\n<li>\n<p>Unsupervised Learning 无监督学习：没有任何的标签，或者有相同的标签。已知数据集，不知如何处理，也未告知每个数据点是什么。<br />\n<img data-src=\"/pic/wuenda/542362-20181026165456165-1973271475.png\" alt=\"fenlei.png\" /><img data-src=\"/pic/wuenda/julei.png\" alt=\"julei.png\" /><br />\n（下边的例子，无监督学习将数据划分为两个集合，也就是聚类 clustering algorithm）</p>\n</li>\n<li>\n<p>Reinforcement learning 强化学习</p>\n</li>\n<li>\n<p>recommender systems 推荐系统</p>\n</li>\n</ul>\n<h2 id=\"为什么要学习为什么使用\"><a class=\"anchor\" href=\"#为什么要学习为什么使用\">#</a> 为什么要学习为什么使用，</h2>\n<ul>\n<li>If you actually tried to develop a machine learning system, how to make those best practices type decisions about the way in which you build your system. 如何在构建机器学习系统的时候选择最好的实践类型决策，节省时间。</li>\n</ul>\n<h1 id=\"监督学习\"><a class=\"anchor\" href=\"#监督学习\">#</a> 监督学习</h1>\n<h2 id=\"regression回归问题预测结果是连续的输出值\"><a class=\"anchor\" href=\"#regression回归问题预测结果是连续的输出值\">#</a> Regression 回归问题：预测结果是连续的输出值</h2>\n<p>在历史房价数据的基础上，预测房屋价格。可以使用直线拟合（粉色），也可以使用二次曲线拟合（蓝色）。<br />\n<img data-src=\"/pic/wuenda/jianduxuexi-01.png\" alt=\"fenlei.png\" /><br />\n 监督学习：基于已有的正确结果      回归问题：预测连续的输出值</p>\n<h2 id=\"classification分类问题预测结果是离散的多个值\"><a class=\"anchor\" href=\"#classification分类问题预测结果是离散的多个值\">#</a> Classification 分类问题：预测结果是离散的多个值</h2>\n<p><img data-src=\"/pic/wuenda/jianduxuexi-02.png\" alt=\"img.png\" /><br />\n 下图是基于两个特征（两个维度）进行预测的例子， 右边是其他可能维度（维度可能有无穷多个）<br />\n<img data-src=\"/pic/wuenda/jianduxuexi-03.png\" alt=\"img.png\" /></p>\n<h2 id=\"区分-分类问题和回归问题\"><a class=\"anchor\" href=\"#区分-分类问题和回归问题\">#</a> 区分 “分类问题” 和 “回归问题”</h2>\n<p><img data-src=\"/pic/wuenda/jianduxuexi-04.png\" alt=\"img.png\" /></p>\n<h1 id=\"无监督学习\"><a class=\"anchor\" href=\"#无监督学习\">#</a> 无监督学习</h1>\n<h2 id=\"聚类算法clustering-algorithm-在现实生活中的应用\"><a class=\"anchor\" href=\"#聚类算法clustering-algorithm-在现实生活中的应用\">#</a> 聚类算法 clustering algorithm 在现实生活中的应用</h2>\n<p>1、Google News 每天将爬来的网址分为一个个的新闻专题。<br />\n2、基因信息分组。<br />\n<img data-src=\"/pic/wuenda/wujianduxuexi-01.png\" alt=\"img.png\" /><br />\n3、组织大型计算机集群。 社交网络的分析。市场分割。天文数据分析<br />\n<img data-src=\"/pic/wuenda/wujianduxuexi-02.png\" alt=\"img.png\" /><br />\n4、鸡尾酒 party 问题，将混在一起的多个音频源拆开。<br />\n<img data-src=\"/pic/wuenda/wujianduxuexi-03.png\" alt=\"img.png\" /><br />\n 通过这个例子，特别强调了 Octave 和 MATLAB 这些软件的简洁之处，这个算法的实现在 Octave 里只需要一行代码</p>\n",
            "tags": [
                "ai",
                "Andrew Ng Lesson",
                "ai lesson"
            ]
        },
        {
            "id": "https://love.youhuamao.xyz/2022/10/31/Java/Java%E5%9F%BA%E7%A1%80/String%EF%BC%8CStringBuffer%EF%BC%8CStringBuilder/",
            "url": "https://love.youhuamao.xyz/2022/10/31/Java/Java%E5%9F%BA%E7%A1%80/String%EF%BC%8CStringBuffer%EF%BC%8CStringBuilder/",
            "title": "String，StringBuffer，StringBuilder",
            "date_published": "2022-10-30T16:00:00.000Z",
            "content_html": "<h1 id=\"string类的理解和创建对象\"><a class=\"anchor\" href=\"#string类的理解和创建对象\">#</a> String 类的理解和创建对象</h1>\n<ul>\n<li>\n<p>String 对象用于保存字符串，也就是一组字符序列</p>\n</li>\n<li>\n<p>字符串常量对象是用双引号括起的字符序列。例如: &quot;你好&quot;、&quot;12.97&quot;、 &quot;boy&quot; 等</p>\n</li>\n<li>\n<p>字符串的字符使用 Unicode 字符编码，一个字符 (不区分字母还县汉宁占两个宁节</p>\n</li>\n<li>\n<p>String 类较常用构造方法 (其它看手册):<br />\nString s1 = new String();<br />\nString s2 = new String(String original);<br />\nString s3 = new String(char[] a);<br />\nString s4 = new String(char[] a,int startIndex,int count)</p>\n</li>\n<li>\n<p>String 有属性 private final char value []; 用于存放字符串内容 一定要注意: value 是一个 final 类型，不可以修改其地址，但可以修改值</p>\n</li>\n<li>\n<p>创建对象的两种方式<br />\n方式一：直接赋值 Strings = &quot;hspedu&quot;;</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>方式- :先从常量池查看是否有<span class=\"token string\">\"hsp\"</span>数据空间，如果有，直接指向<span class=\"token punctuation\">;</span>如果没有则重新创建，然后指向。s最终指向的是常量池的空间地址</pre></td></tr></table></figure><p>方式二：调用构造器 String S = new String (&quot;hspedu&quot;);</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>方式二:先在堆中创建空间，里面维护了value属性，指向常量池的hsp空间。如果常量池没有<span class=\"token string\">\"hsp\"</span>,重新创建，如果有，直接通过value指向。 最终指向的是堆中的空间地址。</pre></td></tr></table></figure><h1 id=\"字符串特性\"><a class=\"anchor\" href=\"#字符串特性\">#</a> 字符串特性</h1>\n<ul>\n<li>String 是一个 final 类， 代表不可变的字符序列</li>\n<li>字符串是不可变的。一个字符串对象旦被分配， 其内容是不可变的.</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>String a <span class=\"token operator\">=</span> <span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">;</span> //创建a对象</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>String b <span class=\"token operator\">=</span> <span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">;</span>//创建 b对象</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//老韩解读</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>//1.先创建一个StringBuilder sb <span class=\"token operator\">=</span> StringBuilder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>//2. 执行sb. append<span class=\"token punctuation\">(</span><span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>//3. sb. append<span class=\"token punctuation\">(</span><span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>//4. String <span class=\"token assign-left variable\">c</span><span class=\"token operator\">=</span> sb. toString<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>//最后其实是c指向堆中的对象<span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">)</span> value<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> -<span class=\"token operator\">></span>池中<span class=\"token string\">\"helloabd\"</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>String C <span class=\"token operator\">=</span>a+b<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>String a <span class=\"token operator\">=</span> <span class=\"token string\">\"hello\"</span>+<span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">;</span> //String a <span class=\"token operator\">=</span> <span class=\"token string\">\"hello\"</span>+ <span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">;</span> //<span class=\"token operator\">==</span><span class=\"token operator\">></span>优化等价String a <span class=\"token operator\">=</span> \"helloabc <span class=\"token punctuation\">;</span></pre></td></tr></table></figure><ul>\n<li>底层是 StringBuilder sb = new StringBuilder (); sb.append (a);sb.append (b); sb 是在堆中，并且 append 是在原来字符串的基础上追加的.</li>\n<li>重要规则，Stringc1 =&quot;ab&quot; + &quot;cd&quot;; 常量相加，看的是池。 Stringc1 = a + b; 变量相加，是在堆中</li>\n</ul>\n<h1 id=\"srtring类常见方法\"><a class=\"anchor\" href=\"#srtring类常见方法\">#</a> Srtring 类常见方法</h1>\n<ul>\n<li>equals // 区分大小写，判断内容是否相等</li>\n<li>equalslgnoreCase // 忽略大小写的判断内容是否相等</li>\n<li>length // 获取字符的个数，字符串的长度</li>\n<li>indexOf // 获取字符在字符串中第 1 次出现的索引，索引从 0 开始，如果找不到，返回 - 1</li>\n<li>lastlndexOf // 获取字符在字符串中最后 1 次出现的索引，索引从 0 开始，如找不到，返回 - 1</li>\n<li>substring // 截取指定范围的子串</li>\n<li>trim // 去前后空格</li>\n<li>charAt: 获取某索引处的字符，注意不能使用 Str [index] 这种方式</li>\n<li>toUpperCase</li>\n<li>toLowerCase</li>\n<li>concat</li>\n<li>replace 替换字符串中的字符</li>\n<li>split 分割字符串，对于某些分割字符，我们需要转义比如 | \\ 等案例: String poem = &quot;锄禾日当午，汗滴禾下土，谁知盘中餐粒粒皆辛苦&quot;; 和文件路径.</li>\n<li>compareTp // 比较两个字符串的大小</li>\n<li>toCharArray // 转换成字符数组</li>\n<li>format // 格式字符串，% s 字符串 % c 字符 % d 整型 %.2f 浮点型案例，将一个人的信息格式化输出。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>int name <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>String i <span class=\"token operator\">=</span> String.format<span class=\"token punctuation\">(</span>我的年龄是%d,name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"stringbuffer类\"><a class=\"anchor\" href=\"#stringbuffer类\">#</a> StringBuffer 类</h1>\n<ul>\n<li>java.lang.StringBuffer 代表可变的字符序列，可以对字符串内容进行增删。</li>\n<li>很多方法与 String 相同，但 StringBuffer 是可变长度的。</li>\n<li>StringBuffer 是一个容器。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span>. StringBuffer 的直接父类是AbstractStringBuilder</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token number\">2</span>. StringBuffer 实现了Serializable, 即StringBuffer的对象可以串行化</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token number\">3</span>.在父类中 AbstractStringBuilder 有属性char<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> vaLue,不是final 该value数组存放字符串内容，引出存放在堆中的</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token number\">4</span>. StringBuffer 是一个final类，不能被继承</pre></td></tr></table></figure><h1 id=\"string-vs-stringbuffer\"><a class=\"anchor\" href=\"#string-vs-stringbuffer\">#</a> String VS StringBuffer</h1>\n<ul>\n<li>String 保存的是字符串常量，里面的值不能更改，每次 String 类的更新实际上就是更改地址，效率较低 //private final char value [];</li>\n<li>StringBuffer 保存的是字符串变量，里面的值可以更改，每次 StringBuffer 的更新实际上可以更新内容，不用每次更新地址 (当空间不够时更新)，效率较高<br />\n //char [] value; / 这个放在堆.</li>\n</ul>\n<h1 id=\"stringbuffer构造器\"><a class=\"anchor\" href=\"#stringbuffer构造器\">#</a> StringBuffer 构造器</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>StringBuffer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>构造一个其中不带字符的字符串缓冲区，其初始容量为16个字符。</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>StringBuffer<span class=\"token punctuation\">(</span>CharSequence <span class=\"token function\">seq</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>public java.lang StringBuilder<span class=\"token punctuation\">(</span>CharSequence <span class=\"token function\">seq</span><span class=\"token punctuation\">)</span>构造- - -个字符串缓冲区，它包含与指定的CharSequence相同的字符。</pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>StringBuffer<span class=\"token punctuation\">(</span>int capacity<span class=\"token punctuation\">)</span> //capacity <span class=\"token punctuation\">[</span>容量<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>构造-一个不带字符，但具有指定初始容量的字符串缓冲区。即对char<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>大小进行指定</pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>StringBuffer<span class=\"token punctuation\">(</span>String str<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>构造一个字符串缓冲区，并将其内容初始化为指定的字符串内容。</pre></td></tr></table></figure><h1 id=\"string和stringbuffer相互转换\"><a class=\"anchor\" href=\"#string和stringbuffer相互转换\">#</a> String 和 StringBuffer 相互转换</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>/ String --<span class=\"token operator\">></span> StringBuffer</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Strings <span class=\"token operator\">=</span> <span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//方式1:</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>StringBuffer b1 <span class=\"token operator\">=</span> new StringBuffer<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>/方式2:</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>StringBuffer b2 <span class=\"token operator\">=</span> new StringBuffer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>b2.append<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>/ StringBuffer 一<span class=\"token operator\">></span> String</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>//方式1:</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>String s2 <span class=\"token operator\">=</span> b1.toString<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> //b1 <span class=\"token punctuation\">[</span>StringBuffer<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>//方式2:</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>String s3 <span class=\"token operator\">=</span> new String<span class=\"token punctuation\">(</span>b1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h1 id=\"stringbuffer方法\"><a class=\"anchor\" href=\"#stringbuffer方法\">#</a> StringBuffer 方法</h1>\n<ul>\n<li>增 append</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>StringBuffer s <span class=\"token operator\">=</span> new StringBuffer<span class=\"token punctuation\">(</span><span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//增</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>s.append<span class=\"token punctuation\">(</span><span class=\"token string\">', '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>// <span class=\"token string\">\"hello,\"</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>s.append<span class=\"token punctuation\">(</span><span class=\"token string\">\"张三丰\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>//<span class=\"token string\">\"hello,张三丰”</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>s.append(\"</span>赵敏<span class=\"token string\">\" ).append(100).append(true).append(10. 5);//\"</span>hello,张三丰赵敏100true10.5<span class=\"token string\">\"</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>System.out.printLn(s);//\"</span>he7O,张三丰赵敏100true10.5\"</pre></td></tr></table></figure><ul>\n<li>删 delete (start,end)</li>\n<li>改 replace (start,end,string)// 将 start---end 间的内容替换掉，不含 end</li>\n<li>查 indexOf // 查找子串在字符串第 1 次出现的索引，如果找不到返回 - 1</li>\n<li>插 insert</li>\n<li>获取长度 length</li>\n</ul>\n<h1 id=\"stringbuilder类\"><a class=\"anchor\" href=\"#stringbuilder类\">#</a> StringBuilder 类</h1>\n<ul>\n<li>个可变的字符序列。此类提供一个与 StringBuffer 兼容的 API, 但不保证同步 (StringBuilder 不是线程安全)。该类被设计用作 StringBuffer 的一个简易替换，用在字符串缓冲区被单个线程使用的时候。如果可能，建议优先采用该类，因为在大多数实现中，它比 StringBuffer 要快。</li>\n<li>在 StringBuilder . 上的主要操作是 append 和 insert 方法，可重载这些方法，以接受任意类型的数据。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>//老韩解读</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>//1. StringBuilder 继承AbstractStringBuilder 类</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>//2. 实现了SeriaLizable ,说明StringBuilder对象是可以串行化<span class=\"token punctuation\">(</span>对象可以网络传输，可以保存到文件<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>//3. StringBuilder 是final类，不能被继承</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>//4. StringBuilder 对象字符序列仍然是存放在其父类AbstractStringBuilder的 char<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> vaLue <span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>//因此，字符序列是堆中</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>//5. StringBuilder的方法，没有做互斥的处理,即没有synchronized 关键字,因此在单线程的情况下使用</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>StringBuilder stringBuilder <span class=\"token operator\">=</span> new StringBuilder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span></pre></td></tr></table></figure>",
            "tags": [
                "学习Java",
                "Java基础",
                "java"
            ]
        }
    ]
}